{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import models \n",
    "from models import get_accuracy\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create similar users from training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen 300 similar users: [345 876 558 667 236 261 651 312  14 674  97 230 566  77  55 492 278 818\n",
      " 658 647 337  31 893 914 294 733 687 320 440 193 144 578 866 311 925 815\n",
      " 809 700 122 409 571 342 204 231 524  65 317 670 767 214 521 366 145 752\n",
      " 427 483 380 747 726 666 308 901 630 200 408 683 549 601 443 249 727 271\n",
      " 403 736  60 596 826 251 744 101 772 142 399 869 240 548 424 653 730   8\n",
      " 912 175 577 264 942 929 495 346 447 306  34 247 196 103 362 695 722 332\n",
      "  27 141  30 813 425 479 293 648 817 316 279 390 628 436 891 729 202 769\n",
      " 649 493 506 750 325 384 941 828 604 814 724 418 741 932 890 916 758 432\n",
      " 927 295   5 304 936 682 745 907 150 773 520 827 253 267 884 460 751 834\n",
      " 113 940  37 908 367 158 154  40 283 266 854 922 356 567 742 887 585 478\n",
      " 350 412 939  62  79 642 181 935 564 298 934 857 285   2 711 389 330 632\n",
      "  85 386  75 710 487 838 372 768 262   1 625 771 215 889 685 676 568 140\n",
      " 776 569 462 415 352 364 252 270 255 162 715 874 580 868 895 518 239 538\n",
      " 561  54  45 363 172 496 299 477 272 466 933  39 310 338  18 331 156 222\n",
      " 788 210 686  50 800 904 167 740 416 420  10 105  68 422 351 382 258 693\n",
      " 519 765 883 871 862  20 855 395 671  71  49 471 481 780 116  76  48 858\n",
      " 263 937 900 870  64 753  52 873 124 613 358 523]\n",
      "train edges shape:  (159619, 3)\n",
      "similar users train edges shape:  (47686, 3)\n",
      "new train edges shape:  (207305, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1243, 1682, 207305, 40381)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'movielens'\n",
    "n_users = 943\n",
    "n_items = 1682\n",
    "n_similar_users = 300 # hyperparameter\n",
    "\n",
    "# load original training edges\n",
    "train_edges = np.load('data/' + dataset + '/train_edges.npy')\n",
    "test_edges = np.load('data/' + dataset + '/test_edges.npy')\n",
    "\n",
    "# create dicts of positive and negative edges for sampling later (only training edges, not test edges)\n",
    "positive_edges = dict()\n",
    "negative_edges = dict() \n",
    "\n",
    "for u in range(n_users):\n",
    "    positive_edges[u] = []\n",
    "    negative_edges[u] = []\n",
    "\n",
    "n_train_edges = train_edges.shape[0]\n",
    "\n",
    "for i in range(n_train_edges):\n",
    "    u = train_edges[i, 0]\n",
    "    v = train_edges[i, 1]\n",
    "    y = train_edges[i, 2]\n",
    "    if y == 1:\n",
    "        positive_edges[u].append(v)\n",
    "    else:\n",
    "        negative_edges[u].append(v)\n",
    "\n",
    "np.random.seed(0)\n",
    "similar_users = np.random.choice(n_users, n_similar_users, replace=False)\n",
    "print('chosen {} similar users: {}'.format(n_similar_users, similar_users))\n",
    "\n",
    "# 100% similarity for similar users \n",
    "similar_users_train_edges = []\n",
    "for j in range(len(similar_users)):\n",
    "    u = similar_users[j]\n",
    "    for item in positive_edges[u]:\n",
    "        similar_users_train_edges.append([j + n_users, item, 1])\n",
    "    for item in negative_edges[u]:\n",
    "        similar_users_train_edges.append([j + n_users, item, 0])\n",
    "\n",
    "similar_users_train_edges = np.array(similar_users_train_edges)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(similar_users_train_edges)\n",
    "np.random.shuffle(similar_users_train_edges)\n",
    "\n",
    "# similar_users_train_edges \n",
    "train_edges_new = np.concatenate((train_edges, similar_users_train_edges), axis=0)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(train_edges_new)\n",
    "print('train edges shape: ', train_edges.shape)\n",
    "print('similar users train edges shape: ', similar_users_train_edges.shape)\n",
    "print('new train edges shape: ', train_edges_new.shape)\n",
    "\n",
    "# proceed with creating users, items and ratings as usual\n",
    "user_list_train = train_edges_new[:, 0]\n",
    "user_list_test = test_edges[:, 0]\n",
    "item_list_train = train_edges_new[:, 1]\n",
    "item_list_test = test_edges[:, 1]\n",
    "rating_list_train = train_edges_new[:, 2].astype('float32')\n",
    "rating_list_test = test_edges[:, 2].astype('float32')\n",
    "\n",
    "# compute new n_users, n_items and n_samples\n",
    "n_users = max(user_list_train.max(), user_list_test.max()) + 1 \n",
    "n_items = max(item_list_train.max(), item_list_test.max()) + 1\n",
    "n_samples_train = len(rating_list_train)\n",
    "n_samples_test = len(rating_list_test)\n",
    "\n",
    "n_users, n_items, n_samples_train, n_samples_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Code for surrogate attack using new users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Algorithm:  meta-similar(300)\n",
      "\n",
      "-> T (surrogate):  25\n",
      "-> T (target):  25\n",
      "-> Delta: 10000 (4.82%)\n",
      "-> Embedding size (surrogate):  8\n",
      "-> Embedding size (target):  8\n",
      "-> Device:  cuda:3\n",
      "\n",
      "-> Surrogate:  CFD\n",
      "-> Target:  CFD\n",
      "-> Surrogate optimizer:  adam\n",
      "-> Target optimizer:  adam\n",
      "-> Surrogate learning rate:  0.2\n",
      "-> Target learning rate:  0.2\n",
      "-> Surrogate dropout:  0\n",
      "-> Target dropout:  0\n",
      "-> Surrogate seed:  0\n",
      "-> Target seed:  1\n",
      "\n",
      "-> Retain graph:  True\n",
      "-> Create graph:  False\n",
      "-> Save results:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-> Perturbations:   2%|‚ñè         | 212/10000 [01:15<1:03:12,  2.58it/s]"
     ]
    }
   ],
   "source": [
    "# model settings\n",
    "algorithm = 'meta-similar({})'.format(n_similar_users)\n",
    "surrogate = 'CFD'\n",
    "target = 'CFD'\n",
    "opt_surrogate = 'adam'\n",
    "opt_target = 'adam'\n",
    "lr_surrogate = 0.2\n",
    "lr_target = 0.2\n",
    "seed_surrogate = 0\n",
    "seed_target = 1\n",
    "dropout_surrogate = 0\n",
    "dropout_target = 0\n",
    "\n",
    "# start execution\n",
    "start_time = time.time()\n",
    "\n",
    "# GPU settings (set use_gpu = -1 if you want to use CPU)\n",
    "use_gpu = 3\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# some hyperparameters\n",
    "T_surrogate = 25\n",
    "T_target = 25\n",
    "Delta = 10000 # 5% ~ 10K perturbations for movielens\n",
    "n_factors_surrogate = 8\n",
    "n_factors_target = 8\n",
    "save_results = True\n",
    "retain_graph = True \n",
    "create_graph = False\n",
    "\n",
    "if Delta < 100:\n",
    "    save_results = False\n",
    "\n",
    "# initialize list of perturbations\n",
    "perturbations = dict()\n",
    "perturbations['edges'] = []\n",
    "perturbations['metagrad'] = []\n",
    "\n",
    "perturbations['accuracy-before-surrogate'] = []\n",
    "perturbations['accuracy-after-surrogate'] = []\n",
    "perturbations['accuracy-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['loss-before-surrogate'] = []\n",
    "perturbations['loss-after-surrogate'] = []\n",
    "perturbations['loss-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['accuracy-before-target'] = []\n",
    "perturbations['accuracy-after-target'] = []\n",
    "perturbations['accuracy-unseen-target'] = []\n",
    "\n",
    "perturbations['loss-before-target'] = []\n",
    "perturbations['loss-after-target'] = []\n",
    "perturbations['loss-unseen-target'] = []\n",
    "\n",
    "perturbations['auc-before-surrogate'] = []\n",
    "perturbations['auc-after-surrogate'] = []\n",
    "perturbations['auc-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['auc-before-target'] = []\n",
    "perturbations['auc-after-target'] = []\n",
    "perturbations['auc-unseen-target'] = []\n",
    "\n",
    "# print hyperparam configuration\n",
    "print('-> Algorithm: ', algorithm)\n",
    "print()\n",
    "print('-> T (surrogate): ', T_surrogate)\n",
    "print('-> T (target): ', T_target)\n",
    "print('-> Delta: {} ({}%)'.format(Delta, round(Delta * 100 / n_samples_train, 2)))\n",
    "print('-> Embedding size (surrogate): ', n_factors_surrogate)\n",
    "print('-> Embedding size (target): ', n_factors_target)\n",
    "print('-> Device: ', device)\n",
    "print()\n",
    "print('-> Surrogate: ', surrogate)\n",
    "print('-> Target: ', target)\n",
    "print('-> Surrogate optimizer: ', opt_surrogate)\n",
    "print('-> Target optimizer: ', opt_target)\n",
    "print('-> Surrogate learning rate: ', lr_surrogate)\n",
    "print('-> Target learning rate: ', lr_target)\n",
    "print('-> Surrogate dropout: ', dropout_surrogate)\n",
    "print('-> Target dropout: ', dropout_target)\n",
    "print('-> Surrogate seed: ', seed_surrogate)\n",
    "print('-> Target seed: ', seed_target)\n",
    "print()\n",
    "print('-> Retain graph: ', retain_graph)\n",
    "print('-> Create graph: ', create_graph)\n",
    "print('-> Save results: ', save_results)\n",
    "\n",
    "# load users, items and ratings as tensors\n",
    "users = torch.tensor(user_list_train, device = device)\n",
    "items = torch.tensor(item_list_train, device = device)\n",
    "ratings = torch.tensor(rating_list_train, device = device, requires_grad = True)\n",
    "\n",
    "# only those edges are allowed to be perturbed whose mask entry is False\n",
    "mask = torch.ones_like(ratings).bool()\n",
    "mask[users >= 943] = False # perturbations only allowed for newly injected similar users\n",
    "mask[ratings == 1] = True # positive edges cannot be perturbed even for new users\n",
    "\n",
    "# perturbs keeps track of perturbed edges by marking them as False\n",
    "perturbs = torch.ones_like(ratings).bool()\n",
    "\n",
    "# generate tensors out of validation data\n",
    "users_test = torch.tensor(user_list_test, device = device)\n",
    "items_test = torch.tensor(item_list_test, device = device)\n",
    "ratings_test = torch.tensor(rating_list_test, device = device)\n",
    "\n",
    "# sample random negative edges to perturb for baseline\n",
    "if 'base' in algorithm:\n",
    "    edges = mask.int().detach().to('cpu').numpy()\n",
    "    neg_edges = np.where(edges == 0)[0]\n",
    "    np.random.seed(0)\n",
    "    edges_to_perturb = np.random.choice(neg_edges, size=Delta, replace = False) # sample Delta edges randomly and perturb one by one inside loop \n",
    "\n",
    "# for each perturbation do the following\n",
    "for delta in tqdm(range(Delta), desc='-> Perturbations'):\n",
    "\n",
    "    # define surrogate model and it's parameters\n",
    "    torch.manual_seed(seed_surrogate)\n",
    "    model = getattr(models, surrogate)(n_users, n_items, n_factors_surrogate, dropout_surrogate).to(device)\n",
    "\n",
    "    # define optimizer and loss function\n",
    "    if 'adam' in opt_surrogate:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr_surrogate)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr_surrogate)\n",
    "    loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # inner loop training process\n",
    "    model.train()\n",
    "    for i in range(T_surrogate):\n",
    "        y_hat = model(users, items).reshape(ratings.shape)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "\n",
    "    # compute and store accuracy of model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # training accuracy and loss including perturbed edges\n",
    "        y_hat = model(users, items).reshape(ratings.shape)\n",
    "        perturbations['accuracy-before-surrogate'].append(get_accuracy(y_hat, ratings))\n",
    "        perturbations['loss-before-surrogate'].append(loss_fn(y_hat, ratings).item())\n",
    "\n",
    "        # compute training AUROC including perturbed edges\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings.detach().clone().to('cpu').numpy() \n",
    "        perturbations['auc-before-surrogate'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "        # training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs)\n",
    "        ratings_masked = torch.masked_select(ratings, perturbs)\n",
    "        perturbations['accuracy-after-surrogate'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss-after-surrogate'].append(loss_fn(y_hat_masked, ratings_masked).item())\n",
    "\n",
    "        # compute training AUROC excluding perturbed edges\n",
    "        y_pred = y_hat_masked.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_masked.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-after-surrogate'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # compute and store accuracy of surrogate model on unseen data\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(users_test, items_test).reshape(ratings_test.shape)\n",
    "        perturbations['accuracy-unseen-surrogate'].append(get_accuracy(y_hat, ratings_test))\n",
    "        perturbations['loss-unseen-surrogate'].append(loss_fn(y_hat, ratings_test).item())\n",
    "\n",
    "        # compute unseen AUROC\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_test.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-unseen-surrogate'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # compute meta gradient\n",
    "    if 'meta' in algorithm:\n",
    "        meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "\n",
    "    # define evaluation model\n",
    "    torch.manual_seed(seed_target)\n",
    "    eval_model = getattr(models, target)(n_users, n_items, n_factors_target, dropout_target).to(device)\n",
    "\n",
    "    # define optimizer and loss function for evaluation\n",
    "    if 'adam' in opt_target:\n",
    "        optimizer_eval = torch.optim.Adam(eval_model.parameters(), lr = lr_target)\n",
    "    else:\n",
    "        optimizer_eval = torch.optim.SGD(eval_model.parameters(), lr = lr_target)\n",
    "    loss_fn_eval = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # detach ratings and perturbs for eval model\n",
    "    ratings_eval = ratings.detach().clone()\n",
    "    perturbs_eval = perturbs.detach().clone()\n",
    "\n",
    "    # inner train  evaluation model\n",
    "    eval_model.train()\n",
    "    for i in range(T_target):\n",
    "        y_hat = eval_model(users, items).reshape(ratings_eval.shape)\n",
    "        loss_eval = loss_fn_eval(y_hat, ratings_eval)\n",
    "        optimizer_eval.zero_grad()\n",
    "        loss_eval.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer_eval.step()\n",
    "    eval_model.eval()\n",
    "\n",
    "    # compute and store accuracy of eval model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # training accuracy and loss including perturbed edges\n",
    "        y_hat = eval_model(users, items).reshape(ratings_eval.shape)\n",
    "        perturbations['accuracy-before-target'].append(get_accuracy(y_hat, ratings_eval))\n",
    "        perturbations['loss-before-target'].append(loss_fn_eval(y_hat, ratings_eval).item())\n",
    "\n",
    "        # compute training AUROC including perturbed edges\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_eval.detach().clone().to('cpu').numpy() \n",
    "        perturbations['auc-before-target'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "        # training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs_eval)\n",
    "        ratings_masked = torch.masked_select(ratings_eval, perturbs_eval)\n",
    "        perturbations['accuracy-after-target'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss-after-target'].append(loss_fn_eval(y_hat_masked, ratings_masked).item())\n",
    "\n",
    "        # compute training AUROC excluding perturbed edges\n",
    "        y_pred = y_hat_masked.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_masked.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-after-target'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # compute and store accuracy of target model on unseen data\n",
    "    with torch.no_grad():\n",
    "        y_hat = eval_model(users_test, items_test).reshape(ratings_test.shape)\n",
    "        perturbations['accuracy-unseen-target'].append(get_accuracy(y_hat, ratings_test))\n",
    "        perturbations['loss-unseen-target'].append(loss_fn(y_hat, ratings_test).item())\n",
    "\n",
    "        # compute unseen AUROC\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_test.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-unseen-target'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # select best edge and perform perturbation\n",
    "    with torch.no_grad():\n",
    "        if 'meta' in algorithm:\n",
    "            meta_grad[mask == True] = 0\n",
    "            best_edge = meta_grad.argmax().item()\n",
    "            \n",
    "            if mask[best_edge] == False:\n",
    "                # if this condition is true, it means there is not even a single eligible unperturbed edge with a positive meta-gradient\n",
    "                ratings[best_edge] = 1\n",
    "                perturbs[best_edge] = False\n",
    "                mask[best_edge] = True\n",
    "                perturbations['edges'].append(best_edge)\n",
    "                perturbations['metagrad'].append(meta_grad[best_edge].item())\n",
    "            else:\n",
    "                perturbations['edges'].append(-1)\n",
    "                perturbations['metagrad'].append(0)\n",
    "\n",
    "        else:\n",
    "            best_edge = edges_to_perturb[delta]\n",
    "            ratings[best_edge] = 1 \n",
    "            perturbs[best_edge] = False\n",
    "            mask[best_edge] = True\n",
    "\n",
    "            perturbations['edges'].append(best_edge)\n",
    "            perturbations['metagrad'].append(-1)\n",
    "\n",
    "sleep(1)\n",
    "# compute execution time\n",
    "exec_time = int(time.time() - start_time)\n",
    "exec_time = time.strftime(\"%Hh %Mm %Ss\", time.gmtime(exec_time))\n",
    "print('-> Execution time: {}'.format(exec_time))\n",
    "\n",
    "# process results\n",
    "perturbations = pd.DataFrame(perturbations)\n",
    "filename = '{}({},{})-{}({},{})-{}-D={}-T({},{})-lr({},{})-seed({},{})-drop({},{})'.format(surrogate, n_factors_surrogate, opt_surrogate, target, n_factors_target, opt_target, algorithm, Delta, T_surrogate, T_target, lr_surrogate, lr_target, seed_surrogate, seed_target, dropout_surrogate, dropout_target)\n",
    "print('-> File name: {}'.format(filename))\n",
    "if save_results:\n",
    "    perturbations.to_csv('results/' + dataset + '/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('File name: ', filename)\n",
    "if 'meta' in algorithm:\n",
    "    print('Max meta-gradient: ', perturbations['metagrad'].max())\n",
    "perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process perturbations data\n",
    "perturbations_reset = perturbations.reset_index()\n",
    "perturbations_reset.columns = ['# Perturbations', 'Perturbed edge', 'Meta gradient', 'Accuracy including perturbed edges (surrogate)', 'Accuracy excluding perturbed edges (surrogate)', 'Accuracy unseen (surrogate)', 'Loss including perturbed edges (surrogate)', 'Loss excluding perturbed edges (surrogate)', 'Loss unseen (surrogate)', 'Accuracy including perturbed edges (target)', 'Accuracy excluding perturbed edges (target)', 'Accuracy unseen (target)', 'Loss including perturbed edges (target)', 'Loss excluding perturbed edges (target)', 'Loss unseen (target)', 'AUROC including perturbed edges (surrogate)', 'AUROC excluding perturbed edges (surrogate)', 'AUROC unseen (surrogate)', 'AUROC including perturbed edges (target)', 'AUROC excluding perturbed edges (target)', 'AUROC unseen (target)']\n",
    "perturbations_reset\n",
    "\n",
    "# Figure specifications\n",
    "sns.set_theme()\n",
    "figsize = (7, 6)\n",
    "print('File name: ', filename)\n",
    "\n",
    "# Loss on training data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss excluding perturbed edges (surrogate)', color = 'blue').set_title('Comparison of loss on training data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss excluding perturbed edges (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(labels = ['Loss (surrogate)', 'Loss (target)'])\n",
    "if save_results: \n",
    "    fig.savefig('plots/' + dataset + '/losses-' + filename + '.png')\n",
    "plt.show()\n",
    "\n",
    "# Loss on unseen data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss unseen (surrogate)', color = 'blue').set_title('Comparison of loss on unseen data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss unseen (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(labels = ['Loss unseen (surrogate)', 'Loss unseen (target)'])\n",
    "if save_results: \n",
    "    fig.savefig('plots/' + dataset + '/losses-unseen-' + filename + '.png')\n",
    "plt.show()\n",
    "\n",
    "# Accuracy on training data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy excluding perturbed edges (surrogate)', color = 'blue').set_title('Comparison of accuracy on training data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy excluding perturbed edges (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(labels = ['Accuracy (surrogate)', 'Accuracy (target)'])\n",
    "if save_results:\n",
    "    fig.savefig('plots/' + dataset + '/accuracy-' + filename + '.png')\n",
    "plt.show()\n",
    "\n",
    "# Accuracy on unseen data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy unseen (surrogate)', color = 'blue').set_title('Comparison of accuracy on unseen data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy unseen (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(labels = ['Accuracy unseen (surrogate)', 'Accuracy unseen (target)'])\n",
    "if save_results: \n",
    "    fig.savefig('plots/' + dataset + '/accuracy-unseen-' + filename + '.png')\n",
    "plt.show()\n",
    "\n",
    "# AUROC on training data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'AUROC excluding perturbed edges (surrogate)', color = 'blue').set_title('Comparison of AUROC on training data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'AUROC excluding perturbed edges (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('AUROC')\n",
    "plt.legend(labels = ['AUROC (surrogate)', 'AUROC (target)'])\n",
    "if save_results:\n",
    "    fig.savefig('plots/' + dataset + '/AUROC-' + filename + '.png')\n",
    "plt.show()\n",
    "\n",
    "# AUROC on unseen data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'AUROC unseen (surrogate)', color = 'blue').set_title('Comparison of AUROC on unseen data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'AUROC unseen (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('AUROC')\n",
    "plt.legend(labels = ['AUROC unseen (surrogate)', 'AUROC unseen (target)'])\n",
    "if save_results:\n",
    "    fig.savefig('plots/' + dataset + '/AUROC-unseen-' + filename + '.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
