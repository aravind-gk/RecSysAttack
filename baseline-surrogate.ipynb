{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparams and loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1698, 1397, 168848)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'steam'\n",
    "\n",
    "train_edges = np.load(dataset + '/train_edges.npy')\n",
    "user_list = train_edges[:, 0]\n",
    "item_list = train_edges[:, 1]\n",
    "rating_list = train_edges[:, 2].astype('float32')\n",
    "\n",
    "n_users = user_list.max() + 1 \n",
    "n_items = item_list.max() + 1\n",
    "n_samples = len(rating_list)\n",
    "\n",
    "n_users, n_items, n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        dot = (u * i).sum(1)\n",
    "        return torch.sigmoid(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.fc1 = nn.Linear(n_factors * 2, n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        tanh = nn.Tanh()\n",
    "        sigmoid = nn.Sigmoid()\n",
    "        swish = nn.SiLU()\n",
    "\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        x = torch.concat([u, i], dim = 1)\n",
    "        x = swish(x)\n",
    "        x = self.fc1(x)\n",
    "        x = swish(x)\n",
    "        x = self.fc2(x)\n",
    "        x = sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_hat, y):\n",
    "    y = y.clone().int()\n",
    "    y_hat = (y_hat.clone() > 0.5).int()\n",
    "    accuracy = (y == y_hat).sum() / len(y)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Baseline code for surrogate meta-attack (surrogate-CF-SGD, evaluation-CF-Adam, same-init)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> T:  250\n",
      "-> Delta: 5000 (2.96%)\n",
      "-> Embedding size:  64\n",
      "-> Device:  cuda:7\n",
      "\n",
      "-> Surrogate:  NCF(swish)\n",
      "-> Target:  NCF(swish)\n",
      "-> Surrogate optimizer:  adam\n",
      "-> Target optimizer:  adam\n",
      "-> Surrogate learning rate:  0.01\n",
      "-> Target learning rate:  0.01\n",
      "-> Surrogate seed:  50\n",
      "-> Target seed:  0\n",
      "\n",
      "-> Retain graph:  True\n",
      "-> Create graph:  False\n",
      "-> Save results:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-> Perturbations: 100%|██████████| 5000/5000 [2:16:25<00:00,  1.64s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Execution time: 02h 16m 26s\n"
     ]
    }
   ],
   "source": [
    "# model settings\n",
    "surrogate = 'NCF(swish)'\n",
    "target = 'NCF(swish)'\n",
    "opt_surrogate = 'adam'\n",
    "opt_target = 'adam'\n",
    "lr_surrogate = 0.01\n",
    "lr_target = 0.01\n",
    "seed_surrogate = 50\n",
    "seed_target = 0\n",
    "\n",
    "# start execution\n",
    "start_time = time.time()\n",
    "\n",
    "# GPU settings (set use_gpu = -1 if you want to use CPU)\n",
    "use_gpu = 7\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# some hyperparams\n",
    "T = 250\n",
    "Delta = 5000 # 5% ~ 10K perturbations\n",
    "n_factors = 64\n",
    "save_results = True\n",
    "retain_graph = True \n",
    "create_graph = False\n",
    "\n",
    "# list of perturbations\n",
    "perturbations = dict()\n",
    "perturbations['edges'] = []\n",
    "perturbations['metagrad'] = []\n",
    "perturbations['accuracy_before'] = []\n",
    "perturbations['accuracy_after'] = []\n",
    "perturbations['loss_before'] = []\n",
    "perturbations['loss_after'] = []\n",
    "\n",
    "perturbations['accuracy_before_eval'] = []\n",
    "perturbations['accuracy_after_eval'] = []\n",
    "perturbations['loss_before_eval'] = []\n",
    "perturbations['loss_after_eval'] = []\n",
    "\n",
    "# print hyperparam config\n",
    "print('-> T: ', T)\n",
    "print('-> Delta: {} ({}%)'.format(Delta, round(Delta * 100 / n_samples, 2)))\n",
    "print('-> Embedding size: ', n_factors)\n",
    "print('-> Device: ', device)\n",
    "print()\n",
    "print('-> Surrogate: ', surrogate)\n",
    "print('-> Target: ', target)\n",
    "print('-> Surrogate optimizer: ', opt_surrogate)\n",
    "print('-> Target optimizer: ', opt_target)\n",
    "print('-> Surrogate learning rate: ', lr_surrogate)\n",
    "print('-> Target learning rate: ', lr_target)\n",
    "print('-> Surrogate seed: ', seed_surrogate)\n",
    "print('-> Target seed: ', seed_target)\n",
    "print()\n",
    "print('-> Retain graph: ', retain_graph)\n",
    "print('-> Create graph: ', create_graph)\n",
    "print('-> Save results: ', save_results)\n",
    "\n",
    "# load users, items and ratings as tensors\n",
    "users = torch.tensor(user_list, device = device)\n",
    "items = torch.tensor(item_list, device = device)\n",
    "ratings = torch.tensor(rating_list, device = device, requires_grad = True)\n",
    "if 'NCF' in surrogate:\n",
    "    ratings = ratings.reshape((n_samples, 1))\n",
    "perturbs = torch.ones_like(ratings).bool()\n",
    "\n",
    "# (for baseline) neg_edges is set of indices of negative edges \n",
    "edges = ratings.detach().to('cpu').numpy()\n",
    "neg_edges = np.where(edges == 0)[0]\n",
    "np.random.seed(0)\n",
    "edges_to_perturb = np.random.choice(neg_edges, size=Delta, replace = True) # sample Delta edges randomly and perturb one by one inside loop \n",
    "\n",
    "# for each perturbation do the following\n",
    "for delta in tqdm(range(Delta), desc='-> Perturbations'):\n",
    "\n",
    "    # define model and it's parameters\n",
    "    if 'NCF' in surrogate:\n",
    "        model = NCF(n_users, n_items, n_factors)\n",
    "    else:\n",
    "        model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    # reset model paramters \n",
    "    torch.manual_seed(seed_surrogate)\n",
    "    for layer in model.children():\n",
    "        layer.reset_parameters()\n",
    "    \n",
    "    # define optimizer\n",
    "    if 'adam' in opt_surrogate:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr_surrogate)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr_surrogate)\n",
    "    \n",
    "    # define loss function\n",
    "    loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # inner loop training process\n",
    "    model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "\n",
    "        # use torch.optim optimizer to compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer.step()\n",
    "\n",
    "    # compute and store accuracy of model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # compute training accuracy and loss including perturbed edges\n",
    "        y_hat = model(users, items)\n",
    "        perturbations['accuracy_before'].append(get_accuracy(y_hat, ratings))\n",
    "        perturbations['loss_before'].append(loss_fn(y_hat, ratings).item())\n",
    "\n",
    "        # compute training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs)\n",
    "        ratings_masked = torch.masked_select(ratings, perturbs)\n",
    "        perturbations['accuracy_after'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss_after'].append(loss_fn(y_hat_masked, ratings_masked).item())\n",
    "    \n",
    "    # compute meta gradient (not required for baseline experiment)\n",
    "    # meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "\n",
    "    # define evaluation model\n",
    "    if 'NCF' in target:\n",
    "        eval_model = NCF(n_users, n_items, n_factors)\n",
    "    else:\n",
    "        eval_model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    eval_model.to(device)\n",
    "\n",
    "    # reset eval model parameters\n",
    "    torch.manual_seed(seed_target)\n",
    "    for layer in eval_model.children():\n",
    "        layer.reset_parameters()\n",
    "\n",
    "    # define optimizer_eval\n",
    "    if 'adam' in opt_target:\n",
    "        optimizer_eval = torch.optim.Adam(eval_model.parameters(), lr = lr_target)\n",
    "    else:\n",
    "        optimizer_eval = torch.optim.SGD(eval_model.parameters(), lr = lr_target)\n",
    "    \n",
    "    # define loss function\n",
    "    loss_fn_eval = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # detach ratings and perturbs for eval model\n",
    "    ratings_eval = ratings.detach().clone()\n",
    "    perturbs_eval = perturbs.detach().clone()\n",
    "\n",
    "    # reshape ratings and perturbs if necessary\n",
    "    if surrogate != target:\n",
    "        if 'NCF' in target:\n",
    "            ratings_eval = ratings_eval.reshape((n_samples, 1))\n",
    "            perturbs_eval = perturbs_eval.reshape((n_samples, 1))\n",
    "        else:\n",
    "            ratings_eval = ratings_eval.reshape((n_samples))\n",
    "            perturbs_eval = perturbs_eval.reshape((n_samples))\n",
    "\n",
    "    # inner train  evaluation model\n",
    "    eval_model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = eval_model(users, items)\n",
    "        loss_eval = loss_fn_eval(y_hat, ratings_eval)\n",
    "\n",
    "        # use torch.optim optimizer to compute gradients\n",
    "        optimizer_eval.zero_grad()\n",
    "        loss_eval.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer_eval.step()\n",
    "    \n",
    "    eval_model.eval()\n",
    "\n",
    "    # compute and store accuracy of eval model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # compute training accuracy and loss including perturbed edges\n",
    "        y_hat = eval_model(users, items)\n",
    "        perturbations['accuracy_before_eval'].append(get_accuracy(y_hat, ratings_eval))\n",
    "        perturbations['loss_before_eval'].append(loss_fn_eval(y_hat, ratings_eval).item())\n",
    "\n",
    "        # compute training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs_eval)\n",
    "        ratings_masked = torch.masked_select(ratings_eval, perturbs_eval)\n",
    "        perturbations['accuracy_after_eval'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss_after_eval'].append(loss_fn_eval(y_hat_masked, ratings_masked).item())\n",
    "\n",
    "    # baseline select edge and perform perturbation\n",
    "    with torch.no_grad():\n",
    "        best_edge = edges_to_perturb[delta]\n",
    "        ratings[best_edge] = 1 \n",
    "        perturbs[best_edge] = False\n",
    "\n",
    "        # keep track of perturbations and accuracy \n",
    "        perturbations['edges'].append(best_edge)\n",
    "        perturbations['metagrad'].append(-1)\n",
    "\n",
    "sleep(1)\n",
    "# compute execution time\n",
    "exec_time = int(time.time() - start_time)\n",
    "exec_time = time.strftime(\"%Hh %Mm %Ss\", time.gmtime(exec_time))\n",
    "print('-> Execution time: {}'.format(exec_time))\n",
    "\n",
    "# convert results to dataframes for visualisation\n",
    "perturbations = pd.DataFrame(perturbations)\n",
    "filename = 'surrogate{}-target{}-base-Delta={}-T={}-diffinit'.format(surrogate, target, Delta, T)\n",
    "\n",
    "# save results in CSV format\n",
    "if save_results:\n",
    "    perturbations.to_csv('results/' + dataset + '/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edges</th>\n",
       "      <th>metagrad</th>\n",
       "      <th>accuracy_before</th>\n",
       "      <th>accuracy_after</th>\n",
       "      <th>loss_before</th>\n",
       "      <th>loss_after</th>\n",
       "      <th>accuracy_before_eval</th>\n",
       "      <th>accuracy_after_eval</th>\n",
       "      <th>loss_before_eval</th>\n",
       "      <th>loss_after_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136339</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.944992</td>\n",
       "      <td>0.944992</td>\n",
       "      <td>0.155346</td>\n",
       "      <td>0.155346</td>\n",
       "      <td>0.963292</td>\n",
       "      <td>0.963292</td>\n",
       "      <td>0.118882</td>\n",
       "      <td>0.118882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86848</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.942078</td>\n",
       "      <td>0.942084</td>\n",
       "      <td>0.159068</td>\n",
       "      <td>0.159063</td>\n",
       "      <td>0.943790</td>\n",
       "      <td>0.943789</td>\n",
       "      <td>0.141376</td>\n",
       "      <td>0.141374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84965</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.944216</td>\n",
       "      <td>0.944221</td>\n",
       "      <td>0.157931</td>\n",
       "      <td>0.157925</td>\n",
       "      <td>0.963014</td>\n",
       "      <td>0.963014</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.118679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91552</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.943890</td>\n",
       "      <td>0.943901</td>\n",
       "      <td>0.159431</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.958744</td>\n",
       "      <td>0.958743</td>\n",
       "      <td>0.126265</td>\n",
       "      <td>0.126264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42170</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.948581</td>\n",
       "      <td>0.948597</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>0.150563</td>\n",
       "      <td>0.957583</td>\n",
       "      <td>0.957582</td>\n",
       "      <td>0.131985</td>\n",
       "      <td>0.131983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>20460</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.964074</td>\n",
       "      <td>0.965241</td>\n",
       "      <td>0.120208</td>\n",
       "      <td>0.117105</td>\n",
       "      <td>0.937867</td>\n",
       "      <td>0.940518</td>\n",
       "      <td>0.176269</td>\n",
       "      <td>0.170088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>164923</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.962671</td>\n",
       "      <td>0.963833</td>\n",
       "      <td>0.122786</td>\n",
       "      <td>0.119714</td>\n",
       "      <td>0.931897</td>\n",
       "      <td>0.933530</td>\n",
       "      <td>0.185337</td>\n",
       "      <td>0.181016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>69054</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.964341</td>\n",
       "      <td>0.966064</td>\n",
       "      <td>0.119818</td>\n",
       "      <td>0.115596</td>\n",
       "      <td>0.933585</td>\n",
       "      <td>0.936896</td>\n",
       "      <td>0.186099</td>\n",
       "      <td>0.178881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>118656</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.900704</td>\n",
       "      <td>0.898532</td>\n",
       "      <td>0.206747</td>\n",
       "      <td>0.210170</td>\n",
       "      <td>0.932454</td>\n",
       "      <td>0.937511</td>\n",
       "      <td>0.182670</td>\n",
       "      <td>0.172657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>88718</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.962854</td>\n",
       "      <td>0.963692</td>\n",
       "      <td>0.120810</td>\n",
       "      <td>0.118386</td>\n",
       "      <td>0.934722</td>\n",
       "      <td>0.938785</td>\n",
       "      <td>0.182028</td>\n",
       "      <td>0.173523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       edges  metagrad  accuracy_before  accuracy_after  loss_before  \\\n",
       "0     136339        -1         0.944992        0.944992     0.155346   \n",
       "1      86848        -1         0.942078        0.942084     0.159068   \n",
       "2      84965        -1         0.944216        0.944221     0.157931   \n",
       "3      91552        -1         0.943890        0.943901     0.159431   \n",
       "4      42170        -1         0.948581        0.948597     0.150577   \n",
       "...      ...       ...              ...             ...          ...   \n",
       "4995   20460        -1         0.964074        0.965241     0.120208   \n",
       "4996  164923        -1         0.962671        0.963833     0.122786   \n",
       "4997   69054        -1         0.964341        0.966064     0.119818   \n",
       "4998  118656        -1         0.900704        0.898532     0.206747   \n",
       "4999   88718        -1         0.962854        0.963692     0.120810   \n",
       "\n",
       "      loss_after  accuracy_before_eval  accuracy_after_eval  loss_before_eval  \\\n",
       "0       0.155346              0.963292             0.963292          0.118882   \n",
       "1       0.159063              0.943790             0.943789          0.141376   \n",
       "2       0.157925              0.963014             0.963014          0.118680   \n",
       "3       0.159420              0.958744             0.958743          0.126265   \n",
       "4       0.150563              0.957583             0.957582          0.131985   \n",
       "...          ...                   ...                  ...               ...   \n",
       "4995    0.117105              0.937867             0.940518          0.176269   \n",
       "4996    0.119714              0.931897             0.933530          0.185337   \n",
       "4997    0.115596              0.933585             0.936896          0.186099   \n",
       "4998    0.210170              0.932454             0.937511          0.182670   \n",
       "4999    0.118386              0.934722             0.938785          0.182028   \n",
       "\n",
       "      loss_after_eval  \n",
       "0            0.118882  \n",
       "1            0.141374  \n",
       "2            0.118679  \n",
       "3            0.126264  \n",
       "4            0.131983  \n",
       "...               ...  \n",
       "4995         0.170088  \n",
       "4996         0.181016  \n",
       "4997         0.178881  \n",
       "4998         0.172657  \n",
       "4999         0.173523  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbations"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
