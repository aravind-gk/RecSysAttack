{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparams and loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1698, 1397, 168848)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edges = np.load('steam/train_edges.npy')\n",
    "user_list = train_edges[:, 0]\n",
    "item_list = train_edges[:, 1]\n",
    "rating_list = train_edges[:, 2].astype('float32')\n",
    "\n",
    "n_users = user_list.max() + 1 \n",
    "n_items = item_list.max() + 1\n",
    "n_samples = len(rating_list)\n",
    "\n",
    "n_users, n_items, n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        dot = (u * i).sum(1)\n",
    "        return torch.sigmoid(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.fc1 = nn.Linear(n_factors * 2, n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        tanh = nn.Tanh()\n",
    "        sigmoid = nn.Sigmoid()\n",
    "\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        features = torch.concat([u, i], dim = 1)\n",
    "        x = sigmoid(features)\n",
    "        x = self.fc1(features)\n",
    "        x = sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_hat, y):\n",
    "    y = y.clone().int()\n",
    "    y_hat = (y_hat.clone() > 0.5).int()\n",
    "    accuracy = (y == y_hat).sum() / len(y)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Code for surrogate meta-attack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Learning rate:  100\n",
      "-> T:  600\n",
      "-> Delta: 5000 (2.96%)\n",
      "-> Embedding size:  64\n",
      "-> Device:  cuda:6\n",
      "-> Retain graph:  True\n",
      "-> Create graph:  False\n",
      "-> Save results:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-> Perturbations: 100%|██████████| 5000/5000 [4:39:39<00:00,  3.36s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Execution time: 04h 39m 40s\n"
     ]
    }
   ],
   "source": [
    "# start execution\n",
    "start_time = time.time()\n",
    "\n",
    "# GPU settings (set use_gpu = -1 if you want to use CPU)\n",
    "use_gpu = 6\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# some hyperparams\n",
    "lr = 100\n",
    "T = 600\n",
    "Delta = 5000 # 5% ~ 10K perturbations\n",
    "n_factors = 64\n",
    "save_results = True\n",
    "retain_graph = True \n",
    "create_graph = False\n",
    "dataset = 'steam'\n",
    "\n",
    "# list of perturbations\n",
    "perturbations = dict()\n",
    "perturbations['edges'] = []\n",
    "perturbations['metagrad'] = []\n",
    "perturbations['accuracy_before'] = []\n",
    "perturbations['accuracy_after'] = []\n",
    "perturbations['loss_before'] = []\n",
    "perturbations['loss_after'] = []\n",
    "\n",
    "perturbations['accuracy_before_eval'] = []\n",
    "perturbations['accuracy_after_eval'] = []\n",
    "perturbations['loss_before_eval'] = []\n",
    "perturbations['loss_after_eval'] = []\n",
    "\n",
    "# print hyperparam config\n",
    "print('-> Learning rate: ', lr)\n",
    "print('-> T: ', T)\n",
    "print('-> Delta: {} ({}%)'.format(Delta, round(Delta * 100 / n_samples, 2)))\n",
    "print('-> Embedding size: ', n_factors)\n",
    "print('-> Device: ', device)\n",
    "# print('-> Manual gradients: ', manual_gradients)\n",
    "print('-> Retain graph: ', retain_graph)\n",
    "print('-> Create graph: ', create_graph)\n",
    "print('-> Save results: ', save_results)\n",
    "\n",
    "# load users, items and ratings as tensors\n",
    "users = torch.tensor(user_list, device = device)\n",
    "items = torch.tensor(item_list, device = device)\n",
    "ratings = torch.tensor(rating_list, device = device, requires_grad = True)\n",
    "ratings = ratings.reshape((n_samples, 1))\n",
    "perturbs = torch.ones_like(ratings).bool()\n",
    "\n",
    "# for each perturbation do the following\n",
    "for delta in tqdm(range(Delta), desc='-> Perturbations'):\n",
    "\n",
    "    # define model and it's parameters\n",
    "    model = NCF(n_users, n_items, n_factors)\n",
    "    model.to(device)\n",
    "\n",
    "    # makes loss reproducible for each iteration in Delta\n",
    "    torch.manual_seed(53)\n",
    "\n",
    "    # reset model paramters \n",
    "    for layer in model.children():\n",
    "        layer.reset_parameters()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    # define loss function\n",
    "    loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # inner loop training process\n",
    "    model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "\n",
    "        # use torch.optim optimizer to compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer.step()\n",
    "\n",
    "    # compute and store accuracy of model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # compute training accuracy and loss including perturbed edges\n",
    "        y_hat = model(users, items)\n",
    "        perturbations['accuracy_before'].append(get_accuracy(y_hat, ratings))\n",
    "        perturbations['loss_before'].append(loss_fn(y_hat, ratings).item())\n",
    "\n",
    "        # compute training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs)\n",
    "        ratings_masked = torch.masked_select(ratings, perturbs)\n",
    "        perturbations['accuracy_after'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss_after'].append(loss_fn(y_hat_masked, ratings_masked).item())\n",
    "    \n",
    "    # compute meta gradient\n",
    "    meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "\n",
    "    # define evaluation model \n",
    "    eval_model = NCF(n_users, n_items, n_factors)\n",
    "    eval_model.to(device)\n",
    "\n",
    "    torch.manual_seed(50)\n",
    "    # reset eval model parameters\n",
    "    for layer in eval_model.children():\n",
    "        layer.reset_parameters()\n",
    "    optimizer_eval = torch.optim.Adam(eval_model.parameters())\n",
    "    \n",
    "    # define loss function\n",
    "    loss_fn_eval = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # detach ratings and perturbs for eval model\n",
    "    ratings_eval = ratings.detach().clone()\n",
    "    perturbs_eval = perturbs.detach().clone()\n",
    "\n",
    "    # # reshape ratings and perturbs for NCF eval model\n",
    "    # ratings_eval = ratings_eval.reshape((n_samples, 1))\n",
    "    # perturbs_eval = perturbs_eval.reshape((n_samples, 1))\n",
    "\n",
    "    # inner train  evaluation model\n",
    "    eval_model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = eval_model(users, items)\n",
    "        loss_eval = loss_fn_eval(y_hat, ratings_eval)\n",
    "\n",
    "        # use torch.optim optimizer to compute gradients\n",
    "        optimizer_eval.zero_grad()\n",
    "        loss_eval.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer_eval.step()\n",
    "    \n",
    "    eval_model.eval()\n",
    "\n",
    "    # compute and store accuracy of eval model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # compute training accuracy and loss including perturbed edges\n",
    "        y_hat = eval_model(users, items)\n",
    "        perturbations['accuracy_before_eval'].append(get_accuracy(y_hat, ratings_eval))\n",
    "        perturbations['loss_before_eval'].append(loss_fn_eval(y_hat, ratings_eval).item())\n",
    "\n",
    "        # compute training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs_eval)\n",
    "        ratings_masked = torch.masked_select(ratings_eval, perturbs_eval)\n",
    "        perturbations['accuracy_after_eval'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss_after_eval'].append(loss_fn_eval(y_hat_masked, ratings_masked).item())\n",
    "\n",
    "    # select best edge and perform perturbation\n",
    "    with torch.no_grad():\n",
    "        mask = ratings.detach().int()\n",
    "        meta_grad[mask == 1] = 0\n",
    "        best_edge = meta_grad.argmax().item()\n",
    "        ratings[best_edge] = 1\n",
    "        perturbs[best_edge] = False\n",
    "\n",
    "        # keep track of perturbations and accuracy\n",
    "        perturbations['edges'].append(best_edge)\n",
    "        perturbations['metagrad'].append(meta_grad[best_edge].item())\n",
    "\n",
    "sleep(1)\n",
    "# compute execution time\n",
    "exec_time = int(time.time() - start_time)\n",
    "exec_time = time.strftime(\"%Hh %Mm %Ss\", time.gmtime(exec_time))\n",
    "print('-> Execution time: {}'.format(exec_time))\n",
    "\n",
    "# convert results to dataframes for visualisation\n",
    "perturbations = pd.DataFrame(perturbations)\n",
    "filename = 'surrogateNCF_evalNCF_meta_Delta={}_T={}_LR={}_Factors={}_diffinit'.format(Delta, T, lr, n_factors) + '_auto' + ('_r' if retain_graph else '_c')\n",
    "\n",
    "# save results in CSV format\n",
    "if save_results:\n",
    "    perturbations.to_csv('results/' + dataset + '/perturbations_' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edges</th>\n",
       "      <th>metagrad</th>\n",
       "      <th>accuracy_before</th>\n",
       "      <th>accuracy_after</th>\n",
       "      <th>loss_before</th>\n",
       "      <th>loss_after</th>\n",
       "      <th>accuracy_before_eval</th>\n",
       "      <th>accuracy_after_eval</th>\n",
       "      <th>loss_before_eval</th>\n",
       "      <th>loss_after_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157446</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.898927</td>\n",
       "      <td>0.898927</td>\n",
       "      <td>0.286734</td>\n",
       "      <td>0.286734</td>\n",
       "      <td>0.880869</td>\n",
       "      <td>0.880869</td>\n",
       "      <td>0.313807</td>\n",
       "      <td>0.313807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44235</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.898951</td>\n",
       "      <td>0.898956</td>\n",
       "      <td>0.286826</td>\n",
       "      <td>0.286809</td>\n",
       "      <td>0.880887</td>\n",
       "      <td>0.880892</td>\n",
       "      <td>0.313758</td>\n",
       "      <td>0.313744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119655</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.898826</td>\n",
       "      <td>0.898837</td>\n",
       "      <td>0.286868</td>\n",
       "      <td>0.286846</td>\n",
       "      <td>0.880887</td>\n",
       "      <td>0.880897</td>\n",
       "      <td>0.313710</td>\n",
       "      <td>0.313691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48722</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.898814</td>\n",
       "      <td>0.898824</td>\n",
       "      <td>0.286943</td>\n",
       "      <td>0.286919</td>\n",
       "      <td>0.880964</td>\n",
       "      <td>0.880980</td>\n",
       "      <td>0.313784</td>\n",
       "      <td>0.313763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89394</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.899110</td>\n",
       "      <td>0.899126</td>\n",
       "      <td>0.287057</td>\n",
       "      <td>0.287020</td>\n",
       "      <td>0.880958</td>\n",
       "      <td>0.880979</td>\n",
       "      <td>0.313757</td>\n",
       "      <td>0.313726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>147154</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.842503</td>\n",
       "      <td>0.857073</td>\n",
       "      <td>0.399489</td>\n",
       "      <td>0.384072</td>\n",
       "      <td>0.861366</td>\n",
       "      <td>0.869993</td>\n",
       "      <td>0.365352</td>\n",
       "      <td>0.354974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>167255</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.842776</td>\n",
       "      <td>0.857329</td>\n",
       "      <td>0.399723</td>\n",
       "      <td>0.384310</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.870096</td>\n",
       "      <td>0.365472</td>\n",
       "      <td>0.355111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>123825</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.842663</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0.400082</td>\n",
       "      <td>0.384668</td>\n",
       "      <td>0.861485</td>\n",
       "      <td>0.870028</td>\n",
       "      <td>0.365532</td>\n",
       "      <td>0.355172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>121458</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.842788</td>\n",
       "      <td>0.857400</td>\n",
       "      <td>0.399786</td>\n",
       "      <td>0.384389</td>\n",
       "      <td>0.860993</td>\n",
       "      <td>0.869515</td>\n",
       "      <td>0.365537</td>\n",
       "      <td>0.355164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>84546</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.842503</td>\n",
       "      <td>0.857045</td>\n",
       "      <td>0.399731</td>\n",
       "      <td>0.384269</td>\n",
       "      <td>0.861331</td>\n",
       "      <td>0.869838</td>\n",
       "      <td>0.365415</td>\n",
       "      <td>0.355084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       edges  metagrad  accuracy_before  accuracy_after  loss_before  \\\n",
       "0     157446  0.000050         0.898927        0.898927     0.286734   \n",
       "1      44235  0.000050         0.898951        0.898956     0.286826   \n",
       "2     119655  0.000049         0.898826        0.898837     0.286868   \n",
       "3      48722  0.000048         0.898814        0.898824     0.286943   \n",
       "4      89394  0.000046         0.899110        0.899126     0.287057   \n",
       "...      ...       ...              ...             ...          ...   \n",
       "4995  147154  0.000024         0.842503        0.857073     0.399489   \n",
       "4996  167255  0.000024         0.842776        0.857329     0.399723   \n",
       "4997  123825  0.000023         0.842663        0.857285     0.400082   \n",
       "4998  121458  0.000023         0.842788        0.857400     0.399786   \n",
       "4999   84546  0.000023         0.842503        0.857045     0.399731   \n",
       "\n",
       "      loss_after  accuracy_before_eval  accuracy_after_eval  loss_before_eval  \\\n",
       "0       0.286734              0.880869             0.880869          0.313807   \n",
       "1       0.286809              0.880887             0.880892          0.313758   \n",
       "2       0.286846              0.880887             0.880897          0.313710   \n",
       "3       0.286919              0.880964             0.880980          0.313784   \n",
       "4       0.287020              0.880958             0.880979          0.313757   \n",
       "...          ...                   ...                  ...               ...   \n",
       "4995    0.384072              0.861366             0.869993          0.365352   \n",
       "4996    0.384310              0.861538             0.870096          0.365472   \n",
       "4997    0.384668              0.861485             0.870028          0.365532   \n",
       "4998    0.384389              0.860993             0.869515          0.365537   \n",
       "4999    0.384269              0.861331             0.869838          0.365415   \n",
       "\n",
       "      loss_after_eval  \n",
       "0            0.313807  \n",
       "1            0.313744  \n",
       "2            0.313691  \n",
       "3            0.313763  \n",
       "4            0.313726  \n",
       "...               ...  \n",
       "4995         0.354974  \n",
       "4996         0.355111  \n",
       "4997         0.355172  \n",
       "4998         0.355164  \n",
       "4999         0.355084  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbations\n",
    "# don't forget to save the results to csv"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
