{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparams and loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1698, 1397, 168848)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edges = np.load('steam/train_edges.npy')\n",
    "user_list = train_edges[:, 0]\n",
    "item_list = train_edges[:, 1]\n",
    "rating_list = train_edges[:, 2].astype('float32')\n",
    "\n",
    "n_users = user_list.max() + 1 \n",
    "n_items = item_list.max() + 1\n",
    "n_samples = len(rating_list)\n",
    "\n",
    "n_users, n_items, n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        dot = (u * i).sum(1)\n",
    "        return torch.sigmoid(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.fc1 = nn.Linear(n_factors * 2, n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        tanh = nn.Tanh()\n",
    "        sigmoid = nn.Sigmoid()\n",
    "\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        features = torch.concat([u, i], dim = 1)\n",
    "        x = self.fc1(features)\n",
    "        x = sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_hat, y):\n",
    "    y = y.clone().int()\n",
    "    y_hat = (y_hat.clone() > 0.5).int()\n",
    "    accuracy = (y == y_hat).sum() / len(y)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Code for surrogate meta-attack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Learning rate:  60\n",
      "-> T:  400\n",
      "-> Delta: 10000 (5.92%)\n",
      "-> Embedding size:  64\n",
      "-> Device:  cuda:6\n",
      "-> Retain graph:  True\n",
      "-> Create graph:  False\n",
      "-> Save results:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-> Perturbations: 100%|██████████| 10000/10000 [2:46:14<00:00,  1.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Execution time: 02h 46m 15s\n"
     ]
    }
   ],
   "source": [
    "# start execution\n",
    "start_time = time.time()\n",
    "\n",
    "# GPU settings (set use_gpu = -1 if you want to use CPU)\n",
    "use_gpu = 6\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# some hyperparams\n",
    "lr = 60\n",
    "T = 400\n",
    "Delta = 10000 # 5% ~ 10K perturbations\n",
    "n_factors = 64\n",
    "save_results = True\n",
    "retain_graph = True \n",
    "create_graph = False\n",
    "dataset = 'steam'\n",
    "\n",
    "# list of perturbations\n",
    "perturbations = dict()\n",
    "perturbations['edges'] = []\n",
    "perturbations['metagrad'] = []\n",
    "perturbations['accuracy_before'] = []\n",
    "perturbations['accuracy_after'] = []\n",
    "perturbations['loss_before'] = []\n",
    "perturbations['loss_after'] = []\n",
    "\n",
    "perturbations['accuracy_before_eval'] = []\n",
    "perturbations['accuracy_after_eval'] = []\n",
    "perturbations['loss_before_eval'] = []\n",
    "perturbations['loss_after_eval'] = []\n",
    "\n",
    "# print hyperparam config\n",
    "print('-> Learning rate: ', lr)\n",
    "print('-> T: ', T)\n",
    "print('-> Delta: {} ({}%)'.format(Delta, round(Delta * 100 / n_samples, 2)))\n",
    "print('-> Embedding size: ', n_factors)\n",
    "print('-> Device: ', device)\n",
    "# print('-> Manual gradients: ', manual_gradients)\n",
    "print('-> Retain graph: ', retain_graph)\n",
    "print('-> Create graph: ', create_graph)\n",
    "print('-> Save results: ', save_results)\n",
    "\n",
    "# load users, items and ratings as tensors\n",
    "users = torch.tensor(user_list, device = device)\n",
    "items = torch.tensor(item_list, device = device)\n",
    "ratings = torch.tensor(rating_list, device = device, requires_grad = True)\n",
    "perturbs = torch.ones_like(ratings).bool()\n",
    "\n",
    "# define model and it's parameters\n",
    "model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "# for each perturbation do the following\n",
    "for delta in tqdm(range(Delta), desc='-> Perturbations'):\n",
    "\n",
    "    # makes loss reproducible for each iteration in Delta\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # reset model paramters \n",
    "    for layer in model.children():\n",
    "        layer.reset_parameters()\n",
    "    \n",
    "    # define loss function\n",
    "    loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # inner loop training process\n",
    "    model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "\n",
    "        # use torch.optim optimizer to compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer.step()\n",
    "\n",
    "    # compute and store accuracy of model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # compute training accuracy and loss including perturbed edges\n",
    "        y_hat = model(users, items)\n",
    "        perturbations['accuracy_before'].append(get_accuracy(y_hat, ratings))\n",
    "        perturbations['loss_before'].append(loss_fn(y_hat, ratings).item())\n",
    "\n",
    "        # compute training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs)\n",
    "        ratings_masked = torch.masked_select(ratings, perturbs)\n",
    "        perturbations['accuracy_after'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss_after'].append(loss_fn(y_hat_masked, ratings_masked).item())\n",
    "    \n",
    "    # compute meta gradient\n",
    "    meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "\n",
    "    # define evaluation model \n",
    "    eval_model = CollaborativeFiltering(n_users, n_items, n_factors) # experiment with twice the embedding size for evaluation\n",
    "    eval_model.to(device)\n",
    "    optimizer_eval = torch.optim.SGD(eval_model.parameters(), lr = lr)\n",
    "\n",
    "    torch.manual_seed(50)\n",
    "    # reset eval model parameters\n",
    "    for layer in eval_model.children():\n",
    "        layer.reset_parameters()\n",
    "    \n",
    "    # define loss function\n",
    "    loss_fn_eval = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # detach ratings for eval model\n",
    "    ratings_eval = ratings.detach().clone()\n",
    "\n",
    "    # inner train  evaluation model\n",
    "    eval_model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = eval_model(users, items)\n",
    "        loss_eval = loss_fn_eval(y_hat, ratings_eval)\n",
    "\n",
    "        # use torch.optim optimizer to compute gradients\n",
    "        optimizer_eval.zero_grad()\n",
    "        loss_eval.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer_eval.step()\n",
    "\n",
    "    # compute and store accuracy of eval model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # compute training accuracy and loss including perturbed edges\n",
    "        y_hat = eval_model(users, items)\n",
    "        perturbations['accuracy_before_eval'].append(get_accuracy(y_hat, ratings_eval))\n",
    "        perturbations['loss_before_eval'].append(loss_fn_eval(y_hat, ratings_eval).item())\n",
    "\n",
    "        # compute training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs)\n",
    "        ratings_masked = torch.masked_select(ratings_eval, perturbs)\n",
    "        perturbations['accuracy_after_eval'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss_after_eval'].append(loss_fn_eval(y_hat_masked, ratings_masked).item())\n",
    "\n",
    "    # select best edge and perform perturbation\n",
    "    with torch.no_grad():\n",
    "        mask = ratings.detach().int()\n",
    "        meta_grad[mask == 1] = 0\n",
    "        best_edge = meta_grad.argmax().item()\n",
    "        ratings[best_edge] = 1\n",
    "        perturbs[best_edge] = False\n",
    "\n",
    "        # keep track of perturbations and accuracy\n",
    "        perturbations['edges'].append(best_edge)\n",
    "        perturbations['metagrad'].append(meta_grad[best_edge].item())\n",
    "\n",
    "sleep(1)\n",
    "# compute execution time\n",
    "exec_time = int(time.time() - start_time)\n",
    "exec_time = time.strftime(\"%Hh %Mm %Ss\", time.gmtime(exec_time))\n",
    "print('-> Execution time: {}'.format(exec_time))\n",
    "\n",
    "# convert results to dataframes for visualisation\n",
    "perturbations = pd.DataFrame(perturbations)\n",
    "filename = 'surrogate_meta_Delta={}_T={}_LR={}_Factors={}'.format(Delta, T, lr, n_factors) + '_auto' + ('_r' if retain_graph else '_c')\n",
    "\n",
    "# save results in CSV format\n",
    "if save_results:\n",
    "    perturbations.to_csv('results/' + dataset + '/perturbations_' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edges</th>\n",
       "      <th>metagrad</th>\n",
       "      <th>accuracy_before</th>\n",
       "      <th>accuracy_after</th>\n",
       "      <th>loss_before</th>\n",
       "      <th>loss_after</th>\n",
       "      <th>accuracy_before_eval</th>\n",
       "      <th>accuracy_after_eval</th>\n",
       "      <th>loss_before_eval</th>\n",
       "      <th>loss_after_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85658</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.887064</td>\n",
       "      <td>0.887064</td>\n",
       "      <td>0.368369</td>\n",
       "      <td>0.368369</td>\n",
       "      <td>0.887887</td>\n",
       "      <td>0.887887</td>\n",
       "      <td>0.365647</td>\n",
       "      <td>0.365647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105403</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.887017</td>\n",
       "      <td>0.887022</td>\n",
       "      <td>0.368462</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.887958</td>\n",
       "      <td>0.887958</td>\n",
       "      <td>0.365639</td>\n",
       "      <td>0.365641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96880</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.886946</td>\n",
       "      <td>0.886956</td>\n",
       "      <td>0.368539</td>\n",
       "      <td>0.368431</td>\n",
       "      <td>0.887964</td>\n",
       "      <td>0.887963</td>\n",
       "      <td>0.365046</td>\n",
       "      <td>0.365051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124502</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.886958</td>\n",
       "      <td>0.886973</td>\n",
       "      <td>0.368618</td>\n",
       "      <td>0.368445</td>\n",
       "      <td>0.887947</td>\n",
       "      <td>0.887945</td>\n",
       "      <td>0.365048</td>\n",
       "      <td>0.365052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108083</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.886910</td>\n",
       "      <td>0.886931</td>\n",
       "      <td>0.368697</td>\n",
       "      <td>0.368463</td>\n",
       "      <td>0.887982</td>\n",
       "      <td>0.887979</td>\n",
       "      <td>0.365036</td>\n",
       "      <td>0.365043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>154646</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.823001</td>\n",
       "      <td>0.845939</td>\n",
       "      <td>0.460898</td>\n",
       "      <td>0.416443</td>\n",
       "      <td>0.882723</td>\n",
       "      <td>0.880651</td>\n",
       "      <td>0.361893</td>\n",
       "      <td>0.367124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>42828</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.822995</td>\n",
       "      <td>0.845926</td>\n",
       "      <td>0.460911</td>\n",
       "      <td>0.416445</td>\n",
       "      <td>0.882753</td>\n",
       "      <td>0.880675</td>\n",
       "      <td>0.361894</td>\n",
       "      <td>0.367127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>133488</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.822989</td>\n",
       "      <td>0.845919</td>\n",
       "      <td>0.460910</td>\n",
       "      <td>0.416447</td>\n",
       "      <td>0.882788</td>\n",
       "      <td>0.880712</td>\n",
       "      <td>0.361345</td>\n",
       "      <td>0.366547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>8061</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.823012</td>\n",
       "      <td>0.845943</td>\n",
       "      <td>0.460927</td>\n",
       "      <td>0.416462</td>\n",
       "      <td>0.882753</td>\n",
       "      <td>0.880680</td>\n",
       "      <td>0.361336</td>\n",
       "      <td>0.366539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>151434</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.822924</td>\n",
       "      <td>0.845835</td>\n",
       "      <td>0.460932</td>\n",
       "      <td>0.416467</td>\n",
       "      <td>0.882758</td>\n",
       "      <td>0.880685</td>\n",
       "      <td>0.361330</td>\n",
       "      <td>0.366533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       edges  metagrad  accuracy_before  accuracy_after  loss_before  \\\n",
       "0      85658  0.000167         0.887064        0.887064     0.368369   \n",
       "1     105403  0.000159         0.887017        0.887022     0.368462   \n",
       "2      96880  0.000156         0.886946        0.886956     0.368539   \n",
       "3     124502  0.000151         0.886958        0.886973     0.368618   \n",
       "4     108083  0.000150         0.886910        0.886931     0.368697   \n",
       "...      ...       ...              ...             ...          ...   \n",
       "9995  154646  0.000029         0.823001        0.845939     0.460898   \n",
       "9996   42828  0.000029         0.822995        0.845926     0.460911   \n",
       "9997  133488  0.000029         0.822989        0.845919     0.460910   \n",
       "9998    8061  0.000029         0.823012        0.845943     0.460927   \n",
       "9999  151434  0.000029         0.822924        0.845835     0.460932   \n",
       "\n",
       "      loss_after  accuracy_before_eval  accuracy_after_eval  loss_before_eval  \\\n",
       "0       0.368369              0.887887             0.887887          0.365647   \n",
       "1       0.368400              0.887958             0.887958          0.365639   \n",
       "2       0.368431              0.887964             0.887963          0.365046   \n",
       "3       0.368445              0.887947             0.887945          0.365048   \n",
       "4       0.368463              0.887982             0.887979          0.365036   \n",
       "...          ...                   ...                  ...               ...   \n",
       "9995    0.416443              0.882723             0.880651          0.361893   \n",
       "9996    0.416445              0.882753             0.880675          0.361894   \n",
       "9997    0.416447              0.882788             0.880712          0.361345   \n",
       "9998    0.416462              0.882753             0.880680          0.361336   \n",
       "9999    0.416467              0.882758             0.880685          0.361330   \n",
       "\n",
       "      loss_after_eval  \n",
       "0            0.365647  \n",
       "1            0.365641  \n",
       "2            0.365051  \n",
       "3            0.365052  \n",
       "4            0.365043  \n",
       "...               ...  \n",
       "9995         0.367124  \n",
       "9996         0.367127  \n",
       "9997         0.366547  \n",
       "9998         0.366539  \n",
       "9999         0.366533  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbations\n",
    "# don't forget to save the results to csv"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
