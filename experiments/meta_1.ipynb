{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparams and loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges = np.load('data/train_edges.npy')\n",
    "users = torch.LongTensor(train_edges[:, 0])\n",
    "items = torch.LongTensor(train_edges[:, 1])\n",
    "ratings = torch.FloatTensor(train_edges[:, 2])\n",
    "\n",
    "n_users = 943 \n",
    "n_items = 1682\n",
    "n_samples = len(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        dot = (u * i).sum(1)\n",
    "        return torch.sigmoid(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Code for inner loop of meta attack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings:  tensor([1., 1., 0.,  ..., 1., 1., 0.], requires_grad=True)\n",
      "inner loss at iter 0: 4.066596031188965\n",
      "inner loss at iter 1: 4.052426815032959\n",
      "inner loss at iter 2: 4.040399551391602\n",
      "inner loss at iter 3: 4.031717300415039\n",
      "inner loss at iter 4: 4.02053165435791\n",
      "inner loss at iter 5: 4.008946418762207\n",
      "inner loss at iter 6: 3.9973649978637695\n",
      "inner loss at iter 7: 3.9875125885009766\n",
      "inner loss at iter 8: 3.975945234298706\n",
      "inner loss at iter 9: 3.963573694229126\n",
      "inner loss at iter 10: 3.9537487030029297\n",
      "inner loss at iter 11: 3.9422755241394043\n",
      "inner loss at iter 12: 3.9307312965393066\n",
      "inner loss at iter 13: 3.9171624183654785\n",
      "inner loss at iter 14: 3.908663034439087\n",
      "inner loss at iter 15: 3.899308443069458\n",
      "inner loss at iter 16: 3.887892484664917\n",
      "inner loss at iter 17: 3.878131151199341\n",
      "inner loss at iter 18: 3.8646483421325684\n",
      "inner loss at iter 19: 3.854921340942383\n",
      "meta gradients:  tensor([ 5.1595e-06,  2.0629e-05, -9.9811e-06,  ..., -1.5046e-05,\n",
      "        -2.3528e-05,  1.8430e-05])\n"
     ]
    }
   ],
   "source": [
    "# makes code reproducible\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# reload the users, items and ratings tensors\n",
    "users = torch.LongTensor(train_edges[:, 0])\n",
    "items = torch.LongTensor(train_edges[:, 1])\n",
    "ratings = torch.FloatTensor(train_edges[:, 2])\n",
    "ratings.requires_grad_() # set requires_grad = True for ratings\n",
    "print('ratings: ', ratings)\n",
    "\n",
    "lr = 10\n",
    "T = 20\n",
    "\n",
    "# define model and loss function\n",
    "model = CollaborativeFiltering(n_users, n_items, n_factors = 64)\n",
    "p1, p2 = model.parameters()\n",
    "model.train()\n",
    "loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "# for i in tqdm(range(T)):\n",
    "for i in range(T):\n",
    "    y_hat = model(users, items)\n",
    "    loss = loss_fn(y_hat, ratings)\n",
    "    print('inner loss at iter {}: {}'.format(i, loss.item()))\n",
    "    \n",
    "    p1_grad = torch.autograd.grad(loss, p1, create_graph=True)\n",
    "    p2_grad = torch.autograd.grad(loss, p2, create_graph=True)\n",
    "\n",
    "    p1_new = p1 - lr * p1_grad[0]\n",
    "    p2_new = p2 - lr * p2_grad[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        p1.copy_(p1_new)\n",
    "        p2.copy_(p2_new)\n",
    "\n",
    "meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "print('meta gradients: ', meta_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Select edge to perturb (add)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002)\n",
      "141472\n",
      "tensor(13) tensor(1628) tensor(0., grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_meta_grad = -math.inf \n",
    "edge_to_add = -1\n",
    "for i in range(n_samples):\n",
    "    if ratings[i] == 0:\n",
    "        if meta_grad[i] > max_meta_grad:\n",
    "            max_meta_grad = meta_grad[i]\n",
    "            edge_to_add = i \n",
    "print(max_meta_grad)\n",
    "print(edge_to_add)\n",
    "print(users[i], items[i], ratings[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train inner loop for modified ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner loss at iter 0: 4.066789150238037\n",
      "inner loss at iter 1: 4.052619934082031\n",
      "inner loss at iter 2: 4.040592670440674\n",
      "inner loss at iter 3: 4.031909465789795\n",
      "inner loss at iter 4: 4.020724296569824\n",
      "inner loss at iter 5: 4.009138584136963\n",
      "inner loss at iter 6: 3.9975569248199463\n",
      "inner loss at iter 7: 3.987704277038574\n",
      "inner loss at iter 8: 3.9761369228363037\n",
      "inner loss at iter 9: 3.9637649059295654\n",
      "inner loss at iter 10: 3.953939914703369\n",
      "inner loss at iter 11: 3.9424662590026855\n",
      "inner loss at iter 12: 3.930921792984009\n",
      "inner loss at iter 13: 3.9173531532287598\n",
      "inner loss at iter 14: 3.908853530883789\n",
      "inner loss at iter 15: 3.899498462677002\n",
      "inner loss at iter 16: 3.888082265853882\n",
      "inner loss at iter 17: 3.8783206939697266\n",
      "inner loss at iter 18: 3.864837884902954\n",
      "inner loss at iter 19: 3.8551104068756104\n",
      "meta gradients:  tensor([ 5.1595e-06,  2.0629e-05, -9.9811e-06,  ..., -1.5046e-05,\n",
      "        -2.3528e-05,  1.8430e-05])\n"
     ]
    }
   ],
   "source": [
    "ratings_mod = train_edges[:, 2].copy()\n",
    "ratings_mod[edge_to_add] = 1\n",
    "ratings_mod = torch.FloatTensor(ratings_mod)\n",
    "ratings_mod.requires_grad_()\n",
    "\n",
    "# set seed to make results reproducible\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# define model and loss function\n",
    "model = CollaborativeFiltering(n_users, n_items, n_factors = 64)\n",
    "p1, p2 = model.parameters()\n",
    "model.train()\n",
    "loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "# for i in tqdm(range(T)):\n",
    "T = 20\n",
    "for i in range(T):\n",
    "    y_hat = model(users, items)\n",
    "    loss = loss_fn(y_hat, ratings_mod)\n",
    "    print('inner loss at iter {}: {}'.format(i, loss.item()))\n",
    "    \n",
    "    p1_grad = torch.autograd.grad(loss, p1, create_graph=True)\n",
    "    p2_grad = torch.autograd.grad(loss, p2, create_graph=True)\n",
    "\n",
    "    p1_new = p1 - lr * p1_grad[0]\n",
    "    p2_new = p2 - lr * p2_grad[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        p1.copy_(p1_new)\n",
    "        p2.copy_(p2_new)\n",
    "\n",
    "meta_grad = torch.autograd.grad(loss, ratings_mod)[0]\n",
    "print('meta gradients: ', meta_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Putting it together: code for outer loop of meta attack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparams used --\n",
      "learning rate:  50\n",
      "inner loop count T:  10\n",
      "outer loop count Delta:  10\n",
      "embedding size:  64\n",
      "0 edges perturbed in \"rating\"\n",
      "perturbation # 0\n",
      "inner loss at iter 0: 4.066596031188965\n",
      "inner loss at iter 1: 4.008872985839844\n",
      "inner loss at iter 2: 3.953612804412842\n",
      "inner loss at iter 3: 3.8982605934143066\n",
      "inner loss at iter 4: 3.842863082885742\n",
      "inner loss at iter 5: 3.7885544300079346\n",
      "inner loss at iter 6: 3.735943555831909\n",
      "inner loss at iter 7: 3.6827290058135986\n",
      "inner loss at iter 8: 3.6294374465942383\n",
      "inner loss at iter 9: 3.579831838607788\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 100000\n",
      "max meta gradient: 0.00018337038636673242, edge to add: 141472\n",
      "\n",
      "\n",
      "\n",
      "1 edges perturbed in \"rating\"\n",
      "perturbation # 1\n",
      "inner loss at iter 0: 4.066789150238037\n",
      "inner loss at iter 1: 4.0090651512146\n",
      "inner loss at iter 2: 3.953803777694702\n",
      "inner loss at iter 3: 3.8984506130218506\n",
      "inner loss at iter 4: 3.8430519104003906\n",
      "inner loss at iter 5: 3.7887423038482666\n",
      "inner loss at iter 6: 3.7361299991607666\n",
      "inner loss at iter 7: 3.6829142570495605\n",
      "inner loss at iter 8: 3.629621982574463\n",
      "inner loss at iter 9: 3.580014944076538\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 99999\n",
      "max meta gradient: 0.00016918685287237167, edge to add: 152311\n",
      "\n",
      "\n",
      "\n",
      "2 edges perturbed in \"rating\"\n",
      "perturbation # 2\n",
      "inner loss at iter 0: 4.066965103149414\n",
      "inner loss at iter 1: 4.00924015045166\n",
      "inner loss at iter 2: 3.9539780616760254\n",
      "inner loss at iter 3: 3.8986239433288574\n",
      "inner loss at iter 4: 3.8432247638702393\n",
      "inner loss at iter 5: 3.788914442062378\n",
      "inner loss at iter 6: 3.7363011837005615\n",
      "inner loss at iter 7: 3.6830849647521973\n",
      "inner loss at iter 8: 3.6297919750213623\n",
      "inner loss at iter 9: 3.5801844596862793\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 99998\n",
      "max meta gradient: 0.0001663512084633112, edge to add: 173390\n",
      "\n",
      "\n",
      "\n",
      "3 edges perturbed in \"rating\"\n",
      "perturbation # 3\n",
      "inner loss at iter 0: 4.067139148712158\n",
      "inner loss at iter 1: 4.009413242340088\n",
      "inner loss at iter 2: 3.954150676727295\n",
      "inner loss at iter 3: 3.8987953662872314\n",
      "inner loss at iter 4: 3.843395233154297\n",
      "inner loss at iter 5: 3.789083957672119\n",
      "inner loss at iter 6: 3.7364699840545654\n",
      "inner loss at iter 7: 3.683253049850464\n",
      "inner loss at iter 8: 3.6299593448638916\n",
      "inner loss at iter 9: 3.580350637435913\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 99997\n",
      "max meta gradient: 0.00015842821449041367, edge to add: 112886\n",
      "\n",
      "\n",
      "\n",
      "4 edges perturbed in \"rating\"\n",
      "perturbation # 4\n",
      "inner loss at iter 0: 4.067302703857422\n",
      "inner loss at iter 1: 4.009576320648193\n",
      "inner loss at iter 2: 3.954313039779663\n",
      "inner loss at iter 3: 3.8989572525024414\n",
      "inner loss at iter 4: 3.8435566425323486\n",
      "inner loss at iter 5: 3.7892448902130127\n",
      "inner loss at iter 6: 3.7366299629211426\n",
      "inner loss at iter 7: 3.683412790298462\n",
      "inner loss at iter 8: 3.6301181316375732\n",
      "inner loss at iter 9: 3.5805089473724365\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 99996\n",
      "max meta gradient: 0.00015628323308192194, edge to add: 55242\n",
      "\n",
      "\n",
      "\n",
      "5 edges perturbed in \"rating\"\n",
      "perturbation # 5\n",
      "inner loss at iter 0: 4.067464828491211\n",
      "inner loss at iter 1: 4.009737491607666\n",
      "inner loss at iter 2: 3.9544737339019775\n",
      "inner loss at iter 3: 3.8991172313690186\n",
      "inner loss at iter 4: 3.8437159061431885\n",
      "inner loss at iter 5: 3.7894034385681152\n",
      "inner loss at iter 6: 3.736788034439087\n",
      "inner loss at iter 7: 3.683570384979248\n",
      "inner loss at iter 8: 3.630274772644043\n",
      "inner loss at iter 9: 3.580665111541748\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 99995\n",
      "max meta gradient: 0.0001530579902464524, edge to add: 140270\n",
      "\n",
      "\n",
      "\n",
      "6 edges perturbed in \"rating\"\n",
      "perturbation # 6\n",
      "inner loss at iter 0: 4.067622184753418\n",
      "inner loss at iter 1: 4.009894371032715\n",
      "inner loss at iter 2: 3.954629898071289\n",
      "inner loss at iter 3: 3.899273157119751\n",
      "inner loss at iter 4: 3.843871593475342\n",
      "inner loss at iter 5: 3.7895586490631104\n",
      "inner loss at iter 6: 3.7369425296783447\n",
      "inner loss at iter 7: 3.6837244033813477\n",
      "inner loss at iter 8: 3.6304285526275635\n",
      "inner loss at iter 9: 3.5808181762695312\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 99994\n",
      "max meta gradient: 0.00015289403381757438, edge to add: 109884\n",
      "\n",
      "\n",
      "\n",
      "7 edges perturbed in \"rating\"\n",
      "perturbation # 7\n",
      "inner loss at iter 0: 4.067781925201416\n",
      "inner loss at iter 1: 4.0100531578063965\n",
      "inner loss at iter 2: 3.9547882080078125\n",
      "inner loss at iter 3: 3.899430513381958\n",
      "inner loss at iter 4: 3.8440277576446533\n",
      "inner loss at iter 5: 3.7897143363952637\n",
      "inner loss at iter 6: 3.7370975017547607\n",
      "inner loss at iter 7: 3.6838786602020264\n",
      "inner loss at iter 8: 3.6305816173553467\n",
      "inner loss at iter 9: 3.5809710025787354\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 99993\n",
      "max meta gradient: 0.00015228013216983527, edge to add: 179043\n",
      "\n",
      "\n",
      "\n",
      "8 edges perturbed in \"rating\"\n",
      "perturbation # 8\n",
      "inner loss at iter 0: 4.067943096160889\n",
      "inner loss at iter 1: 4.010213375091553\n",
      "inner loss at iter 2: 3.954946756362915\n",
      "inner loss at iter 3: 3.8995888233184814\n",
      "inner loss at iter 4: 3.844184637069702\n",
      "inner loss at iter 5: 3.7898707389831543\n",
      "inner loss at iter 6: 3.7372524738311768\n",
      "inner loss at iter 7: 3.6840322017669678\n",
      "inner loss at iter 8: 3.63073468208313\n",
      "inner loss at iter 9: 3.581123113632202\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 99992\n",
      "max meta gradient: 0.00015204312512651086, edge to add: 5665\n",
      "\n",
      "\n",
      "\n",
      "9 edges perturbed in \"rating\"\n",
      "perturbation # 9\n",
      "inner loss at iter 0: 4.068107604980469\n",
      "inner loss at iter 1: 4.010376453399658\n",
      "inner loss at iter 2: 3.955108642578125\n",
      "inner loss at iter 3: 3.8997488021850586\n",
      "inner loss at iter 4: 3.844343423843384\n",
      "inner loss at iter 5: 3.790027618408203\n",
      "inner loss at iter 6: 3.737408399581909\n",
      "inner loss at iter 7: 3.6841869354248047\n",
      "inner loss at iter 8: 3.630887746810913\n",
      "inner loss at iter 9: 3.58127498626709\n",
      "meta gradients:  tensor([ 3.9364e-06,  1.9463e-05, -8.3421e-06,  ..., -1.4434e-05,\n",
      "        -2.3683e-05,  1.8197e-05])\n",
      "edges searched: 99991\n",
      "max meta gradient: 0.00015154418360907584, edge to add: 195865\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# some hyperparams\n",
    "lr = 50\n",
    "T = 10\n",
    "Delta = 10\n",
    "n_factors = 64\n",
    "\n",
    "print('hyperparams used --')\n",
    "print('learning rate: ', lr)\n",
    "print('inner loop count T: ', T)\n",
    "print('outer loop count Delta: ', Delta)\n",
    "print('embedding size: ', n_factors)\n",
    "\n",
    "# list of perturbations\n",
    "edges_to_add = []\n",
    "\n",
    "for delta in range(Delta):\n",
    "    # reload the users, items and ratings tensors\n",
    "    users = torch.LongTensor(train_edges[:, 0])\n",
    "    items = torch.LongTensor(train_edges[:, 1])\n",
    "    ratings = torch.FloatTensor(train_edges[:, 2])\n",
    "\n",
    "    # add those perturbations to \"ratings\"\n",
    "    for index in edges_to_add:\n",
    "        ratings[index] = 1\n",
    "    print('{} edges perturbed in \"rating\"'.format(len(edges_to_add)))\n",
    "\n",
    "    # set requires_grad for ratings, to compute meta gradients\n",
    "    ratings.requires_grad_()\n",
    "\n",
    "    # makes code reproducible\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # define model and loss\n",
    "    model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    p1, p2 = model.parameters()\n",
    "    loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "    model.train()\n",
    "\n",
    "    print('perturbation #', delta)\n",
    "    # inner loop training process\n",
    "    for i in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        # if i % 5 == 0:\n",
    "        print('inner loss at iter {}: {}'.format(i, loss.item()))\n",
    "        \n",
    "        p1_grad = torch.autograd.grad(loss, p1, create_graph=True)\n",
    "        p2_grad = torch.autograd.grad(loss, p2, create_graph=True)\n",
    "\n",
    "        p1_new = p1 - lr * p1_grad[0]\n",
    "        p2_new = p2 - lr * p2_grad[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            p1.copy_(p1_new)\n",
    "            p2.copy_(p2_new)\n",
    "    \n",
    "    # compute meta gradient\n",
    "    meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "    print('meta gradients: ', meta_grad)\n",
    "\n",
    "    # select best edge to perturb\n",
    "    max_meta_grad = -math.inf\n",
    "    edge_to_add = -1\n",
    "    search_space = 0\n",
    "    for i in range(n_samples):\n",
    "        if ratings[i] == 0: # search over only negative edges\n",
    "            if meta_grad[i] > max_meta_grad:\n",
    "                max_meta_grad = meta_grad[i]\n",
    "                edge_to_add = i \n",
    "            search_space += 1\n",
    "    print('edges searched: {}'.format(search_space))\n",
    "    print('max meta gradient: {}, edge to add: {}'.format(max_meta_grad, edge_to_add))\n",
    "    edges_to_add.append(edge_to_add)\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f08714d2ad0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = torch.FloatTensor(train_edges[:, 2])\n",
    "ratings[2] = 1\n",
    "ratings"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
