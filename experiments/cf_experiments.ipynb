{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# from cf import CollaborativeFiltering\n",
    "from cf_bce import CollaborativeFiltering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparams and loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges = np.load('train_edges.npy')\n",
    "train_edges.shape\n",
    "users = torch.LongTensor(train_edges[:, 0])\n",
    "items = torch.LongTensor(train_edges[:, 1])\n",
    "ratings = torch.FloatTensor(train_edges[:, 2])\n",
    "\n",
    "# some hyperparams\n",
    "epochs = 100\n",
    "lr = 0.01\n",
    "n_users = 943 \n",
    "n_items = 1682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MSE Collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.57it/s]\n"
     ]
    }
   ],
   "source": [
    "model = CollaborativeFiltering(n_users, n_items, n_factors = 32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "model.train()\n",
    "losses = []\n",
    "\n",
    "for _ in tqdm(range(epochs)):\n",
    "    y_hat = model(users, items)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting value using trained model\n",
    "user = 229\n",
    "item = 818\n",
    "\n",
    "user = torch.LongTensor([user])\n",
    "item = torch.LongTensor([item])\n",
    "\n",
    "model.eval()\n",
    "y_hat = model(user, item)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Understanding how F.nll_loss and nn.BCELoss work**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(100.)\n",
      "tensor(100.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "one = torch.tensor([1])\n",
    "onef = torch.tensor([1.])\n",
    "zero = torch.tensor([0])\n",
    "# zerof = torch.tensor([0.01])\n",
    "zerof = torch.tensor([0.])\n",
    "# print(F.nll_loss(zerof, zero))\n",
    "# print(F.nll_loss(zerof, one))\n",
    "# print(F.nll_loss(onef, zero))\n",
    "# print(F.nll_loss(onef, one))\n",
    "loss = nn.BCELoss()\n",
    "print(loss(zerof, zerof))\n",
    "print(loss(zerof, onef))\n",
    "print(loss(onef, zerof))\n",
    "print(loss(onef, onef))\n",
    "# note: Binary cross entropy BCELoss is  better suited for this problem\n",
    "# loss(y_hat, y) -> position of arguments y_hat and y\n",
    "# gradients are clamped to [-100, 100] to get finite losses\n",
    "# BCELoss supports only float y_hat's and y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if reduction='sum' is not used, the loss will be averaged\n",
    "loss_fn = nn.BCELoss(reduction = 'sum')\n",
    "x1 = torch.tensor([1., 1, 0, 1, 1], requires_grad=True)\n",
    "x2 = torch.tensor([1., 1, 1, 0, 1])\n",
    "# loss(x1, x2).backward()\n",
    "loss = loss_fn(x1, x2)\n",
    "loss.backward()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Sigmoid NCF Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:21<00:00,  9.34it/s]\n"
     ]
    }
   ],
   "source": [
    "model = CollaborativeFiltering(n_users, n_items, n_factors = 64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "losses = []\n",
    "model.train()\n",
    "loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "epochs = 200\n",
    "n_samples = len(ratings)\n",
    "\n",
    "for _ in tqdm(range(epochs)):\n",
    "    y_hat = model(users, items)\n",
    "    # loss = loss_fn(y_hat, ratings.reshape((-1, 1)))\n",
    "    loss = loss_fn(y_hat, ratings)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_hat, y):\n",
    "    y = y.clone().int()\n",
    "    y_hat = (y_hat.clone() > 0.5).int()\n",
    "    accuracy = (y == y_hat).sum() / len(y)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9840800166130066"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(users, items)\n",
    "get_accuracy(y_hat, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.054061412811279,\n",
       " 3.94698166847229,\n",
       " 3.840118169784546,\n",
       " 3.742799758911133,\n",
       " 3.638658046722412,\n",
       " 3.540802478790283,\n",
       " 3.448302745819092,\n",
       " 3.351581573486328,\n",
       " 3.263144016265869,\n",
       " 3.1771671772003174,\n",
       " 3.094047784805298,\n",
       " 3.0049450397491455,\n",
       " 2.9228687286376953,\n",
       " 2.8485872745513916,\n",
       " 2.7708237171173096,\n",
       " 2.6924474239349365,\n",
       " 2.6185224056243896,\n",
       " 2.545653820037842,\n",
       " 2.471665382385254,\n",
       " 2.4020462036132812,\n",
       " 2.3409500122070312,\n",
       " 2.27826189994812,\n",
       " 2.2160863876342773,\n",
       " 2.15813946723938,\n",
       " 2.0973310470581055,\n",
       " 2.0411341190338135,\n",
       " 1.9861838817596436,\n",
       " 1.9358195066452026,\n",
       " 1.885769009590149,\n",
       " 1.834368109703064,\n",
       " 1.7865874767303467,\n",
       " 1.7361736297607422,\n",
       " 1.689346194267273,\n",
       " 1.6427218914031982,\n",
       " 1.598846197128296,\n",
       " 1.5547336339950562,\n",
       " 1.5128867626190186,\n",
       " 1.469881534576416,\n",
       " 1.4300044775009155,\n",
       " 1.3910809755325317,\n",
       " 1.3510043621063232,\n",
       " 1.3140119314193726,\n",
       " 1.2771203517913818,\n",
       " 1.2412101030349731,\n",
       " 1.2049938440322876,\n",
       " 1.1701903343200684,\n",
       " 1.135968565940857,\n",
       " 1.1019337177276611,\n",
       " 1.070609211921692,\n",
       " 1.0403317213058472,\n",
       " 1.0094743967056274,\n",
       " 0.9805383682250977,\n",
       " 0.9523451328277588,\n",
       " 0.9236199259757996,\n",
       " 0.8952299952507019,\n",
       " 0.8684694766998291,\n",
       " 0.8416606187820435,\n",
       " 0.8168993592262268,\n",
       " 0.7921164631843567,\n",
       " 0.769383430480957,\n",
       " 0.7470420598983765,\n",
       " 0.7267488241195679,\n",
       " 0.7072232961654663,\n",
       " 0.6868011951446533,\n",
       " 0.6679556369781494,\n",
       " 0.649813711643219,\n",
       " 0.6327934861183167,\n",
       " 0.6164364218711853,\n",
       " 0.6007134914398193,\n",
       " 0.5864380598068237,\n",
       " 0.5727285146713257,\n",
       " 0.5591393113136292,\n",
       " 0.5456469655036926,\n",
       " 0.5334948301315308,\n",
       " 0.5197041630744934,\n",
       " 0.5080364942550659,\n",
       " 0.49678632616996765,\n",
       " 0.48593151569366455,\n",
       " 0.47461599111557007,\n",
       " 0.46490657329559326,\n",
       " 0.45510151982307434,\n",
       " 0.4452192187309265,\n",
       " 0.4364689886569977,\n",
       " 0.42759114503860474,\n",
       " 0.41856616735458374,\n",
       " 0.41022989153862,\n",
       " 0.4025556147098541,\n",
       " 0.3947090208530426,\n",
       " 0.38750872015953064,\n",
       " 0.3796764016151428,\n",
       " 0.3728971481323242,\n",
       " 0.36589962244033813,\n",
       " 0.35951319336891174,\n",
       " 0.3528927266597748,\n",
       " 0.3468600809574127,\n",
       " 0.3405844569206238,\n",
       " 0.3348906338214874,\n",
       " 0.32935231924057007,\n",
       " 0.32354211807250977,\n",
       " 0.3178815543651581,\n",
       " 0.3123556077480316,\n",
       " 0.3069709241390228,\n",
       " 0.30212852358818054,\n",
       " 0.29699379205703735,\n",
       " 0.29198065400123596,\n",
       " 0.28750133514404297,\n",
       " 0.2831268310546875,\n",
       " 0.2784475088119507,\n",
       " 0.27428925037384033,\n",
       " 0.2698090672492981,\n",
       " 0.26584482192993164,\n",
       " 0.2615571916103363,\n",
       " 0.2573601305484772,\n",
       " 0.2536667287349701,\n",
       " 0.25006064772605896,\n",
       " 0.24611498415470123,\n",
       " 0.24267303943634033,\n",
       " 0.23888303339481354,\n",
       " 0.23558877408504486,\n",
       " 0.23236589133739471,\n",
       " 0.2292163074016571,\n",
       " 0.22613300383090973,\n",
       " 0.22311334311962128,\n",
       " 0.2201593518257141,\n",
       " 0.21684415638446808,\n",
       " 0.21317189931869507,\n",
       " 0.2099786102771759,\n",
       " 0.20726075768470764,\n",
       " 0.2045990377664566,\n",
       " 0.2019888013601303,\n",
       " 0.199429452419281,\n",
       " 0.196495920419693,\n",
       " 0.1940375566482544,\n",
       " 0.19162650406360626,\n",
       " 0.18926280736923218,\n",
       " 0.18694338202476501,\n",
       " 0.18466921150684357,\n",
       " 0.18243740499019623,\n",
       " 0.18024694919586182,\n",
       " 0.17809656262397766,\n",
       " 0.1755649745464325,\n",
       " 0.1734912097454071,\n",
       " 0.17145085334777832,\n",
       " 0.1694498211145401,\n",
       " 0.16748356819152832,\n",
       " 0.16513097286224365,\n",
       " 0.16322632133960724,\n",
       " 0.16093747317790985,\n",
       " 0.1590997278690338,\n",
       " 0.15729433298110962,\n",
       " 0.15551583468914032,\n",
       " 0.15377052128314972,\n",
       " 0.15205146372318268,\n",
       " 0.1503593623638153,\n",
       " 0.14869637787342072,\n",
       " 0.14705988764762878,\n",
       " 0.14545069634914398,\n",
       " 0.14386677742004395,\n",
       " 0.14230775833129883,\n",
       " 0.14077365398406982,\n",
       " 0.1392630785703659,\n",
       " 0.1377757489681244,\n",
       " 0.13631084561347961,\n",
       " 0.13486787676811218,\n",
       " 0.13344606757164001,\n",
       " 0.13204552233219147,\n",
       " 0.13066552579402924,\n",
       " 0.1293056160211563,\n",
       " 0.12796539068222046,\n",
       " 0.12664446234703064,\n",
       " 0.12534189224243164,\n",
       " 0.12405826896429062,\n",
       " 0.12279273569583893,\n",
       " 0.12154494225978851,\n",
       " 0.12031418085098267,\n",
       " 0.11910084635019302,\n",
       " 0.11790446937084198,\n",
       " 0.11672478169202805,\n",
       " 0.11556130647659302,\n",
       " 0.11441446095705032,\n",
       " 0.1132836788892746,\n",
       " 0.1121683269739151,\n",
       " 0.11106862127780914,\n",
       " 0.10998355597257614,\n",
       " 0.10891318321228027,\n",
       " 0.10785666853189468,\n",
       " 0.10681413859128952,\n",
       " 0.10578474402427673,\n",
       " 0.10476884990930557,\n",
       " 0.10376560688018799,\n",
       " 0.10277532041072845,\n",
       " 0.10179731249809265,\n",
       " 0.10083157569169998,\n",
       " 0.09987793862819672,\n",
       " 0.09893639385700226,\n",
       " 0.09800631552934647,\n",
       " 0.09708775579929352,\n",
       " 0.09618055820465088,\n",
       " 0.09528443217277527,\n",
       " 0.09439931809902191]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses\n",
    "# I can't get the BCE loss less than approx 0.463\n",
    "# thinking to try different n_samples and weight_initialisations\n",
    "# Seems it's not a good value for BCE loss \n",
    "# reference: https://medium.com/swlh/cross-entropy-loss-in-pytorch-c010faf97bab\n",
    "# now getting loss = 0.088 (~98.5% acc) using cf_bce.CollaborativeFiltering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0130], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Predicting value using trained model\n",
    "user = 229\n",
    "item = 818\n",
    "\n",
    "user = torch.LongTensor([user])\n",
    "item = torch.LongTensor([item])\n",
    "\n",
    "model.eval()\n",
    "y_hat = model(user, item)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(943, 64)\n",
      "Embedding(1682, 64)\n",
      "Linear(in_features=128, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.children():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Use mini-batch gradient descent (different ways to do that)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 710, 1346,    0],\n",
      "        [ 654, 1606,    1],\n",
      "        [ 428,   41,    1],\n",
      "        [ 270,  222,    0],\n",
      "        [ 502, 1017,    0],\n",
      "        [ 379,    6,    1],\n",
      "        [ 458,  171,    1],\n",
      "        [ 822, 1395,    0]], dtype=torch.int32)\n",
      "tensor([[ 710, 1346],\n",
      "        [ 654, 1606],\n",
      "        [ 428,   41],\n",
      "        [ 270,  222],\n",
      "        [ 502, 1017],\n",
      "        [ 379,    6],\n",
      "        [ 458,  171],\n",
      "        [ 822, 1395]], dtype=torch.int32)\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.tensor(train_edges)\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "minibatch = next(iter(train_loader))\n",
    "print(minibatch)\n",
    "print(minibatch[:, :2])\n",
    "print(minibatch[:, 2].)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[541, 731],\n",
      "        [845, 174],\n",
      "        [229, 818],\n",
      "        [822, 502],\n",
      "        [166, 654],\n",
      "        [313, 716],\n",
      "        [278, 860],\n",
      "        [404, 925]], dtype=torch.int32)\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "X_tensor = torch.tensor(train_edges[:, :2])\n",
    "y_tensor = torch.tensor(train_edges[:, 2])\n",
    "train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 8)\n",
    "X_batch, y_batch = next(iter(train_loader))\n",
    "print(X_batch)\n",
    "print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([541, 845, 229, 822, 166, 313, 278, 404])\n",
      "tensor([731, 174, 818, 502, 654, 716, 860, 925])\n",
      "tensor([1., 1., 0., 1., 1., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(users, items, ratings)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 8)\n",
    "user_batch, item_batch, rating_batch = next(iter(train_loader))\n",
    "print(user_batch)\n",
    "print(item_batch)\n",
    "print(rating_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Collaborative filtering with minibatch training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:28<00:00,  4.42s/it]\n"
     ]
    }
   ],
   "source": [
    "model = CollaborativeFiltering(n_users, n_items, n_factors = 64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_dataset = TensorDataset(users, items, ratings)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 2048, shuffle = True)\n",
    "\n",
    "losses = []\n",
    "model.train()\n",
    "loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "epochs = 20\n",
    "n_samples = len(ratings)\n",
    "\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for user_batch, item_batch, rating_batch in train_loader:\n",
    "        y_hat = model(user_batch, item_batch)\n",
    "        loss = loss_fn(y_hat, rating_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References for minibatch code:\n",
    "- https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\n",
    "- https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful PyTorch tutorial links:\n",
    "- https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.184617519378662,\n",
       " 1.9821864366531372,\n",
       " 1.3081116676330566,\n",
       " 0.8630186915397644,\n",
       " 0.5753305554389954,\n",
       " 0.4868320822715759,\n",
       " 0.37049880623817444,\n",
       " 0.3189575970172882,\n",
       " 0.28166326880455017,\n",
       " 0.25819700956344604,\n",
       " 0.2314123809337616,\n",
       " 0.208090141415596,\n",
       " 0.197652205824852,\n",
       " 0.24252861738204956,\n",
       " 0.13589927554130554,\n",
       " 0.14347687363624573,\n",
       " 0.11966618150472641,\n",
       " 0.11535950750112534,\n",
       " 0.10997869074344635,\n",
       " 0.09858120232820511]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
