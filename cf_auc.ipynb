{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682, 159619, 40381)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'movielens'\n",
    "\n",
    "train_edges = np.load('data/' + dataset + '/train_edges.npy')\n",
    "test_edges = np.load('data/' + dataset + '/test_edges.npy')\n",
    "\n",
    "user_list_train = train_edges[:, 0]\n",
    "user_list_test = test_edges[:, 0]\n",
    "item_list_train = train_edges[:, 1]\n",
    "item_list_test = test_edges[:, 1]\n",
    "rating_list_train = train_edges[:, 2].astype('float32')\n",
    "rating_list_test = test_edges[:, 2].astype('float32')\n",
    "\n",
    "n_users = max(user_list_train.max(), user_list_test.max()) + 1 \n",
    "n_items = max(item_list_train.max(), item_list_test.max()) + 1\n",
    "n_samples_train = len(rating_list_train)\n",
    "n_samples_test = len(rating_list_test)\n",
    "\n",
    "n_users, n_items, n_samples_train, n_samples_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        drop_u = nn.Dropout(p = 0.3)\n",
    "        drop_i = nn.Dropout(p = 0.3)\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        u = drop_u(u)\n",
    "        i = drop_i(i)\n",
    "        dot = (u * i).sum(1)\n",
    "        return torch.sigmoid(dot)\n",
    "\n",
    "class CF1(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CF1, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.fc = nn.Linear(n_factors * 3, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        drop_u = nn.Dropout(p = 0.3)\n",
    "        drop_i = nn.Dropout(p = 0.3)\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        u = drop_u(u)\n",
    "        i = drop_i(i)\n",
    "        dot = (u * i)\n",
    "        x = torch.concat([u, i, dot], dim = 1)\n",
    "        # x = torch.sigmoid(x)\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "class CF2(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CF2, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        drop_u = nn.Dropout(p = 0.3)\n",
    "        drop_i = nn.Dropout(p = 0.3)\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        u = drop_u(u)\n",
    "        i = drop_i(i)\n",
    "        dot = (u * i)\n",
    "        sum = u + i + dot\n",
    "        return torch.sigmoid(sum.sum(dim = 1))\n",
    "\n",
    "class CF4(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CF4, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.item_bias = nn.Embedding(n_items, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        drop_u = nn.Dropout(p = 0.2)\n",
    "        drop_i = nn.Dropout(p = 0.2)\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        u = drop_u(u)\n",
    "        i = drop_i(i)\n",
    "        dot = (u * i)\n",
    "        bias_u = self.user_bias(user).squeeze()\n",
    "        bias_i = self.item_bias(item).squeeze()\n",
    "        total = dot.sum(dim = 1) + bias_u + bias_i\n",
    "        # total = dot.sum(dim = 1)\n",
    "        return torch.sigmoid(total)\n",
    "\n",
    "class NCF(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.fc1 = nn.Linear(n_factors * 2, n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        tanh = nn.Tanh()\n",
    "        sigmoid = nn.Sigmoid()\n",
    "        swish = nn.SiLU()\n",
    "\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        x = torch.concat([u, i], dim = 1)\n",
    "        x = swish(x)\n",
    "        x = self.fc1(x)\n",
    "        x = swish(x)\n",
    "        x = self.fc2(x)\n",
    "        x = sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class GMF(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(GMF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.h = nn.Linear(n_factors, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        dot = (u * i)\n",
    "        x = self.h(dot)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "class GMFD(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(GMFD, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.h = nn.Linear(n_factors, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        drop_u = nn.Dropout(p = 0.2)\n",
    "        drop_i = nn.Dropout(p = 0.2)\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        u = drop_u(u)\n",
    "        i = drop_i(i)\n",
    "        dot = (u * i)\n",
    "        x = self.h(dot)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "def get_accuracy(y_hat, y):\n",
    "    y = y.clone().int()\n",
    "    y_hat = (y_hat.clone() > 0.5).int()\n",
    "    accuracy = (y == y_hat).sum() / len(y)\n",
    "    return accuracy.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test collaborative filtering on unseen data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = 6\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "users = torch.tensor(user_list_train, device = device)\n",
    "items = torch.tensor(item_list_train, device = device)\n",
    "ratings = torch.tensor(rating_list_train, device = device, requires_grad = True)\n",
    "\n",
    "users_test = torch.tensor(user_list_test, device = device)\n",
    "items_test = torch.tensor(item_list_test, device = device)\n",
    "ratings_test = torch.tensor(rating_list_test, device = device)\n",
    "\n",
    "ratings = ratings.reshape((n_samples_train, 1))\n",
    "ratings_test = ratings_test.reshape((n_samples_test, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#:  0 train loss:0.7562330365180969, train auc: 0.5009421490944372 test loss:0.9416249990463257, test auc: 0.49466115622393403\n",
      "#:  1 train loss:1.026253342628479, train auc: 0.4275177886245745 test loss:0.7245694994926453, test auc: 0.5243123092586233\n",
      "#:  2 train loss:0.7380927205085754, train auc: 0.4929121450281968 test loss:0.6897484064102173, test auc: 0.5958933737304353\n",
      "#:  3 train loss:0.6748147010803223, train auc: 0.6277720195556337 test loss:0.6480313539505005, test auc: 0.698458678425985\n",
      "#:  4 train loss:0.6233042478561401, train auc: 0.7290074899678468 test loss:0.5917366743087769, test auc: 0.7865492860997988\n",
      "#:  5 train loss:0.5584977269172668, train auc: 0.8078740382320803 test loss:0.5889905691146851, test auc: 0.8176463937000148\n",
      "#:  6 train loss:0.5436345338821411, train auc: 0.8394385306114118 test loss:0.5405320525169373, test auc: 0.8246116223443403\n",
      "#:  7 train loss:0.48796406388282776, train auc: 0.8528487489638152 test loss:0.5413393378257751, test auc: 0.8003524790245817\n",
      "#:  8 train loss:0.4876677989959717, train auc: 0.8431048974648011 test loss:0.5387145280838013, test auc: 0.8092996025710221\n",
      "#:  9 train loss:0.4772290587425232, train auc: 0.8495954883570505 test loss:0.524084746837616, test auc: 0.8337481882635789\n",
      "#:  10 train loss:0.4579562246799469, train auc: 0.8666204821556414 test loss:0.5260593295097351, test auc: 0.8352634831460675\n",
      "#:  11 train loss:0.45248958468437195, train auc: 0.8708592817826146 test loss:0.5165143013000488, test auc: 0.843626930719788\n",
      "#:  12 train loss:0.43815746903419495, train auc: 0.8807416708009395 test loss:0.5066099166870117, test auc: 0.8417460134438939\n",
      "#:  13 train loss:0.43268799781799316, train auc: 0.880503509291124 test loss:0.48460832238197327, test auc: 0.8531195353515529\n",
      "#:  14 train loss:0.42069870233535767, train auc: 0.8869179818102464 test loss:0.5109050869941711, test auc: 0.8549861071586281\n",
      "#:  15 train loss:0.417135089635849, train auc: 0.8939652250091059 test loss:0.48945069313049316, test auc: 0.8578919103576861\n",
      "#:  16 train loss:0.40119969844818115, train auc: 0.8988923786250769 test loss:0.4707011580467224, test auc: 0.8614848449536333\n",
      "#:  17 train loss:0.40102896094322205, train auc: 0.8985082488162375 test loss:0.4841378927230835, test auc: 0.8623998540307148\n",
      "#:  18 train loss:0.3933916687965393, train auc: 0.903336651976915 test loss:0.4846552908420563, test auc: 0.8621571291889504\n",
      "#:  19 train loss:0.3852897882461548, train auc: 0.9067217356252903 test loss:0.48282018303871155, test auc: 0.8617199217408371\n",
      "#:  20 train loss:0.38634008169174194, train auc: 0.9057198475709316 test loss:0.47696560621261597, test auc: 0.8623284308915168\n",
      "#:  21 train loss:0.3826797604560852, train auc: 0.9077100564092742 test loss:0.505465567111969, test auc: 0.8654363635248515\n",
      "#:  22 train loss:0.3855447471141815, train auc: 0.9111358744457981 test loss:0.4836641848087311, test auc: 0.8602736323045974\n",
      "#:  23 train loss:0.37671616673469543, train auc: 0.9102203134616108 test loss:0.49027350544929504, test auc: 0.8642556486433443\n",
      "#:  24 train loss:0.3692866265773773, train auc: 0.9148736855367439 test loss:0.4831979274749756, test auc: 0.8635168195868701\n",
      "#:  25 train loss:0.36475852131843567, train auc: 0.9160139247541416 test loss:0.4792141020298004, test auc: 0.8646479723762328\n",
      "#:  26 train loss:0.363951712846756, train auc: 0.9164280419089665 test loss:0.5107031464576721, test auc: 0.8673613426720965\n",
      "#:  27 train loss:0.3611433207988739, train auc: 0.9202289234510607 test loss:0.49933886528015137, test auc: 0.8600002956184682\n",
      "#:  28 train loss:0.35833221673965454, train auc: 0.9192209666505482 test loss:0.48143744468688965, test auc: 0.864765167312693\n",
      "#:  29 train loss:0.353042334318161, train auc: 0.9213486310585413 test loss:0.48368334770202637, test auc: 0.8648737549678622\n",
      "max meta grad:  0.0001967788557521999\n",
      "min meta grad:  -inf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_factors = 16\n",
    "T = 30\n",
    "seed = 50\n",
    "\n",
    "# for lr in list(range(1, 500, 5)):\n",
    "for lr in [500]:\n",
    "\n",
    "    # model = CF4(n_users, n_items, n_factors)\n",
    "    torch.manual_seed(seed)\n",
    "    model = GMFD(n_users, n_items, n_factors)\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    # for layer in model.children():\n",
    "    #     layer.reset_parameters()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.5)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "    loss_fn = torch.nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # y_hat = model(users, items)\n",
    "    # print(y_hat.shape)\n",
    "    # print(ratings.shape)\n",
    "\n",
    "    for t in list(range(T)):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            print('#: ', t, end = ' ')\n",
    "            # training metrics\n",
    "            y_pred = y_hat.detach().to('cpu').numpy()\n",
    "            y = ratings.detach().to('cpu').numpy()\n",
    "            print('train loss:{}, train auc: {}'.format(loss.item(), roc_auc_score(y, y_pred)), end = ' ')\n",
    "            # test metrics\n",
    "            y_hat_test = model(users_test, items_test)\n",
    "            y_pred = y_hat_test.detach().to('cpu').numpy()\n",
    "            y = ratings_test.detach().to('cpu').numpy()\n",
    "            loss = loss_fn(y_hat_test, ratings_test)\n",
    "            print('test loss:{}, test auc: {}'.format(loss.item(), roc_auc_score(y, y_pred)))\n",
    "\n",
    "    # model.eval()\n",
    "    y_hat = model(users, items)\n",
    "    # print('lr: ', lr)\n",
    "    # print('Training accuracy: ', get_accuracy(y_hat, ratings))\n",
    "    # y_pred = y_hat.detach().to('cpu').numpy()\n",
    "    # y = ratings.detach().to('cpu').numpy()\n",
    "    # print('Training AUC: ', roc_auc_score(y, y_pred), end = '\\n\\n')\n",
    "\n",
    "    loss = loss_fn(y_hat, ratings)\n",
    "    meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "    # print('meta grad: ', meta_grad.detach().to('cpu').numpy().tolist())\n",
    "    print('max meta grad: ', meta_grad.max().item())\n",
    "    print('min meta grad: ', meta_grad.min().item(), end = '\\n\\n')\n",
    "    \n",
    "    # y_hat = model(users_test, items_test)\n",
    "    # print('Testing accuracy: ', get_accuracy(y_hat, ratings_test))\n",
    "    # y_pred = y_hat.detach().to('cpu').numpy()\n",
    "    # y = ratings_test.detach().to('cpu').numpy()\n",
    "    # print('Testing AUC: ', roc_auc_score(y, y_pred), end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1000\n",
      "Training accuracy:  0.9091523885726929\n",
      "Training AUC:  0.972411446309926\n",
      "\n",
      "max meta grad:  tensor(0.0003, device='cuda:6')\n",
      "min meta grad:  tensor(-inf, device='cuda:6')\n",
      "tensor([ 3.1337e-06, -1.8015e-05, -4.1825e-05,  ..., -2.6589e-06,\n",
      "         5.7238e-05,  1.4330e-06], device='cuda:6')\n",
      "\n",
      "Testing accuracy:  0.7618434429168701\n",
      "Training AUC:  0.8365536504587607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lr = 1 and T = 1000, Adam giving 77% accuracy on test data\n",
    "# lr = 1.1 and T = 500, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.4 and T = 250, Adam giving 76.8% accuracy on test data\n",
    "# lr = 1.8 and T = 250, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.6 and T = 250, Adam giving 77% accuracy on test data but making meta-gradients infinite\n",
    "# lr = 500, T = 300, SGD, Dropout = 0.3 gives 75.58% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 0 gives 76% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 50 gives 76.18% accuracy on test data\n",
    "\n",
    "# model: GMF, T = 100, seed=50, factors=32, lr=0.05, acc=77.1, auc=0.85\n",
    "# model: GMF, T = 100, seed=50, factors=16, lr=0.1, acc=78.4, auc=0.86\n",
    "# model: GMF, T = 50, seed=50, factors=16, lr=0.1, acc=77.8, auc=85.8\n",
    "# model: GMF, T = 25, seed=50, factors=16, lr=0.5, acc=78.3, auc=0.86\n",
    "# from the looks of it, 20 epochs are good enough for GMF model with dropout-p = 0.2\n",
    "# I feel like sticking with GMFD, T=20, lr=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1000\n",
      "Training accuracy:  0.9477066993713379\n",
      "Training AUC:  0.9897268408765496\n",
      "\n",
      "max meta grad:  tensor(0.0004, device='cuda:6')\n",
      "min meta grad:  tensor(-inf, device='cuda:6')\n",
      "tensor([ 1.5794e-05, -3.6377e-05, -5.2107e-05,  ..., -1.5311e-07,\n",
      "         4.8483e-05,  7.0595e-05], device='cuda:6')\n",
      "\n",
      "Testing accuracy:  0.7502290606498718\n",
      "Testing AUC:  0.8177104337373045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Double factors \n",
    "\n",
    "# lr = 1 and T = 1000, Adam giving 77% accuracy on test data\n",
    "# lr = 1.1 and T = 500, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.4 and T = 250, Adam giving 76.8% accuracy on test data\n",
    "# lr = 1.8 and T = 250, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.6 and T = 250, Adam giving 77% accuracy on test data but making meta-gradients infinite\n",
    "# lr = 500, T = 300, SGD, Dropout = 0.3 gives 75.58% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 0 gives 76% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 50 gives 76.18% accuracy on test data\n",
    "\n",
    "n_factors = 128\n",
    "T = 300\n",
    "seed = 0\n",
    "\n",
    "# for lr in list(range(1, 500, 5)):\n",
    "for lr in [1000]:\n",
    "\n",
    "    # model = CF4(n_users, n_items, n_factors)\n",
    "    model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    model.to(device)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    for layer in model.children():\n",
    "        layer.reset_parameters()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "    loss_fn = torch.nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        # loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    y_hat = model(users, items)\n",
    "    print('lr: ', lr)\n",
    "    print('Training accuracy: ', get_accuracy(y_hat, ratings))\n",
    "    y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "    y = ratings.detach().clone().to('cpu').numpy()\n",
    "    print('Training AUC: ', roc_auc_score(y, y_pred))\n",
    "    print()\n",
    "    loss = loss_fn(y_hat, ratings)\n",
    "    meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "    print('max meta grad: ', meta_grad.max())\n",
    "    print('min meta grad: ', meta_grad.min())\n",
    "    print(meta_grad)\n",
    "    print()\n",
    "    y_hat = model(users_test, items_test)\n",
    "    print('Testing accuracy: ', get_accuracy(y_hat, ratings_test))\n",
    "    y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "    y = ratings_test.detach().clone().to('cpu').numpy()\n",
    "    print('Testing AUC: ', roc_auc_score(y, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "n_factors = 64\n",
    "print(n_factors)\n",
    "print(n_factors // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1000\n",
      "Training accuracy:  0.8688000440597534\n",
      "Training AUC:  0.9457508614463884\n",
      "\n",
      "max meta grad:  tensor(0.0002, device='cuda:6')\n",
      "min meta grad:  tensor(-inf, device='cuda:6')\n",
      "tensor([-5.5593e-07, -1.4034e-05, -4.0434e-05,  ..., -3.7553e-06,\n",
      "         1.1104e-05,  1.5798e-05], device='cuda:6')\n",
      "\n",
      "Testing accuracy:  0.7748198509216309\n",
      "Testing AUC:  0.8519723553800107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Half factors \n",
    "\n",
    "# lr = 1 and T = 1000, Adam giving 77% accuracy on test data\n",
    "# lr = 1.1 and T = 500, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.4 and T = 250, Adam giving 76.8% accuracy on test data\n",
    "# lr = 1.8 and T = 250, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.6 and T = 250, Adam giving 77% accuracy on test data but making meta-gradients infinite\n",
    "# lr = 500, T = 300, SGD, Dropout = 0.3 gives 75.58% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 0 gives 76% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 50 gives 76.18% accuracy on test data\n",
    "\n",
    "n_factors = 32\n",
    "T = 300\n",
    "seed = 0\n",
    "\n",
    "# for lr in list(range(1, 500, 5)):\n",
    "for lr in [1000]:\n",
    "\n",
    "    # model = CF4(n_users, n_items, n_factors)\n",
    "    model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    model.to(device)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    for layer in model.children():\n",
    "        layer.reset_parameters()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "    loss_fn = torch.nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        # loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    y_hat = model(users, items)\n",
    "    print('lr: ', lr)\n",
    "    print('Training accuracy: ', get_accuracy(y_hat, ratings))\n",
    "    y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "    y = ratings.detach().clone().to('cpu').numpy()\n",
    "    print('Training AUC: ', roc_auc_score(y, y_pred))\n",
    "    print()\n",
    "    loss = loss_fn(y_hat, ratings)\n",
    "    meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "    print('max meta grad: ', meta_grad.max())\n",
    "    print('min meta grad: ', meta_grad.min())\n",
    "    print(meta_grad)\n",
    "    print()\n",
    "    y_hat = model(users_test, items_test)\n",
    "    print('Testing accuracy: ', get_accuracy(y_hat, ratings_test))\n",
    "    y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "    y = ratings_test.detach().clone().to('cpu').numpy()\n",
    "    print('Testing AUC: ', roc_auc_score(y, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollaborativeFiltering(\n",
       "  (user_emb): Embedding(943, 128)\n",
       "  (item_emb): Embedding(1682, 128)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exploring AUC metric for evaluating CF model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far, using AUROC instead of accuracy seems promising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **AUC for CF2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 6.9827717e-03 2.9729408e-06 ... 5.6153840e-01 9.9999976e-01\n",
      " 9.9999976e-01]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8441157242039155"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(users_test, items_test)\n",
    "y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "y = ratings_test.detach().clone().to('cpu').numpy()\n",
    "print(y_pred)\n",
    "print(y)\n",
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1213294e-06 9.9984813e-01 1.0000000e+00 ... 1.9173597e-01 3.6412087e-09\n",
      " 8.8454279e-12]\n",
      "[0. 1. 1. ... 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9632291366539395"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(users, items)\n",
    "y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "y = ratings.detach().clone().to('cpu').numpy()\n",
    "print(y_pred)\n",
    "print(y)\n",
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **AUC for original CF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90360653 0.7383278  0.7618074  ... 0.9854893  0.85157144 0.9285307 ]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8366609955350572"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(users_test, items_test)\n",
    "y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "y = ratings_test.detach().clone().to('cpu').numpy()\n",
    "print(y_pred)\n",
    "print(y)\n",
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9852560e-01 9.3463689e-01 9.8911220e-01 ... 8.1000441e-01 4.7213207e-06\n",
      " 5.9991311e-02]\n",
      "[0. 1. 1. ... 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9726644336621912"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(users, items)\n",
    "y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "y = ratings.detach().clone().to('cpu').numpy()\n",
    "print(y_pred)\n",
    "print(y)\n",
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **AUC for CF4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98724735 0.96072394 0.62975526 ... 0.90863013 0.9980566  0.99219877]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8266789252244737"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(users_test, items_test)\n",
    "y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "y = ratings_test.detach().clone().to('cpu').numpy()\n",
    "print(y_pred)\n",
    "print(y)\n",
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58443964 0.94244504 0.65263903 ... 0.98390967 0.01553843 0.00244195]\n",
      "[0. 1. 1. ... 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9771650815917055"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(users, items)\n",
    "y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "y = ratings.detach().clone().to('cpu').numpy()\n",
    "print(y_pred)\n",
    "print(y)\n",
    "roc_auc_score(y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
