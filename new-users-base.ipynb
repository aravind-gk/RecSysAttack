{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import models \n",
    "from models import get_accuracy\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993, 1682, 243719, 40381)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'movielens'\n",
    "n_users = 943\n",
    "n_items = 1682\n",
    "n_new_users = 50\n",
    "\n",
    "# load original training edges\n",
    "train_edges = np.load('data/' + dataset + '/train_edges.npy')\n",
    "test_edges = np.load('data/' + dataset + '/test_edges.npy')\n",
    "\n",
    "# create list of new edges\n",
    "new_users_edges = []\n",
    "for u in range(n_users, n_users + n_new_users):\n",
    "    for i in range(n_items):\n",
    "        new_users_edges.append([u, i, 0])\n",
    "\n",
    "# shuffle the new user edges so that it's not in any particular order\n",
    "new_users_edges = np.array(new_users_edges)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(new_users_edges)\n",
    "\n",
    "# concatenate with original training edges\n",
    "train_edges = np.concatenate((train_edges, new_users_edges))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(train_edges)\n",
    "\n",
    "# proceed with creating users, items and ratings as usual\n",
    "user_list_train = train_edges[:, 0]\n",
    "user_list_test = test_edges[:, 0]\n",
    "item_list_train = train_edges[:, 1]\n",
    "item_list_test = test_edges[:, 1]\n",
    "rating_list_train = train_edges[:, 2].astype('float32')\n",
    "rating_list_test = test_edges[:, 2].astype('float32')\n",
    "\n",
    "# compute new n_users, n_items and n_samples\n",
    "n_users = max(user_list_train.max(), user_list_test.max()) + 1 \n",
    "n_items = max(item_list_train.max(), item_list_test.max()) + 1\n",
    "n_samples_train = len(rating_list_train)\n",
    "n_samples_test = len(rating_list_test)\n",
    "\n",
    "n_users, n_items, n_samples_train, n_samples_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Code for surrogate attack using new users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Algorithm:  base-new\n",
      "\n",
      "-> T (surrogate):  25\n",
      "-> T (target):  25\n",
      "-> Delta: 5000 (2.05%)\n",
      "-> Embedding size (surrogate):  8\n",
      "-> Embedding size (target):  8\n",
      "-> Device:  cuda:5\n",
      "\n",
      "-> Surrogate:  CFD\n",
      "-> Target:  CFD\n",
      "-> Surrogate optimizer:  adam\n",
      "-> Target optimizer:  adam\n",
      "-> Surrogate learning rate:  0.3\n",
      "-> Target learning rate:  0.3\n",
      "-> Surrogate seed:  0\n",
      "-> Target seed:  3\n",
      "\n",
      "-> Retain graph:  True\n",
      "-> Create graph:  False\n",
      "-> Save results:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-> Perturbations:   1%|‚ñè         | 68/5000 [00:35<41:51,  1.96it/s]"
     ]
    }
   ],
   "source": [
    "# model settings\n",
    "algorithm = 'base-new'\n",
    "surrogate = 'CFD'\n",
    "target = 'CFD'\n",
    "opt_surrogate = 'adam'\n",
    "opt_target = 'adam'\n",
    "lr_surrogate = 0.3\n",
    "lr_target = 0.3\n",
    "seed_surrogate = 0\n",
    "seed_target = 3\n",
    "dropout_surrogate = 0.3\n",
    "dropout_target = 0.3\n",
    "\n",
    "# start execution\n",
    "start_time = time.time()\n",
    "\n",
    "# GPU settings (set use_gpu = -1 if you want to use CPU)\n",
    "use_gpu = 5\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# some hyperparameters\n",
    "T_surrogate = 25\n",
    "T_target = 25\n",
    "Delta = 5000 # 5% ~ 10K perturbations for movielens\n",
    "n_factors_surrogate = 8\n",
    "n_factors_target = 8\n",
    "save_results = True\n",
    "retain_graph = True \n",
    "create_graph = False\n",
    "\n",
    "if Delta < 100:\n",
    "    save_results = False\n",
    "\n",
    "# initialize list of perturbations\n",
    "perturbations = dict()\n",
    "perturbations['edges'] = []\n",
    "perturbations['metagrad'] = []\n",
    "\n",
    "perturbations['accuracy-before-surrogate'] = []\n",
    "perturbations['accuracy-after-surrogate'] = []\n",
    "perturbations['accuracy-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['loss-before-surrogate'] = []\n",
    "perturbations['loss-after-surrogate'] = []\n",
    "perturbations['loss-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['accuracy-before-target'] = []\n",
    "perturbations['accuracy-after-target'] = []\n",
    "perturbations['accuracy-unseen-target'] = []\n",
    "\n",
    "perturbations['loss-before-target'] = []\n",
    "perturbations['loss-after-target'] = []\n",
    "perturbations['loss-unseen-target'] = []\n",
    "\n",
    "perturbations['auc-before-surrogate'] = []\n",
    "perturbations['auc-after-surrogate'] = []\n",
    "perturbations['auc-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['auc-before-target'] = []\n",
    "perturbations['auc-after-target'] = []\n",
    "perturbations['auc-unseen-target'] = []\n",
    "\n",
    "# print hyperparam configuration\n",
    "print('-> Algorithm: ', algorithm)\n",
    "print()\n",
    "print('-> T (surrogate): ', T_surrogate)\n",
    "print('-> T (target): ', T_target)\n",
    "print('-> Delta: {} ({}%)'.format(Delta, round(Delta * 100 / n_samples_train, 2)))\n",
    "print('-> Embedding size (surrogate): ', n_factors_surrogate)\n",
    "print('-> Embedding size (target): ', n_factors_target)\n",
    "print('-> Device: ', device)\n",
    "print()\n",
    "print('-> Surrogate: ', surrogate)\n",
    "print('-> Target: ', target)\n",
    "print('-> Surrogate optimizer: ', opt_surrogate)\n",
    "print('-> Target optimizer: ', opt_target)\n",
    "print('-> Surrogate learning rate: ', lr_surrogate)\n",
    "print('-> Target learning rate: ', lr_target)\n",
    "print('-> Surrogate seed: ', seed_surrogate)\n",
    "print('-> Target seed: ', seed_target)\n",
    "print()\n",
    "print('-> Retain graph: ', retain_graph)\n",
    "print('-> Create graph: ', create_graph)\n",
    "print('-> Save results: ', save_results)\n",
    "\n",
    "# load users, items and ratings as tensors\n",
    "users = torch.tensor(user_list_train, device = device)\n",
    "items = torch.tensor(item_list_train, device = device)\n",
    "ratings = torch.tensor(rating_list_train, device = device, requires_grad = True)\n",
    "\n",
    "# only those edges are allowed to be perturbed whose mask entry is False\n",
    "mask = torch.ones_like(ratings).bool()\n",
    "mask[users >= 943] = False\n",
    "\n",
    "# perturbs keeps track of perturbed edges by marking them as False\n",
    "perturbs = torch.ones_like(ratings).bool()\n",
    "\n",
    "# generate tensors out of validation data\n",
    "users_test = torch.tensor(user_list_test, device = device)\n",
    "items_test = torch.tensor(item_list_test, device = device)\n",
    "ratings_test = torch.tensor(rating_list_test, device = device)\n",
    "\n",
    "# sample random negative edges to perturb for baseline\n",
    "if 'base' in algorithm:\n",
    "    edges = mask.int().detach().to('cpu').numpy()\n",
    "    neg_edges = np.where(edges == 0)[0]\n",
    "    np.random.seed(0)\n",
    "    edges_to_perturb = np.random.choice(neg_edges, size=Delta, replace = False) # sample Delta edges randomly and perturb one by one inside loop \n",
    "\n",
    "# for each perturbation do the following\n",
    "for delta in tqdm(range(Delta), desc='-> Perturbations'):\n",
    "\n",
    "    # define surrogate model and it's parameters\n",
    "    torch.manual_seed(seed_surrogate)\n",
    "    model = getattr(models, surrogate)(n_users, n_items, n_factors_surrogate, dropout_surrogate).to(device)\n",
    "\n",
    "    # define optimizer and loss function\n",
    "    if 'adam' in opt_surrogate:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr_surrogate)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr_surrogate)\n",
    "    loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # inner loop training process\n",
    "    model.train()\n",
    "    for i in range(T_surrogate):\n",
    "        y_hat = model(users, items).reshape(ratings.shape)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "\n",
    "    # compute and store accuracy of model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # training accuracy and loss including perturbed edges\n",
    "        y_hat = model(users, items).reshape(ratings.shape)\n",
    "        perturbations['accuracy-before-surrogate'].append(get_accuracy(y_hat, ratings))\n",
    "        perturbations['loss-before-surrogate'].append(loss_fn(y_hat, ratings).item())\n",
    "\n",
    "        # compute training AUROC including perturbed edges\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings.detach().clone().to('cpu').numpy() \n",
    "        perturbations['auc-before-surrogate'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "        # training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs)\n",
    "        ratings_masked = torch.masked_select(ratings, perturbs)\n",
    "        perturbations['accuracy-after-surrogate'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss-after-surrogate'].append(loss_fn(y_hat_masked, ratings_masked).item())\n",
    "\n",
    "        # compute training AUROC excluding perturbed edges\n",
    "        y_pred = y_hat_masked.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_masked.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-after-surrogate'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # compute and store accuracy of surrogate model on unseen data\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(users_test, items_test).reshape(ratings_test.shape)\n",
    "        perturbations['accuracy-unseen-surrogate'].append(get_accuracy(y_hat, ratings_test))\n",
    "        perturbations['loss-unseen-surrogate'].append(loss_fn(y_hat, ratings_test).item())\n",
    "\n",
    "        # compute unseen AUROC\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_test.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-unseen-surrogate'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # compute meta gradient\n",
    "    if 'meta' in algorithm:\n",
    "        meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "\n",
    "    # define evaluation model\n",
    "    torch.manual_seed(seed_target)\n",
    "    eval_model = getattr(models, target)(n_users, n_items, n_factors_target, dropout_target).to(device)\n",
    "\n",
    "    # define optimizer and loss function for evaluation\n",
    "    if 'adam' in opt_target:\n",
    "        optimizer_eval = torch.optim.Adam(eval_model.parameters(), lr = lr_target)\n",
    "    else:\n",
    "        optimizer_eval = torch.optim.SGD(eval_model.parameters(), lr = lr_target)\n",
    "    loss_fn_eval = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # detach ratings and perturbs for eval model\n",
    "    ratings_eval = ratings.detach().clone()\n",
    "    perturbs_eval = perturbs.detach().clone()\n",
    "\n",
    "    # inner train  evaluation model\n",
    "    eval_model.train()\n",
    "    for i in range(T_target):\n",
    "        y_hat = eval_model(users, items).reshape(ratings_eval.shape)\n",
    "        loss_eval = loss_fn_eval(y_hat, ratings_eval)\n",
    "        optimizer_eval.zero_grad()\n",
    "        loss_eval.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer_eval.step()\n",
    "    eval_model.eval()\n",
    "\n",
    "    # compute and store accuracy of eval model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # training accuracy and loss including perturbed edges\n",
    "        y_hat = eval_model(users, items).reshape(ratings_eval.shape)\n",
    "        perturbations['accuracy-before-target'].append(get_accuracy(y_hat, ratings_eval))\n",
    "        perturbations['loss-before-target'].append(loss_fn_eval(y_hat, ratings_eval).item())\n",
    "\n",
    "        # compute training AUROC including perturbed edges\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_eval.detach().clone().to('cpu').numpy() \n",
    "        perturbations['auc-before-target'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "        # training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs_eval)\n",
    "        ratings_masked = torch.masked_select(ratings_eval, perturbs_eval)\n",
    "        perturbations['accuracy-after-target'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss-after-target'].append(loss_fn_eval(y_hat_masked, ratings_masked).item())\n",
    "\n",
    "        # compute training AUROC excluding perturbed edges\n",
    "        y_pred = y_hat_masked.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_masked.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-after-target'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # compute and store accuracy of target model on unseen data\n",
    "    with torch.no_grad():\n",
    "        y_hat = eval_model(users_test, items_test).reshape(ratings_test.shape)\n",
    "        perturbations['accuracy-unseen-target'].append(get_accuracy(y_hat, ratings_test))\n",
    "        perturbations['loss-unseen-target'].append(loss_fn(y_hat, ratings_test).item())\n",
    "\n",
    "        # compute unseen AUROC\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_test.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-unseen-target'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # select best edge and perform perturbation\n",
    "    with torch.no_grad():\n",
    "        if 'meta' in algorithm:\n",
    "            meta_grad[mask == True] = 0\n",
    "            best_edge = meta_grad.argmax().item()\n",
    "            \n",
    "            if mask[best_edge] == False:\n",
    "                ratings[best_edge] = 1\n",
    "                perturbs[best_edge] = False\n",
    "                mask[best_edge] = True\n",
    "            else:\n",
    "                print('Perturbation #{}: No more edges left to perturb'.format(delta))\n",
    "\n",
    "            perturbations['edges'].append(best_edge)\n",
    "            perturbations['metagrad'].append(meta_grad[best_edge].item())\n",
    "\n",
    "        else:\n",
    "            best_edge = edges_to_perturb[delta]\n",
    "            ratings[best_edge] = 1 \n",
    "            perturbs[best_edge] = False\n",
    "            mask[best_edge] = True\n",
    "\n",
    "            perturbations['edges'].append(best_edge)\n",
    "            perturbations['metagrad'].append(-1)\n",
    "\n",
    "sleep(1)\n",
    "# compute execution time\n",
    "exec_time = int(time.time() - start_time)\n",
    "exec_time = time.strftime(\"%Hh %Mm %Ss\", time.gmtime(exec_time))\n",
    "print('-> Execution time: {}'.format(exec_time))\n",
    "\n",
    "# process results\n",
    "perturbations = pd.DataFrame(perturbations)\n",
    "filename = '{}({},{})-{}({},{})-{}-D={}-T({},{})-lr({},{})-seed({},{})-drop({},{})'.format(surrogate, n_factors_surrogate, opt_surrogate, target, n_factors_target, opt_target, algorithm, Delta, T_surrogate, T_target, lr_surrogate, lr_target, seed_surrogate, seed_target, dropout_surrogate, dropout_target)\n",
    "print('-> File name: {}'.format(filename))\n",
    "if save_results:\n",
    "    perturbations.to_csv('results/' + dataset + '/' + filename + '.csv')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
