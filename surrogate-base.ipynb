{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics import AUROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682, 159619, 40381)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'movielens'\n",
    "\n",
    "train_edges = np.load('data/' + dataset + '/train_edges.npy')\n",
    "test_edges = np.load('data/' + dataset + '/test_edges.npy')\n",
    "\n",
    "user_list_train = train_edges[:, 0]\n",
    "user_list_test = test_edges[:, 0]\n",
    "item_list_train = train_edges[:, 1]\n",
    "item_list_test = test_edges[:, 1]\n",
    "rating_list_train = train_edges[:, 2].astype('float32')\n",
    "rating_list_test = test_edges[:, 2].astype('float32')\n",
    "\n",
    "n_users = max(user_list_train.max(), user_list_test.max()) + 1 \n",
    "n_items = max(item_list_train.max(), item_list_test.max()) + 1\n",
    "n_samples_train = len(rating_list_train)\n",
    "n_samples_test = len(rating_list_test)\n",
    "\n",
    "n_users, n_items, n_samples_train, n_samples_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        drop_u = nn.Dropout(p = 0.3)\n",
    "        drop_i = nn.Dropout(p = 0.3)\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        u = drop_u(u)\n",
    "        i = drop_i(i)\n",
    "        dot = (u * i).sum(1)\n",
    "        return torch.sigmoid(dot)\n",
    "\n",
    "class NCF(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.fc1 = nn.Linear(n_factors * 2, n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        tanh = nn.Tanh()\n",
    "        sigmoid = nn.Sigmoid()\n",
    "        swish = nn.SiLU()\n",
    "\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        x = torch.concat([u, i], dim = 1)\n",
    "        x = swish(x)\n",
    "        x = self.fc1(x)\n",
    "        x = swish(x)\n",
    "        x = self.fc2(x)\n",
    "        x = sigmoid(x)\n",
    "        return x\n",
    "\n",
    "def get_accuracy(y_hat, y):\n",
    "    y = y.clone().int()\n",
    "    y_hat = (y_hat.clone() > 0.5).int()\n",
    "    accuracy = (y == y_hat).sum() / len(y)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test collaborative filtering on unseen data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = 5\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "users = torch.tensor(user_list_train, device = device)\n",
    "items = torch.tensor(item_list_train, device = device)\n",
    "ratings = torch.tensor(rating_list_train, device = device, requires_grad = True)\n",
    "\n",
    "users_test = torch.tensor(user_list_test, device = device)\n",
    "items_test = torch.tensor(item_list_test, device = device)\n",
    "ratings_test = torch.tensor(rating_list_test, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1000\n",
      "Training accuracy:  0.9096159934997559\n",
      "Training AUC:  0.9728331497506877\n",
      "\n",
      "max meta grad:  tensor(0.0003, device='cuda:5')\n",
      "min meta grad:  tensor(-inf, device='cuda:5')\n",
      "tensor([ 1.9450e-05, -2.8092e-05, -4.5575e-05,  ..., -3.5770e-05,\n",
      "         4.0386e-05, -1.2304e-05], device='cuda:5')\n",
      "\n",
      "Testing accuracy:  0.7588222026824951\n",
      "Training AUC:  0.8350820960698689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lr = 1 and T = 1000, Adam giving 77% accuracy on test data\n",
    "# lr = 1.1 and T = 500, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.4 and T = 250, Adam giving 76.8% accuracy on test data\n",
    "# lr = 1.8 and T = 250, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.6 and T = 250, Adam giving 77% accuracy on test data but making meta-gradients infinite\n",
    "# lr = 500, T = 300, SGD, Dropout = 0.3 gives 75.58% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 0 gives 76% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 50 gives 76.18% accuracy on test data\n",
    "\n",
    "n_factors = 64\n",
    "T = 300\n",
    "seed = 25\n",
    "\n",
    "# for lr in list(range(1, 500, 5)):\n",
    "for lr in [1000]:\n",
    "\n",
    "    model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    model.to(device)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    for layer in model.children():\n",
    "        layer.reset_parameters()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "    loss_fn = torch.nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    y_hat = model(users, items)\n",
    "    print('lr: ', lr)\n",
    "    print('Training accuracy: ', get_accuracy(y_hat, ratings))\n",
    "    y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "    y = ratings.detach().clone().to('cpu').numpy()\n",
    "    print('Training AUC: ', roc_auc_score(y, y_pred))\n",
    "    print()\n",
    "    loss = loss_fn(y_hat, ratings)\n",
    "    meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "    print('max meta grad: ', meta_grad.max())\n",
    "    print('min meta grad: ', meta_grad.min())\n",
    "    print(meta_grad)\n",
    "    print()\n",
    "    y_hat = model(users_test, items_test)\n",
    "    print('Testing accuracy: ', get_accuracy(y_hat, ratings_test))\n",
    "    y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "    y = ratings_test.detach().clone().to('cpu').numpy()\n",
    "    print('Training AUC: ', roc_auc_score(y, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Code for surrogate meta-attack (surrogate-CF-SGD, evaluation-CF-Adam, same-init)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aravindg1/anaconda3/envs/PyG/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Algorithm:  base\n",
      "\n",
      "-> T:  300\n",
      "-> Delta: 10000 (6.26%)\n",
      "-> Embedding size:  64\n",
      "-> Device:  cuda:5\n",
      "\n",
      "-> Surrogate:  CF\n",
      "-> Target:  CF\n",
      "-> Surrogate optimizer:  sgd\n",
      "-> Target optimizer:  sgd\n",
      "-> Surrogate learning rate:  1000\n",
      "-> Target learning rate:  1000\n",
      "-> Surrogate seed:  0\n",
      "-> Target seed:  25\n",
      "\n",
      "-> Retain graph:  True\n",
      "-> Create graph:  False\n",
      "-> Save results:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-> Perturbations:   0%|          | 22/10000 [00:22<2:52:33,  1.04s/it]"
     ]
    }
   ],
   "source": [
    "# model settings\n",
    "algorithm = 'base'\n",
    "surrogate = 'CF'\n",
    "target = 'CF'\n",
    "opt_surrogate = 'sgd'\n",
    "opt_target = 'sgd'\n",
    "lr_surrogate = 1000\n",
    "lr_target = 1000\n",
    "seed_surrogate = 0\n",
    "seed_target = 25\n",
    "\n",
    "# start execution\n",
    "start_time = time.time()\n",
    "\n",
    "# GPU settings (set use_gpu = -1 if you want to use CPU)\n",
    "use_gpu = 5\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# some hyperparameters\n",
    "T = 300\n",
    "Delta = 10000 # 5% ~ 10K perturbations for movielens\n",
    "n_factors = 64\n",
    "save_results = True\n",
    "retain_graph = True \n",
    "create_graph = False\n",
    "\n",
    "if Delta < 100:\n",
    "    save_results = False\n",
    "\n",
    "# initialize list of perturbations\n",
    "perturbations = dict()\n",
    "perturbations['edges'] = []\n",
    "perturbations['metagrad'] = []\n",
    "\n",
    "perturbations['accuracy-before-surrogate'] = []\n",
    "perturbations['accuracy-after-surrogate'] = []\n",
    "perturbations['accuracy-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['loss-before-surrogate'] = []\n",
    "perturbations['loss-after-surrogate'] = []\n",
    "perturbations['loss-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['accuracy-before-target'] = []\n",
    "perturbations['accuracy-after-target'] = []\n",
    "perturbations['accuracy-unseen-target'] = []\n",
    "\n",
    "perturbations['loss-before-target'] = []\n",
    "perturbations['loss-after-target'] = []\n",
    "perturbations['loss-unseen-target'] = []\n",
    "\n",
    "perturbations['auc-before-surrogate'] = []\n",
    "perturbations['auc-after-surrogate'] = []\n",
    "perturbations['auc-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['auc-before-target'] = []\n",
    "perturbations['auc-after-target'] = []\n",
    "perturbations['auc-unseen-target'] = []\n",
    "\n",
    "# print hyperparam configuration\n",
    "print('-> Algorithm: ', algorithm)\n",
    "print()\n",
    "print('-> T: ', T)\n",
    "print('-> Delta: {} ({}%)'.format(Delta, round(Delta * 100 / n_samples_train, 2)))\n",
    "print('-> Embedding size: ', n_factors)\n",
    "print('-> Device: ', device)\n",
    "print()\n",
    "print('-> Surrogate: ', surrogate)\n",
    "print('-> Target: ', target)\n",
    "print('-> Surrogate optimizer: ', opt_surrogate)\n",
    "print('-> Target optimizer: ', opt_target)\n",
    "print('-> Surrogate learning rate: ', lr_surrogate)\n",
    "print('-> Target learning rate: ', lr_target)\n",
    "print('-> Surrogate seed: ', seed_surrogate)\n",
    "print('-> Target seed: ', seed_target)\n",
    "print()\n",
    "print('-> Retain graph: ', retain_graph)\n",
    "print('-> Create graph: ', create_graph)\n",
    "print('-> Save results: ', save_results)\n",
    "\n",
    "# load users, items and ratings as tensors\n",
    "users = torch.tensor(user_list_train, device = device)\n",
    "items = torch.tensor(item_list_train, device = device)\n",
    "ratings = torch.tensor(rating_list_train, device = device, requires_grad = True)\n",
    "\n",
    "users_test = torch.tensor(user_list_test, device = device)\n",
    "items_test = torch.tensor(item_list_test, device = device)\n",
    "ratings_test = torch.tensor(rating_list_test, device = device)\n",
    "\n",
    "if 'NCF' in surrogate:\n",
    "    ratings = ratings.reshape((n_samples_train, 1))\n",
    "perturbs = torch.ones_like(ratings).bool()\n",
    "auroc = AUROC(pos_label = 1)\n",
    "\n",
    "# sample random negative edges to perturb\n",
    "if 'base' in algorithm:\n",
    "    edges = ratings.detach().to('cpu').numpy()\n",
    "    neg_edges = np.where(edges == 0)[0]\n",
    "    np.random.seed(0)\n",
    "    edges_to_perturb = np.random.choice(neg_edges, size=Delta, replace = True) # sample Delta edges randomly and perturb one by one inside loop \n",
    "\n",
    "# for each perturbation do the following\n",
    "for delta in tqdm(range(Delta), desc='-> Perturbations'):\n",
    "\n",
    "    # define surrogate model and it's parameters\n",
    "    if 'NCF' in surrogate:\n",
    "        model = NCF(n_users, n_items, n_factors)\n",
    "    else:\n",
    "        model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    model.to(device)\n",
    "\n",
    "    # reset model paramters \n",
    "    torch.manual_seed(seed_surrogate)\n",
    "    for layer in model.children():\n",
    "        layer.reset_parameters()\n",
    "\n",
    "    # define optimizer and loss function\n",
    "    if 'adam' in opt_surrogate:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr_surrogate)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr_surrogate)\n",
    "    loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # inner loop training process\n",
    "    model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "\n",
    "    # compute and store accuracy of model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # training accuracy and loss including perturbed edges\n",
    "        y_hat = model(users, items)\n",
    "        perturbations['accuracy-before-surrogate'].append(get_accuracy(y_hat, ratings))\n",
    "        perturbations['loss-before-surrogate'].append(loss_fn(y_hat, ratings).item())\n",
    "        perturbations['auc-before-surrogate'].append(auroc(y_hat, ratings.int()).item())\n",
    "\n",
    "        # training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs)\n",
    "        ratings_masked = torch.masked_select(ratings, perturbs)\n",
    "        perturbations['accuracy-after-surrogate'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss-after-surrogate'].append(loss_fn(y_hat_masked, ratings_masked).item())\n",
    "        perturbations['auc-after-surrogate'].append(auroc(y_hat_masked, ratings_masked.int()).item())\n",
    "\n",
    "    # compute and store accuracy of surrogate model on unseen data\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(users_test, items_test)\n",
    "        perturbations['accuracy-unseen-surrogate'].append(get_accuracy(y_hat, ratings_test))\n",
    "        perturbations['loss-unseen-surrogate'].append(loss_fn(y_hat, ratings_test).item())\n",
    "        perturbations['auc-unseen-surrogate'].append(auroc(y_hat, ratings_test.int()).item())\n",
    "\n",
    "    # compute meta gradient\n",
    "    if 'meta' in algorithm:\n",
    "        meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "\n",
    "    # define evaluation model\n",
    "    if 'NCF' in target:\n",
    "        eval_model = NCF(n_users, n_items, n_factors)\n",
    "    else:\n",
    "        eval_model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    eval_model.to(device)\n",
    "\n",
    "    # reset evaluation model parameters\n",
    "    torch.manual_seed(seed_target)\n",
    "    for layer in eval_model.children():\n",
    "        layer.reset_parameters()\n",
    "\n",
    "    # define optimizer and loss function for evaluation\n",
    "    if 'adam' in opt_target:\n",
    "        optimizer_eval = torch.optim.Adam(eval_model.parameters(), lr = lr_target)\n",
    "    else:\n",
    "        optimizer_eval = torch.optim.SGD(eval_model.parameters(), lr = lr_target)\n",
    "    loss_fn_eval = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # detach ratings and perturbs for eval model\n",
    "    ratings_eval = ratings.detach().clone()\n",
    "    perturbs_eval = perturbs.detach().clone()\n",
    "\n",
    "    # reshape ratings and perturbs if necessary\n",
    "    # later add code for reshaping ratings_test as well (incomplete right now)\n",
    "    if surrogate != target:\n",
    "        if 'NCF' in target:\n",
    "            ratings_eval = ratings_eval.reshape((n_samples_train, 1))\n",
    "            perturbs_eval = perturbs_eval.reshape((n_samples_train, 1))\n",
    "        else:\n",
    "            ratings_eval = ratings_eval.reshape((n_samples_train))\n",
    "            perturbs_eval = perturbs_eval.reshape((n_samples_train))\n",
    "\n",
    "    # inner train  evaluation model\n",
    "    eval_model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = eval_model(users, items)\n",
    "        loss_eval = loss_fn_eval(y_hat, ratings_eval)\n",
    "        optimizer_eval.zero_grad()\n",
    "        loss_eval.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer_eval.step()\n",
    "    eval_model.eval()\n",
    "\n",
    "    # compute and store accuracy of eval model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # training accuracy and loss including perturbed edges\n",
    "        y_hat = eval_model(users, items)\n",
    "        perturbations['accuracy-before-target'].append(get_accuracy(y_hat, ratings_eval))\n",
    "        perturbations['loss-before-target'].append(loss_fn_eval(y_hat, ratings_eval).item())\n",
    "        perturbations['auc-before-target'].append(auroc(y_hat, ratings_eval.int()).item())\n",
    "\n",
    "        # training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs_eval)\n",
    "        ratings_masked = torch.masked_select(ratings_eval, perturbs_eval)\n",
    "        perturbations['accuracy-after-target'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss-after-target'].append(loss_fn_eval(y_hat_masked, ratings_masked).item())\n",
    "        perturbations['auc-after-target'].append(auroc(y_hat_masked, ratings_masked.int()).item())\n",
    "\n",
    "    # compute and store accuracy of target model on unseen data\n",
    "    with torch.no_grad():\n",
    "        y_hat = eval_model(users_test, items_test)\n",
    "        perturbations['accuracy-unseen-target'].append(get_accuracy(y_hat, ratings_test))\n",
    "        perturbations['loss-unseen-target'].append(loss_fn(y_hat, ratings_test).item())\n",
    "        perturbations['auc-unseen-target'].append(auroc(y_hat, ratings_test.int()).item())\n",
    "\n",
    "    # select best edge and perform perturbation\n",
    "    with torch.no_grad():\n",
    "        if 'meta' in algorithm:\n",
    "            mask = ratings.detach().int()\n",
    "            meta_grad[mask == 1] = 0\n",
    "            best_edge = meta_grad.argmax().item()\n",
    "            ratings[best_edge] = 1\n",
    "            perturbs[best_edge] = False\n",
    "\n",
    "            perturbations['edges'].append(best_edge)\n",
    "            perturbations['metagrad'].append(meta_grad[best_edge].item())\n",
    "\n",
    "        else:\n",
    "            best_edge = edges_to_perturb[delta]\n",
    "            ratings[best_edge] = 1 \n",
    "            perturbs[best_edge] = False\n",
    "\n",
    "            perturbations['edges'].append(best_edge)\n",
    "            perturbations['metagrad'].append(-1)\n",
    "\n",
    "sleep(1)\n",
    "# compute execution time\n",
    "exec_time = int(time.time() - start_time)\n",
    "exec_time = time.strftime(\"%Hh %Mm %Ss\", time.gmtime(exec_time))\n",
    "print('-> Execution time: {}'.format(exec_time))\n",
    "\n",
    "# process results\n",
    "perturbations = pd.DataFrame(perturbations)\n",
    "filename = '{}({})-{}({})-{}-D={}-T={}-lr({},{})-seed({},{})'.format(surrogate, opt_surrogate, target, opt_target, algorithm, Delta, T, lr_surrogate, lr_target, seed_surrogate, seed_target)\n",
    "if save_results:\n",
    "    perturbations.to_csv('results/' + dataset + '/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('File name: ', filename)\n",
    "if 'meta' in algorithm:\n",
    "    print('Max meta-gradient: ', perturbations['metagrad'].max())\n",
    "perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Perturbations</th>\n",
       "      <th>Perturbed edge</th>\n",
       "      <th>Meta gradient</th>\n",
       "      <th>Accuracy including perturbed edges (surrogate)</th>\n",
       "      <th>Accuracy excluding perturbed edges (surrogate)</th>\n",
       "      <th>Accuracy unseen (surrogate)</th>\n",
       "      <th>Loss including perturbed edges (surrogate)</th>\n",
       "      <th>Loss excluding perturbed edges (surrogate)</th>\n",
       "      <th>Loss unseen (surrogate)</th>\n",
       "      <th>Accuracy including perturbed edges (target)</th>\n",
       "      <th>Accuracy excluding perturbed edges (target)</th>\n",
       "      <th>Accuracy unseen (target)</th>\n",
       "      <th>Loss including perturbed edges (target)</th>\n",
       "      <th>Loss excluding perturbed edges (target)</th>\n",
       "      <th>Loss unseen (target)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64572</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.760556</td>\n",
       "      <td>0.213116</td>\n",
       "      <td>0.213116</td>\n",
       "      <td>0.724937</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.761843</td>\n",
       "      <td>0.211837</td>\n",
       "      <td>0.211837</td>\n",
       "      <td>0.724220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45202</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.908094</td>\n",
       "      <td>0.908093</td>\n",
       "      <td>0.759912</td>\n",
       "      <td>0.213170</td>\n",
       "      <td>0.213171</td>\n",
       "      <td>0.725120</td>\n",
       "      <td>0.908902</td>\n",
       "      <td>0.908907</td>\n",
       "      <td>0.762141</td>\n",
       "      <td>0.212384</td>\n",
       "      <td>0.212378</td>\n",
       "      <td>0.725803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>136204</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.907993</td>\n",
       "      <td>0.907999</td>\n",
       "      <td>0.760803</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.213290</td>\n",
       "      <td>0.724132</td>\n",
       "      <td>0.908839</td>\n",
       "      <td>0.908838</td>\n",
       "      <td>0.761868</td>\n",
       "      <td>0.212368</td>\n",
       "      <td>0.212371</td>\n",
       "      <td>0.724222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1810</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.907923</td>\n",
       "      <td>0.759689</td>\n",
       "      <td>0.213443</td>\n",
       "      <td>0.213447</td>\n",
       "      <td>0.725339</td>\n",
       "      <td>0.909134</td>\n",
       "      <td>0.909138</td>\n",
       "      <td>0.762116</td>\n",
       "      <td>0.211804</td>\n",
       "      <td>0.211801</td>\n",
       "      <td>0.724209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111703</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.907874</td>\n",
       "      <td>0.907872</td>\n",
       "      <td>0.760308</td>\n",
       "      <td>0.213378</td>\n",
       "      <td>0.213383</td>\n",
       "      <td>0.724941</td>\n",
       "      <td>0.909027</td>\n",
       "      <td>0.909025</td>\n",
       "      <td>0.761843</td>\n",
       "      <td>0.211630</td>\n",
       "      <td>0.211632</td>\n",
       "      <td>0.723913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>68592</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.870780</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.708502</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>0.281563</td>\n",
       "      <td>0.786965</td>\n",
       "      <td>0.882245</td>\n",
       "      <td>0.887331</td>\n",
       "      <td>0.707882</td>\n",
       "      <td>0.271749</td>\n",
       "      <td>0.261128</td>\n",
       "      <td>0.822038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>126611</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.870717</td>\n",
       "      <td>0.877579</td>\n",
       "      <td>0.708551</td>\n",
       "      <td>0.295908</td>\n",
       "      <td>0.281516</td>\n",
       "      <td>0.786867</td>\n",
       "      <td>0.882301</td>\n",
       "      <td>0.887397</td>\n",
       "      <td>0.707981</td>\n",
       "      <td>0.271762</td>\n",
       "      <td>0.261151</td>\n",
       "      <td>0.821963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>115370</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.870799</td>\n",
       "      <td>0.877638</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.295924</td>\n",
       "      <td>0.281529</td>\n",
       "      <td>0.786675</td>\n",
       "      <td>0.882288</td>\n",
       "      <td>0.887436</td>\n",
       "      <td>0.708105</td>\n",
       "      <td>0.271747</td>\n",
       "      <td>0.261129</td>\n",
       "      <td>0.821770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>83334</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.870799</td>\n",
       "      <td>0.877718</td>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.295871</td>\n",
       "      <td>0.281476</td>\n",
       "      <td>0.786680</td>\n",
       "      <td>0.882357</td>\n",
       "      <td>0.887509</td>\n",
       "      <td>0.707981</td>\n",
       "      <td>0.271724</td>\n",
       "      <td>0.261085</td>\n",
       "      <td>0.821525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>33335</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.877831</td>\n",
       "      <td>0.708229</td>\n",
       "      <td>0.295848</td>\n",
       "      <td>0.281479</td>\n",
       "      <td>0.786641</td>\n",
       "      <td>0.882564</td>\n",
       "      <td>0.887695</td>\n",
       "      <td>0.708056</td>\n",
       "      <td>0.271720</td>\n",
       "      <td>0.261079</td>\n",
       "      <td>0.821538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # Perturbations  Perturbed edge  Meta gradient  \\\n",
       "0                   0           64572       0.000252   \n",
       "1                   1           45202       0.000244   \n",
       "2                   2          136204       0.000241   \n",
       "3                   3            1810       0.000231   \n",
       "4                   4          111703       0.000232   \n",
       "...               ...             ...            ...   \n",
       "9995             9995           68592       0.000048   \n",
       "9996             9996          126611       0.000048   \n",
       "9997             9997          115370       0.000048   \n",
       "9998             9998           83334       0.000047   \n",
       "9999             9999           33335       0.000048   \n",
       "\n",
       "      Accuracy including perturbed edges (surrogate)  \\\n",
       "0                                           0.908213   \n",
       "1                                           0.908094   \n",
       "2                                           0.907993   \n",
       "3                                           0.907924   \n",
       "4                                           0.907874   \n",
       "...                                              ...   \n",
       "9995                                        0.870780   \n",
       "9996                                        0.870717   \n",
       "9997                                        0.870799   \n",
       "9998                                        0.870799   \n",
       "9999                                        0.870930   \n",
       "\n",
       "      Accuracy excluding perturbed edges (surrogate)  \\\n",
       "0                                           0.908213   \n",
       "1                                           0.908093   \n",
       "2                                           0.907999   \n",
       "3                                           0.907923   \n",
       "4                                           0.907872   \n",
       "...                                              ...   \n",
       "9995                                        0.877660   \n",
       "9996                                        0.877579   \n",
       "9997                                        0.877638   \n",
       "9998                                        0.877718   \n",
       "9999                                        0.877831   \n",
       "\n",
       "      Accuracy unseen (surrogate)  Loss including perturbed edges (surrogate)  \\\n",
       "0                        0.760556                                    0.213116   \n",
       "1                        0.759912                                    0.213170   \n",
       "2                        0.760803                                    0.213313   \n",
       "3                        0.759689                                    0.213443   \n",
       "4                        0.760308                                    0.213378   \n",
       "...                           ...                                         ...   \n",
       "9995                     0.708502                                    0.295964   \n",
       "9996                     0.708551                                    0.295908   \n",
       "9997                     0.708848                                    0.295924   \n",
       "9998                     0.708204                                    0.295871   \n",
       "9999                     0.708229                                    0.295848   \n",
       "\n",
       "      Loss excluding perturbed edges (surrogate)  Loss unseen (surrogate)  \\\n",
       "0                                       0.213116                 0.724937   \n",
       "1                                       0.213171                 0.725120   \n",
       "2                                       0.213290                 0.724132   \n",
       "3                                       0.213447                 0.725339   \n",
       "4                                       0.213383                 0.724941   \n",
       "...                                          ...                      ...   \n",
       "9995                                    0.281563                 0.786965   \n",
       "9996                                    0.281516                 0.786867   \n",
       "9997                                    0.281529                 0.786675   \n",
       "9998                                    0.281476                 0.786680   \n",
       "9999                                    0.281479                 0.786641   \n",
       "\n",
       "      Accuracy including perturbed edges (target)  \\\n",
       "0                                        0.909152   \n",
       "1                                        0.908902   \n",
       "2                                        0.908839   \n",
       "3                                        0.909134   \n",
       "4                                        0.909027   \n",
       "...                                           ...   \n",
       "9995                                     0.882245   \n",
       "9996                                     0.882301   \n",
       "9997                                     0.882288   \n",
       "9998                                     0.882357   \n",
       "9999                                     0.882564   \n",
       "\n",
       "      Accuracy excluding perturbed edges (target)  Accuracy unseen (target)  \\\n",
       "0                                        0.909152                  0.761843   \n",
       "1                                        0.908907                  0.762141   \n",
       "2                                        0.908838                  0.761868   \n",
       "3                                        0.909138                  0.762116   \n",
       "4                                        0.909025                  0.761843   \n",
       "...                                           ...                       ...   \n",
       "9995                                     0.887331                  0.707882   \n",
       "9996                                     0.887397                  0.707981   \n",
       "9997                                     0.887436                  0.708105   \n",
       "9998                                     0.887509                  0.707981   \n",
       "9999                                     0.887695                  0.708056   \n",
       "\n",
       "      Loss including perturbed edges (target)  \\\n",
       "0                                    0.211837   \n",
       "1                                    0.212384   \n",
       "2                                    0.212368   \n",
       "3                                    0.211804   \n",
       "4                                    0.211630   \n",
       "...                                       ...   \n",
       "9995                                 0.271749   \n",
       "9996                                 0.271762   \n",
       "9997                                 0.271747   \n",
       "9998                                 0.271724   \n",
       "9999                                 0.271720   \n",
       "\n",
       "      Loss excluding perturbed edges (target)  Loss unseen (target)  \n",
       "0                                    0.211837              0.724220  \n",
       "1                                    0.212378              0.725803  \n",
       "2                                    0.212371              0.724222  \n",
       "3                                    0.211801              0.724209  \n",
       "4                                    0.211632              0.723913  \n",
       "...                                       ...                   ...  \n",
       "9995                                 0.261128              0.822038  \n",
       "9996                                 0.261151              0.821963  \n",
       "9997                                 0.261129              0.821770  \n",
       "9998                                 0.261085              0.821525  \n",
       "9999                                 0.261079              0.821538  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process perturbations data\n",
    "perturbations_reset = perturbations.reset_index()\n",
    "perturbations_reset.columns = ['# Perturbations', 'Perturbed edge', 'Meta gradient', 'Accuracy including perturbed edges (surrogate)', 'Accuracy excluding perturbed edges (surrogate)', 'Accuracy unseen (surrogate)', 'Loss including perturbed edges (surrogate)', 'Loss excluding perturbed edges (surrogate)', 'Loss unseen (surrogate)', 'Accuracy including perturbed edges (target)', 'Accuracy excluding perturbed edges (target)', 'Accuracy unseen (target)', 'Loss including perturbed edges (target)', 'Loss excluding perturbed edges (target)', 'Loss unseen (target)']\n",
    "perturbations_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process perturbations data\n",
    "perturbations_reset = perturbations.reset_index()\n",
    "perturbations_reset.columns = ['# Perturbations', 'Perturbed edge', 'Meta gradient', 'Accuracy including perturbed edges (surrogate)', 'Accuracy excluding perturbed edges (surrogate)', 'Accuracy unseen (surrogate)', 'Loss including perturbed edges (surrogate)', 'Loss excluding perturbed edges (surrogate)', 'Loss unseen (surrogate)', 'Accuracy including perturbed edges (target)', 'Accuracy excluding perturbed edges (target)', 'Accuracy unseen (target)', 'Loss including perturbed edges (target)', 'Loss excluding perturbed edges (target)', 'Loss unseen (target)']\n",
    "perturbations_reset\n",
    "\n",
    "# Figure specifications\n",
    "sns.set_theme()\n",
    "figsize = (7, 6)\n",
    "print('File name: ', filename)\n",
    "\n",
    "# Loss plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss excluding perturbed edges (surrogate)', color = 'blue').set_title('Comparison of loss on training data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss excluding perturbed edges (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(labels = ['Loss (surrogate)', 'Loss (target)'], loc = 'upper left')\n",
    "if save_results: \n",
    "    fig.savefig('plots/' + dataset + '/losses-' + filename)\n",
    "plt.show()\n",
    "\n",
    "# Loss on unseen data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss unseen (surrogate)', color = 'blue').set_title('Comparison of loss on unseen data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss unseen (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(labels = ['Loss unseen (surrogate)', 'Loss unseen (target)'], loc = 'upper left')\n",
    "if save_results: \n",
    "    fig.savefig('plots/' + dataset + '/losses-unseen-' + filename)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy excluding perturbed edges (surrogate)', color = 'blue').set_title('Comparison of accuracy on training data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy excluding perturbed edges (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(labels = ['Accuracy (surrogate)', 'Accuracy (target)'])\n",
    "if save_results:\n",
    "    fig.savefig('plots/' + dataset + '/accuracy-' + filename)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy on unseen data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy unseen (surrogate)', color = 'blue').set_title('Comparison of accuracy on unseen data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy unseen (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(labels = ['Accuracy unseen (surrogate)', 'Accuracy unseen (target)'], loc = 'upper left')\n",
    "if save_results: \n",
    "    fig.savefig('plots/' + dataset + '/accuracy-unseen-' + filename)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
