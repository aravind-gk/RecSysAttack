{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682, 159619, 40381)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'movielens'\n",
    "\n",
    "train_edges = np.load('data/' + dataset + '/train_edges.npy')\n",
    "test_edges = np.load('data/' + dataset + '/test_edges.npy')\n",
    "\n",
    "user_list_train = train_edges[:, 0]\n",
    "user_list_test = test_edges[:, 0]\n",
    "item_list_train = train_edges[:, 1]\n",
    "item_list_test = test_edges[:, 1]\n",
    "rating_list_train = train_edges[:, 2].astype('float32')\n",
    "rating_list_test = test_edges[:, 2].astype('float32')\n",
    "\n",
    "n_users = max(user_list_train.max(), user_list_test.max()) + 1 \n",
    "n_items = max(item_list_train.max(), item_list_test.max()) + 1\n",
    "n_samples_train = len(rating_list_train)\n",
    "n_samples_test = len(rating_list_test)\n",
    "\n",
    "n_users, n_items, n_samples_train, n_samples_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        drop_u = nn.Dropout(p = 0.3)\n",
    "        drop_i = nn.Dropout(p = 0.3)\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        u = drop_u(u)\n",
    "        i = drop_i(i)\n",
    "        dot = (u * i).sum(1)\n",
    "        return torch.sigmoid(dot)\n",
    "\n",
    "class NCF(Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "        self.fc1 = nn.Linear(n_factors * 2, n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        tanh = nn.Tanh()\n",
    "        sigmoid = nn.Sigmoid()\n",
    "        swish = nn.SiLU()\n",
    "\n",
    "        u = self.user_emb(user)\n",
    "        i = self.item_emb(item)\n",
    "        x = torch.concat([u, i], dim = 1)\n",
    "        x = swish(x)\n",
    "        x = self.fc1(x)\n",
    "        x = swish(x)\n",
    "        x = self.fc2(x)\n",
    "        x = sigmoid(x)\n",
    "        return x\n",
    "\n",
    "def get_accuracy(y_hat, y):\n",
    "    y = y.clone().int()\n",
    "    y_hat = (y_hat.clone() > 0.5).int()\n",
    "    accuracy = (y == y_hat).sum() / len(y)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test collaborative filtering on unseen data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = 6\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "users = torch.tensor(user_list_train, device = device)\n",
    "items = torch.tensor(item_list_train, device = device)\n",
    "ratings = torch.tensor(rating_list_train, device = device, requires_grad = True)\n",
    "\n",
    "users_test = torch.tensor(user_list_test, device = device)\n",
    "items_test = torch.tensor(item_list_test, device = device)\n",
    "ratings_test = torch.tensor(rating_list_test, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1000\n",
      "Training accuracy:  0.9096159934997559\n",
      "Training AUC:  0.9728331497506877\n",
      "\n",
      "max meta grad:  tensor(0.0003, device='cuda:6')\n",
      "min meta grad:  tensor(-inf, device='cuda:6')\n",
      "tensor([ 1.9450e-05, -2.8092e-05, -4.5575e-05,  ..., -3.5770e-05,\n",
      "         4.0386e-05, -1.2304e-05], device='cuda:6')\n",
      "\n",
      "Testing accuracy:  0.7588222026824951\n",
      "Training AUC:  0.8350820960698689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lr = 1 and T = 1000, Adam giving 77% accuracy on test data\n",
    "# lr = 1.1 and T = 500, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.4 and T = 250, Adam giving 76.8% accuracy on test data\n",
    "# lr = 1.8 and T = 250, Adam giving 77.2% accuracy on test data\n",
    "# lr = 1.6 and T = 250, Adam giving 77% accuracy on test data but making meta-gradients infinite\n",
    "# lr = 500, T = 300, SGD, Dropout = 0.3 gives 75.58% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 0 gives 76% accuracy on test data\n",
    "# lr = 1000, T = 300, SGD, Dropout = 0.3, seed = 50 gives 76.18% accuracy on test data\n",
    "\n",
    "n_factors = 64\n",
    "T = 300\n",
    "seed = 25\n",
    "\n",
    "# for lr in list(range(1, 500, 5)):\n",
    "for lr in [1000]:\n",
    "\n",
    "    model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    model.to(device)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    for layer in model.children():\n",
    "        layer.reset_parameters()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "    loss_fn = torch.nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    y_hat = model(users, items)\n",
    "    print('lr: ', lr)\n",
    "    print('Training accuracy: ', get_accuracy(y_hat, ratings))\n",
    "    y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "    y = ratings.detach().clone().to('cpu').numpy()\n",
    "    print('Training AUC: ', roc_auc_score(y, y_pred))\n",
    "    print()\n",
    "    loss = loss_fn(y_hat, ratings)\n",
    "    meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "    print('max meta grad: ', meta_grad.max())\n",
    "    print('min meta grad: ', meta_grad.min())\n",
    "    print(meta_grad)\n",
    "    print()\n",
    "    y_hat = model(users_test, items_test)\n",
    "    print('Testing accuracy: ', get_accuracy(y_hat, ratings_test))\n",
    "    y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "    y = ratings_test.detach().clone().to('cpu').numpy()\n",
    "    print('Training AUC: ', roc_auc_score(y, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Code for surrogate meta-attack (surrogate-CF-SGD, evaluation-CF-Adam, same-init)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Algorithm:  base\n",
      "\n",
      "-> T:  300\n",
      "-> Delta: 10000 (6.26%)\n",
      "-> Embedding size:  64\n",
      "-> Device:  cuda:5\n",
      "\n",
      "-> Surrogate:  CF\n",
      "-> Target:  CF\n",
      "-> Surrogate optimizer:  sgd\n",
      "-> Target optimizer:  sgd\n",
      "-> Surrogate learning rate:  1000\n",
      "-> Target learning rate:  1000\n",
      "-> Surrogate seed:  0\n",
      "-> Target seed:  25\n",
      "\n",
      "-> Retain graph:  True\n",
      "-> Create graph:  False\n",
      "-> Save results:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-> Perturbations:   0%|          | 27/10000 [00:31<3:12:33,  1.16s/it]"
     ]
    }
   ],
   "source": [
    "# model settings\n",
    "algorithm = 'base'\n",
    "surrogate = 'CF'\n",
    "target = 'CF'\n",
    "opt_surrogate = 'sgd'\n",
    "opt_target = 'sgd'\n",
    "lr_surrogate = 1000\n",
    "lr_target = 1000\n",
    "seed_surrogate = 0\n",
    "seed_target = 25\n",
    "\n",
    "# start execution\n",
    "start_time = time.time()\n",
    "\n",
    "# GPU settings (set use_gpu = -1 if you want to use CPU)\n",
    "use_gpu = 5\n",
    "if use_gpu == -1:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = torch.device('cuda:{}'.format(str(use_gpu)) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# some hyperparameters\n",
    "T = 300\n",
    "Delta = 10000 # 5% ~ 10K perturbations for movielens\n",
    "n_factors = 64\n",
    "save_results = True\n",
    "retain_graph = True \n",
    "create_graph = False\n",
    "\n",
    "if Delta < 100:\n",
    "    save_results = False\n",
    "\n",
    "# initialize list of perturbations\n",
    "perturbations = dict()\n",
    "perturbations['edges'] = []\n",
    "perturbations['metagrad'] = []\n",
    "\n",
    "perturbations['accuracy-before-surrogate'] = []\n",
    "perturbations['accuracy-after-surrogate'] = []\n",
    "perturbations['accuracy-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['loss-before-surrogate'] = []\n",
    "perturbations['loss-after-surrogate'] = []\n",
    "perturbations['loss-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['accuracy-before-target'] = []\n",
    "perturbations['accuracy-after-target'] = []\n",
    "perturbations['accuracy-unseen-target'] = []\n",
    "\n",
    "perturbations['loss-before-target'] = []\n",
    "perturbations['loss-after-target'] = []\n",
    "perturbations['loss-unseen-target'] = []\n",
    "\n",
    "perturbations['auc-before-surrogate'] = []\n",
    "perturbations['auc-after-surrogate'] = []\n",
    "perturbations['auc-unseen-surrogate'] = []\n",
    "\n",
    "perturbations['auc-before-target'] = []\n",
    "perturbations['auc-after-target'] = []\n",
    "perturbations['auc-unseen-target'] = []\n",
    "\n",
    "# print hyperparam configuration\n",
    "print('-> Algorithm: ', algorithm)\n",
    "print()\n",
    "print('-> T: ', T)\n",
    "print('-> Delta: {} ({}%)'.format(Delta, round(Delta * 100 / n_samples_train, 2)))\n",
    "print('-> Embedding size: ', n_factors)\n",
    "print('-> Device: ', device)\n",
    "print()\n",
    "print('-> Surrogate: ', surrogate)\n",
    "print('-> Target: ', target)\n",
    "print('-> Surrogate optimizer: ', opt_surrogate)\n",
    "print('-> Target optimizer: ', opt_target)\n",
    "print('-> Surrogate learning rate: ', lr_surrogate)\n",
    "print('-> Target learning rate: ', lr_target)\n",
    "print('-> Surrogate seed: ', seed_surrogate)\n",
    "print('-> Target seed: ', seed_target)\n",
    "print()\n",
    "print('-> Retain graph: ', retain_graph)\n",
    "print('-> Create graph: ', create_graph)\n",
    "print('-> Save results: ', save_results)\n",
    "\n",
    "# load users, items and ratings as tensors\n",
    "users = torch.tensor(user_list_train, device = device)\n",
    "items = torch.tensor(item_list_train, device = device)\n",
    "ratings = torch.tensor(rating_list_train, device = device, requires_grad = True)\n",
    "\n",
    "users_test = torch.tensor(user_list_test, device = device)\n",
    "items_test = torch.tensor(item_list_test, device = device)\n",
    "ratings_test = torch.tensor(rating_list_test, device = device)\n",
    "\n",
    "if 'NCF' in surrogate:\n",
    "    ratings = ratings.reshape((n_samples_train, 1))\n",
    "perturbs = torch.ones_like(ratings).bool()\n",
    "\n",
    "# sample random negative edges to perturb\n",
    "if 'base' in algorithm:\n",
    "    edges = ratings.detach().to('cpu').numpy()\n",
    "    neg_edges = np.where(edges == 0)[0]\n",
    "    np.random.seed(0)\n",
    "    edges_to_perturb = np.random.choice(neg_edges, size=Delta, replace = True) # sample Delta edges randomly and perturb one by one inside loop \n",
    "\n",
    "# for each perturbation do the following\n",
    "for delta in tqdm(range(Delta), desc='-> Perturbations'):\n",
    "\n",
    "    # define surrogate model and it's parameters\n",
    "    if 'NCF' in surrogate:\n",
    "        model = NCF(n_users, n_items, n_factors)\n",
    "    else:\n",
    "        model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    model.to(device)\n",
    "\n",
    "    # reset model paramters \n",
    "    torch.manual_seed(seed_surrogate)\n",
    "    for layer in model.children():\n",
    "        layer.reset_parameters()\n",
    "\n",
    "    # define optimizer and loss function\n",
    "    if 'adam' in opt_surrogate:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr_surrogate)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr_surrogate)\n",
    "    loss_fn = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # inner loop training process\n",
    "    model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = model(users, items)\n",
    "        loss = loss_fn(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "\n",
    "    # compute and store accuracy of model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # training accuracy and loss including perturbed edges\n",
    "        y_hat = model(users, items)\n",
    "        perturbations['accuracy-before-surrogate'].append(get_accuracy(y_hat, ratings))\n",
    "        perturbations['loss-before-surrogate'].append(loss_fn(y_hat, ratings).item())\n",
    "\n",
    "        # compute training AUROC including perturbed edges\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings.detach().clone().to('cpu').numpy() \n",
    "        perturbations['auc-before-surrogate'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "        # training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs)\n",
    "        ratings_masked = torch.masked_select(ratings, perturbs)\n",
    "        perturbations['accuracy-after-surrogate'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss-after-surrogate'].append(loss_fn(y_hat_masked, ratings_masked).item())\n",
    "\n",
    "        # compute training AUROC excluding perturbed edges\n",
    "        y_pred = y_hat_masked.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_masked.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-after-surrogate'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # compute and store accuracy of surrogate model on unseen data\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(users_test, items_test)\n",
    "        perturbations['accuracy-unseen-surrogate'].append(get_accuracy(y_hat, ratings_test))\n",
    "        perturbations['loss-unseen-surrogate'].append(loss_fn(y_hat, ratings_test).item())\n",
    "\n",
    "        # compute unseen AUROC\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_test.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-unseen-surrogate'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # compute meta gradient\n",
    "    if 'meta' in algorithm:\n",
    "        meta_grad = torch.autograd.grad(loss, ratings)[0]\n",
    "\n",
    "    # define evaluation model\n",
    "    if 'NCF' in target:\n",
    "        eval_model = NCF(n_users, n_items, n_factors)\n",
    "    else:\n",
    "        eval_model = CollaborativeFiltering(n_users, n_items, n_factors)\n",
    "    eval_model.to(device)\n",
    "\n",
    "    # reset evaluation model parameters\n",
    "    torch.manual_seed(seed_target)\n",
    "    for layer in eval_model.children():\n",
    "        layer.reset_parameters()\n",
    "\n",
    "    # define optimizer and loss function for evaluation\n",
    "    if 'adam' in opt_target:\n",
    "        optimizer_eval = torch.optim.Adam(eval_model.parameters(), lr = lr_target)\n",
    "    else:\n",
    "        optimizer_eval = torch.optim.SGD(eval_model.parameters(), lr = lr_target)\n",
    "    loss_fn_eval = nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "    # detach ratings and perturbs for eval model\n",
    "    ratings_eval = ratings.detach().clone()\n",
    "    perturbs_eval = perturbs.detach().clone()\n",
    "\n",
    "    # reshape ratings and perturbs if necessary\n",
    "    # later add code for reshaping ratings_test as well (incomplete right now)\n",
    "    if surrogate != target:\n",
    "        if 'NCF' in target:\n",
    "            ratings_eval = ratings_eval.reshape((n_samples_train, 1))\n",
    "            perturbs_eval = perturbs_eval.reshape((n_samples_train, 1))\n",
    "        else:\n",
    "            ratings_eval = ratings_eval.reshape((n_samples_train))\n",
    "            perturbs_eval = perturbs_eval.reshape((n_samples_train))\n",
    "\n",
    "    # inner train  evaluation model\n",
    "    eval_model.train()\n",
    "    for i in range(T):\n",
    "        y_hat = eval_model(users, items)\n",
    "        loss_eval = loss_fn_eval(y_hat, ratings_eval)\n",
    "        optimizer_eval.zero_grad()\n",
    "        loss_eval.backward(retain_graph=retain_graph, create_graph=create_graph)\n",
    "        optimizer_eval.step()\n",
    "    eval_model.eval()\n",
    "\n",
    "    # compute and store accuracy of eval model after T training steps\n",
    "    with torch.no_grad():\n",
    "        # training accuracy and loss including perturbed edges\n",
    "        y_hat = eval_model(users, items)\n",
    "        perturbations['accuracy-before-target'].append(get_accuracy(y_hat, ratings_eval))\n",
    "        perturbations['loss-before-target'].append(loss_fn_eval(y_hat, ratings_eval).item())\n",
    "\n",
    "        # compute training AUROC including perturbed edges\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_eval.detach().clone().to('cpu').numpy() \n",
    "        perturbations['auc-before-target'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "        # training accuracy and loss excluding perturbed edges\n",
    "        y_hat_masked = torch.masked_select(y_hat, perturbs_eval)\n",
    "        ratings_masked = torch.masked_select(ratings_eval, perturbs_eval)\n",
    "        perturbations['accuracy-after-target'].append(get_accuracy(y_hat_masked, ratings_masked))\n",
    "        perturbations['loss-after-target'].append(loss_fn_eval(y_hat_masked, ratings_masked).item())\n",
    "\n",
    "        # compute training AUROC excluding perturbed edges\n",
    "        y_pred = y_hat_masked.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_masked.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-after-target'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # compute and store accuracy of target model on unseen data\n",
    "    with torch.no_grad():\n",
    "        y_hat = eval_model(users_test, items_test)\n",
    "        perturbations['accuracy-unseen-target'].append(get_accuracy(y_hat, ratings_test))\n",
    "        perturbations['loss-unseen-target'].append(loss_fn(y_hat, ratings_test).item())\n",
    "\n",
    "        # compute unseen AUROC\n",
    "        y_pred = y_hat.detach().clone().to('cpu').numpy()\n",
    "        y_actual = ratings_test.detach().clone().to('cpu').numpy()\n",
    "        perturbations['auc-unseen-target'].append(roc_auc_score(y_actual, y_pred))\n",
    "\n",
    "    # select best edge and perform perturbation\n",
    "    with torch.no_grad():\n",
    "        if 'meta' in algorithm:\n",
    "            mask = ratings.detach().int()\n",
    "            meta_grad[mask == 1] = 0\n",
    "            best_edge = meta_grad.argmax().item()\n",
    "            ratings[best_edge] = 1\n",
    "            perturbs[best_edge] = False\n",
    "\n",
    "            perturbations['edges'].append(best_edge)\n",
    "            perturbations['metagrad'].append(meta_grad[best_edge].item())\n",
    "\n",
    "        else:\n",
    "            best_edge = edges_to_perturb[delta]\n",
    "            ratings[best_edge] = 1 \n",
    "            perturbs[best_edge] = False\n",
    "\n",
    "            perturbations['edges'].append(best_edge)\n",
    "            perturbations['metagrad'].append(-1)\n",
    "\n",
    "sleep(1)\n",
    "# compute execution time\n",
    "exec_time = int(time.time() - start_time)\n",
    "exec_time = time.strftime(\"%Hh %Mm %Ss\", time.gmtime(exec_time))\n",
    "print('-> Execution time: {}'.format(exec_time))\n",
    "\n",
    "# process results\n",
    "perturbations = pd.DataFrame(perturbations)\n",
    "filename = '{}({})-{}({})-{}-D={}-T={}-lr({},{})-seed({},{})'.format(surrogate, opt_surrogate, target, opt_target, algorithm, Delta, T, lr_surrogate, lr_target, seed_surrogate, seed_target)\n",
    "if save_results:\n",
    "    perturbations.to_csv('results/' + dataset + '/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name:  CF(sgd)-CF(sgd)-meta-D=100-T=300-lr(1000,1000)-seed(0,25)\n",
      "Max meta-gradient:  0.00025150133296847343\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edges</th>\n",
       "      <th>metagrad</th>\n",
       "      <th>accuracy-before-surrogate</th>\n",
       "      <th>accuracy-after-surrogate</th>\n",
       "      <th>accuracy-unseen-surrogate</th>\n",
       "      <th>loss-before-surrogate</th>\n",
       "      <th>loss-after-surrogate</th>\n",
       "      <th>loss-unseen-surrogate</th>\n",
       "      <th>accuracy-before-target</th>\n",
       "      <th>accuracy-after-target</th>\n",
       "      <th>accuracy-unseen-target</th>\n",
       "      <th>loss-before-target</th>\n",
       "      <th>loss-after-target</th>\n",
       "      <th>loss-unseen-target</th>\n",
       "      <th>auc-before-surrogate</th>\n",
       "      <th>auc-after-surrogate</th>\n",
       "      <th>auc-unseen-surrogate</th>\n",
       "      <th>auc-before-target</th>\n",
       "      <th>auc-after-target</th>\n",
       "      <th>auc-unseen-target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64572</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.760556</td>\n",
       "      <td>0.213116</td>\n",
       "      <td>0.213116</td>\n",
       "      <td>0.724937</td>\n",
       "      <td>0.909616</td>\n",
       "      <td>0.909616</td>\n",
       "      <td>0.758822</td>\n",
       "      <td>0.210115</td>\n",
       "      <td>0.210115</td>\n",
       "      <td>0.731731</td>\n",
       "      <td>0.972110</td>\n",
       "      <td>0.972110</td>\n",
       "      <td>0.837078</td>\n",
       "      <td>0.972833</td>\n",
       "      <td>0.972833</td>\n",
       "      <td>0.835082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45202</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.908094</td>\n",
       "      <td>0.908093</td>\n",
       "      <td>0.759912</td>\n",
       "      <td>0.213170</td>\n",
       "      <td>0.213171</td>\n",
       "      <td>0.725120</td>\n",
       "      <td>0.909008</td>\n",
       "      <td>0.909008</td>\n",
       "      <td>0.758921</td>\n",
       "      <td>0.211128</td>\n",
       "      <td>0.211130</td>\n",
       "      <td>0.730293</td>\n",
       "      <td>0.972075</td>\n",
       "      <td>0.972074</td>\n",
       "      <td>0.836613</td>\n",
       "      <td>0.972583</td>\n",
       "      <td>0.972583</td>\n",
       "      <td>0.834938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136204</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.907993</td>\n",
       "      <td>0.907999</td>\n",
       "      <td>0.760803</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.213290</td>\n",
       "      <td>0.724132</td>\n",
       "      <td>0.909203</td>\n",
       "      <td>0.909201</td>\n",
       "      <td>0.758698</td>\n",
       "      <td>0.210722</td>\n",
       "      <td>0.210724</td>\n",
       "      <td>0.731177</td>\n",
       "      <td>0.972063</td>\n",
       "      <td>0.972068</td>\n",
       "      <td>0.837366</td>\n",
       "      <td>0.972674</td>\n",
       "      <td>0.972673</td>\n",
       "      <td>0.834629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1810</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.907923</td>\n",
       "      <td>0.759689</td>\n",
       "      <td>0.213443</td>\n",
       "      <td>0.213447</td>\n",
       "      <td>0.725339</td>\n",
       "      <td>0.909409</td>\n",
       "      <td>0.909408</td>\n",
       "      <td>0.758451</td>\n",
       "      <td>0.210580</td>\n",
       "      <td>0.210584</td>\n",
       "      <td>0.730272</td>\n",
       "      <td>0.972012</td>\n",
       "      <td>0.972011</td>\n",
       "      <td>0.836595</td>\n",
       "      <td>0.972712</td>\n",
       "      <td>0.972711</td>\n",
       "      <td>0.834758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111703</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.907874</td>\n",
       "      <td>0.907872</td>\n",
       "      <td>0.760308</td>\n",
       "      <td>0.213378</td>\n",
       "      <td>0.213383</td>\n",
       "      <td>0.724941</td>\n",
       "      <td>0.909246</td>\n",
       "      <td>0.909244</td>\n",
       "      <td>0.759144</td>\n",
       "      <td>0.210515</td>\n",
       "      <td>0.210519</td>\n",
       "      <td>0.731534</td>\n",
       "      <td>0.972025</td>\n",
       "      <td>0.972024</td>\n",
       "      <td>0.836598</td>\n",
       "      <td>0.972721</td>\n",
       "      <td>0.972720</td>\n",
       "      <td>0.834819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>137697</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.907304</td>\n",
       "      <td>0.907324</td>\n",
       "      <td>0.759318</td>\n",
       "      <td>0.215062</td>\n",
       "      <td>0.214965</td>\n",
       "      <td>0.725362</td>\n",
       "      <td>0.909403</td>\n",
       "      <td>0.909449</td>\n",
       "      <td>0.756990</td>\n",
       "      <td>0.211441</td>\n",
       "      <td>0.211208</td>\n",
       "      <td>0.735615</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.971623</td>\n",
       "      <td>0.835308</td>\n",
       "      <td>0.972549</td>\n",
       "      <td>0.972600</td>\n",
       "      <td>0.833921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>117937</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.907404</td>\n",
       "      <td>0.907430</td>\n",
       "      <td>0.759590</td>\n",
       "      <td>0.214925</td>\n",
       "      <td>0.214809</td>\n",
       "      <td>0.725326</td>\n",
       "      <td>0.909403</td>\n",
       "      <td>0.909443</td>\n",
       "      <td>0.757163</td>\n",
       "      <td>0.210788</td>\n",
       "      <td>0.210590</td>\n",
       "      <td>0.732528</td>\n",
       "      <td>0.971637</td>\n",
       "      <td>0.971661</td>\n",
       "      <td>0.835286</td>\n",
       "      <td>0.972672</td>\n",
       "      <td>0.972714</td>\n",
       "      <td>0.833643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>37471</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.907273</td>\n",
       "      <td>0.907298</td>\n",
       "      <td>0.759293</td>\n",
       "      <td>0.215009</td>\n",
       "      <td>0.214892</td>\n",
       "      <td>0.725294</td>\n",
       "      <td>0.909384</td>\n",
       "      <td>0.909423</td>\n",
       "      <td>0.757089</td>\n",
       "      <td>0.210858</td>\n",
       "      <td>0.210662</td>\n",
       "      <td>0.732681</td>\n",
       "      <td>0.971618</td>\n",
       "      <td>0.971642</td>\n",
       "      <td>0.835276</td>\n",
       "      <td>0.972656</td>\n",
       "      <td>0.972698</td>\n",
       "      <td>0.833626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>117309</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.907492</td>\n",
       "      <td>0.907517</td>\n",
       "      <td>0.758996</td>\n",
       "      <td>0.215051</td>\n",
       "      <td>0.214937</td>\n",
       "      <td>0.725735</td>\n",
       "      <td>0.909541</td>\n",
       "      <td>0.909579</td>\n",
       "      <td>0.757213</td>\n",
       "      <td>0.210841</td>\n",
       "      <td>0.210644</td>\n",
       "      <td>0.730194</td>\n",
       "      <td>0.971609</td>\n",
       "      <td>0.971632</td>\n",
       "      <td>0.835247</td>\n",
       "      <td>0.972649</td>\n",
       "      <td>0.972691</td>\n",
       "      <td>0.833855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>41924</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.907517</td>\n",
       "      <td>0.907541</td>\n",
       "      <td>0.759045</td>\n",
       "      <td>0.215039</td>\n",
       "      <td>0.214926</td>\n",
       "      <td>0.725573</td>\n",
       "      <td>0.909372</td>\n",
       "      <td>0.909409</td>\n",
       "      <td>0.757361</td>\n",
       "      <td>0.210732</td>\n",
       "      <td>0.210537</td>\n",
       "      <td>0.732313</td>\n",
       "      <td>0.971613</td>\n",
       "      <td>0.971636</td>\n",
       "      <td>0.835247</td>\n",
       "      <td>0.972683</td>\n",
       "      <td>0.972725</td>\n",
       "      <td>0.833626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     edges  metagrad  accuracy-before-surrogate  accuracy-after-surrogate  \\\n",
       "0    64572  0.000252                   0.908213                  0.908213   \n",
       "1    45202  0.000244                   0.908094                  0.908093   \n",
       "2   136204  0.000241                   0.907993                  0.907999   \n",
       "3     1810  0.000231                   0.907924                  0.907923   \n",
       "4   111703  0.000232                   0.907874                  0.907872   \n",
       "..     ...       ...                        ...                       ...   \n",
       "95  137697  0.000162                   0.907304                  0.907324   \n",
       "96  117937  0.000161                   0.907404                  0.907430   \n",
       "97   37471  0.000162                   0.907273                  0.907298   \n",
       "98  117309  0.000162                   0.907492                  0.907517   \n",
       "99   41924  0.000162                   0.907517                  0.907541   \n",
       "\n",
       "    accuracy-unseen-surrogate  loss-before-surrogate  loss-after-surrogate  \\\n",
       "0                    0.760556               0.213116              0.213116   \n",
       "1                    0.759912               0.213170              0.213171   \n",
       "2                    0.760803               0.213313              0.213290   \n",
       "3                    0.759689               0.213443              0.213447   \n",
       "4                    0.760308               0.213378              0.213383   \n",
       "..                        ...                    ...                   ...   \n",
       "95                   0.759318               0.215062              0.214965   \n",
       "96                   0.759590               0.214925              0.214809   \n",
       "97                   0.759293               0.215009              0.214892   \n",
       "98                   0.758996               0.215051              0.214937   \n",
       "99                   0.759045               0.215039              0.214926   \n",
       "\n",
       "    loss-unseen-surrogate  accuracy-before-target  accuracy-after-target  \\\n",
       "0                0.724937                0.909616               0.909616   \n",
       "1                0.725120                0.909008               0.909008   \n",
       "2                0.724132                0.909203               0.909201   \n",
       "3                0.725339                0.909409               0.909408   \n",
       "4                0.724941                0.909246               0.909244   \n",
       "..                    ...                     ...                    ...   \n",
       "95               0.725362                0.909403               0.909449   \n",
       "96               0.725326                0.909403               0.909443   \n",
       "97               0.725294                0.909384               0.909423   \n",
       "98               0.725735                0.909541               0.909579   \n",
       "99               0.725573                0.909372               0.909409   \n",
       "\n",
       "    accuracy-unseen-target  loss-before-target  loss-after-target  \\\n",
       "0                 0.758822            0.210115           0.210115   \n",
       "1                 0.758921            0.211128           0.211130   \n",
       "2                 0.758698            0.210722           0.210724   \n",
       "3                 0.758451            0.210580           0.210584   \n",
       "4                 0.759144            0.210515           0.210519   \n",
       "..                     ...                 ...                ...   \n",
       "95                0.756990            0.211441           0.211208   \n",
       "96                0.757163            0.210788           0.210590   \n",
       "97                0.757089            0.210858           0.210662   \n",
       "98                0.757213            0.210841           0.210644   \n",
       "99                0.757361            0.210732           0.210537   \n",
       "\n",
       "    loss-unseen-target  auc-before-surrogate  auc-after-surrogate  \\\n",
       "0             0.731731              0.972110             0.972110   \n",
       "1             0.730293              0.972075             0.972074   \n",
       "2             0.731177              0.972063             0.972068   \n",
       "3             0.730272              0.972012             0.972011   \n",
       "4             0.731534              0.972025             0.972024   \n",
       "..                 ...                   ...                  ...   \n",
       "95            0.735615              0.971604             0.971623   \n",
       "96            0.732528              0.971637             0.971661   \n",
       "97            0.732681              0.971618             0.971642   \n",
       "98            0.730194              0.971609             0.971632   \n",
       "99            0.732313              0.971613             0.971636   \n",
       "\n",
       "    auc-unseen-surrogate  auc-before-target  auc-after-target  \\\n",
       "0               0.837078           0.972833          0.972833   \n",
       "1               0.836613           0.972583          0.972583   \n",
       "2               0.837366           0.972674          0.972673   \n",
       "3               0.836595           0.972712          0.972711   \n",
       "4               0.836598           0.972721          0.972720   \n",
       "..                   ...                ...               ...   \n",
       "95              0.835308           0.972549          0.972600   \n",
       "96              0.835286           0.972672          0.972714   \n",
       "97              0.835276           0.972656          0.972698   \n",
       "98              0.835247           0.972649          0.972691   \n",
       "99              0.835247           0.972683          0.972725   \n",
       "\n",
       "    auc-unseen-target  \n",
       "0            0.835082  \n",
       "1            0.834938  \n",
       "2            0.834629  \n",
       "3            0.834758  \n",
       "4            0.834819  \n",
       "..                ...  \n",
       "95           0.833921  \n",
       "96           0.833643  \n",
       "97           0.833626  \n",
       "98           0.833855  \n",
       "99           0.833626  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('File name: ', filename)\n",
    "if 'meta' in algorithm:\n",
    "    print('Max meta-gradient: ', perturbations['metagrad'].max())\n",
    "perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Perturbations</th>\n",
       "      <th>Perturbed edge</th>\n",
       "      <th>Meta gradient</th>\n",
       "      <th>Accuracy including perturbed edges (surrogate)</th>\n",
       "      <th>Accuracy excluding perturbed edges (surrogate)</th>\n",
       "      <th>Accuracy unseen (surrogate)</th>\n",
       "      <th>Loss including perturbed edges (surrogate)</th>\n",
       "      <th>Loss excluding perturbed edges (surrogate)</th>\n",
       "      <th>Loss unseen (surrogate)</th>\n",
       "      <th>Accuracy including perturbed edges (target)</th>\n",
       "      <th>Accuracy excluding perturbed edges (target)</th>\n",
       "      <th>Accuracy unseen (target)</th>\n",
       "      <th>Loss including perturbed edges (target)</th>\n",
       "      <th>Loss excluding perturbed edges (target)</th>\n",
       "      <th>Loss unseen (target)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64572</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.760556</td>\n",
       "      <td>0.213116</td>\n",
       "      <td>0.213116</td>\n",
       "      <td>0.724937</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.761843</td>\n",
       "      <td>0.211837</td>\n",
       "      <td>0.211837</td>\n",
       "      <td>0.724220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45202</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.908094</td>\n",
       "      <td>0.908093</td>\n",
       "      <td>0.759912</td>\n",
       "      <td>0.213170</td>\n",
       "      <td>0.213171</td>\n",
       "      <td>0.725120</td>\n",
       "      <td>0.908902</td>\n",
       "      <td>0.908907</td>\n",
       "      <td>0.762141</td>\n",
       "      <td>0.212384</td>\n",
       "      <td>0.212378</td>\n",
       "      <td>0.725803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>136204</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.907993</td>\n",
       "      <td>0.907999</td>\n",
       "      <td>0.760803</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.213290</td>\n",
       "      <td>0.724132</td>\n",
       "      <td>0.908839</td>\n",
       "      <td>0.908838</td>\n",
       "      <td>0.761868</td>\n",
       "      <td>0.212368</td>\n",
       "      <td>0.212371</td>\n",
       "      <td>0.724222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1810</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.907923</td>\n",
       "      <td>0.759689</td>\n",
       "      <td>0.213443</td>\n",
       "      <td>0.213447</td>\n",
       "      <td>0.725339</td>\n",
       "      <td>0.909134</td>\n",
       "      <td>0.909138</td>\n",
       "      <td>0.762116</td>\n",
       "      <td>0.211804</td>\n",
       "      <td>0.211801</td>\n",
       "      <td>0.724209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111703</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.907874</td>\n",
       "      <td>0.907872</td>\n",
       "      <td>0.760308</td>\n",
       "      <td>0.213378</td>\n",
       "      <td>0.213383</td>\n",
       "      <td>0.724941</td>\n",
       "      <td>0.909027</td>\n",
       "      <td>0.909025</td>\n",
       "      <td>0.761843</td>\n",
       "      <td>0.211630</td>\n",
       "      <td>0.211632</td>\n",
       "      <td>0.723913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>68592</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.870780</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.708502</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>0.281563</td>\n",
       "      <td>0.786965</td>\n",
       "      <td>0.882245</td>\n",
       "      <td>0.887331</td>\n",
       "      <td>0.707882</td>\n",
       "      <td>0.271749</td>\n",
       "      <td>0.261128</td>\n",
       "      <td>0.822038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>126611</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.870717</td>\n",
       "      <td>0.877579</td>\n",
       "      <td>0.708551</td>\n",
       "      <td>0.295908</td>\n",
       "      <td>0.281516</td>\n",
       "      <td>0.786867</td>\n",
       "      <td>0.882301</td>\n",
       "      <td>0.887397</td>\n",
       "      <td>0.707981</td>\n",
       "      <td>0.271762</td>\n",
       "      <td>0.261151</td>\n",
       "      <td>0.821963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>115370</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.870799</td>\n",
       "      <td>0.877638</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.295924</td>\n",
       "      <td>0.281529</td>\n",
       "      <td>0.786675</td>\n",
       "      <td>0.882288</td>\n",
       "      <td>0.887436</td>\n",
       "      <td>0.708105</td>\n",
       "      <td>0.271747</td>\n",
       "      <td>0.261129</td>\n",
       "      <td>0.821770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>83334</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.870799</td>\n",
       "      <td>0.877718</td>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.295871</td>\n",
       "      <td>0.281476</td>\n",
       "      <td>0.786680</td>\n",
       "      <td>0.882357</td>\n",
       "      <td>0.887509</td>\n",
       "      <td>0.707981</td>\n",
       "      <td>0.271724</td>\n",
       "      <td>0.261085</td>\n",
       "      <td>0.821525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>33335</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.877831</td>\n",
       "      <td>0.708229</td>\n",
       "      <td>0.295848</td>\n",
       "      <td>0.281479</td>\n",
       "      <td>0.786641</td>\n",
       "      <td>0.882564</td>\n",
       "      <td>0.887695</td>\n",
       "      <td>0.708056</td>\n",
       "      <td>0.271720</td>\n",
       "      <td>0.261079</td>\n",
       "      <td>0.821538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # Perturbations  Perturbed edge  Meta gradient  \\\n",
       "0                   0           64572       0.000252   \n",
       "1                   1           45202       0.000244   \n",
       "2                   2          136204       0.000241   \n",
       "3                   3            1810       0.000231   \n",
       "4                   4          111703       0.000232   \n",
       "...               ...             ...            ...   \n",
       "9995             9995           68592       0.000048   \n",
       "9996             9996          126611       0.000048   \n",
       "9997             9997          115370       0.000048   \n",
       "9998             9998           83334       0.000047   \n",
       "9999             9999           33335       0.000048   \n",
       "\n",
       "      Accuracy including perturbed edges (surrogate)  \\\n",
       "0                                           0.908213   \n",
       "1                                           0.908094   \n",
       "2                                           0.907993   \n",
       "3                                           0.907924   \n",
       "4                                           0.907874   \n",
       "...                                              ...   \n",
       "9995                                        0.870780   \n",
       "9996                                        0.870717   \n",
       "9997                                        0.870799   \n",
       "9998                                        0.870799   \n",
       "9999                                        0.870930   \n",
       "\n",
       "      Accuracy excluding perturbed edges (surrogate)  \\\n",
       "0                                           0.908213   \n",
       "1                                           0.908093   \n",
       "2                                           0.907999   \n",
       "3                                           0.907923   \n",
       "4                                           0.907872   \n",
       "...                                              ...   \n",
       "9995                                        0.877660   \n",
       "9996                                        0.877579   \n",
       "9997                                        0.877638   \n",
       "9998                                        0.877718   \n",
       "9999                                        0.877831   \n",
       "\n",
       "      Accuracy unseen (surrogate)  Loss including perturbed edges (surrogate)  \\\n",
       "0                        0.760556                                    0.213116   \n",
       "1                        0.759912                                    0.213170   \n",
       "2                        0.760803                                    0.213313   \n",
       "3                        0.759689                                    0.213443   \n",
       "4                        0.760308                                    0.213378   \n",
       "...                           ...                                         ...   \n",
       "9995                     0.708502                                    0.295964   \n",
       "9996                     0.708551                                    0.295908   \n",
       "9997                     0.708848                                    0.295924   \n",
       "9998                     0.708204                                    0.295871   \n",
       "9999                     0.708229                                    0.295848   \n",
       "\n",
       "      Loss excluding perturbed edges (surrogate)  Loss unseen (surrogate)  \\\n",
       "0                                       0.213116                 0.724937   \n",
       "1                                       0.213171                 0.725120   \n",
       "2                                       0.213290                 0.724132   \n",
       "3                                       0.213447                 0.725339   \n",
       "4                                       0.213383                 0.724941   \n",
       "...                                          ...                      ...   \n",
       "9995                                    0.281563                 0.786965   \n",
       "9996                                    0.281516                 0.786867   \n",
       "9997                                    0.281529                 0.786675   \n",
       "9998                                    0.281476                 0.786680   \n",
       "9999                                    0.281479                 0.786641   \n",
       "\n",
       "      Accuracy including perturbed edges (target)  \\\n",
       "0                                        0.909152   \n",
       "1                                        0.908902   \n",
       "2                                        0.908839   \n",
       "3                                        0.909134   \n",
       "4                                        0.909027   \n",
       "...                                           ...   \n",
       "9995                                     0.882245   \n",
       "9996                                     0.882301   \n",
       "9997                                     0.882288   \n",
       "9998                                     0.882357   \n",
       "9999                                     0.882564   \n",
       "\n",
       "      Accuracy excluding perturbed edges (target)  Accuracy unseen (target)  \\\n",
       "0                                        0.909152                  0.761843   \n",
       "1                                        0.908907                  0.762141   \n",
       "2                                        0.908838                  0.761868   \n",
       "3                                        0.909138                  0.762116   \n",
       "4                                        0.909025                  0.761843   \n",
       "...                                           ...                       ...   \n",
       "9995                                     0.887331                  0.707882   \n",
       "9996                                     0.887397                  0.707981   \n",
       "9997                                     0.887436                  0.708105   \n",
       "9998                                     0.887509                  0.707981   \n",
       "9999                                     0.887695                  0.708056   \n",
       "\n",
       "      Loss including perturbed edges (target)  \\\n",
       "0                                    0.211837   \n",
       "1                                    0.212384   \n",
       "2                                    0.212368   \n",
       "3                                    0.211804   \n",
       "4                                    0.211630   \n",
       "...                                       ...   \n",
       "9995                                 0.271749   \n",
       "9996                                 0.271762   \n",
       "9997                                 0.271747   \n",
       "9998                                 0.271724   \n",
       "9999                                 0.271720   \n",
       "\n",
       "      Loss excluding perturbed edges (target)  Loss unseen (target)  \n",
       "0                                    0.211837              0.724220  \n",
       "1                                    0.212378              0.725803  \n",
       "2                                    0.212371              0.724222  \n",
       "3                                    0.211801              0.724209  \n",
       "4                                    0.211632              0.723913  \n",
       "...                                       ...                   ...  \n",
       "9995                                 0.261128              0.822038  \n",
       "9996                                 0.261151              0.821963  \n",
       "9997                                 0.261129              0.821770  \n",
       "9998                                 0.261085              0.821525  \n",
       "9999                                 0.261079              0.821538  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process perturbations data\n",
    "perturbations_reset = perturbations.reset_index()\n",
    "perturbations_reset.columns = ['# Perturbations', 'Perturbed edge', 'Meta gradient', 'Accuracy including perturbed edges (surrogate)', 'Accuracy excluding perturbed edges (surrogate)', 'Accuracy unseen (surrogate)', 'Loss including perturbed edges (surrogate)', 'Loss excluding perturbed edges (surrogate)', 'Loss unseen (surrogate)', 'Accuracy including perturbed edges (target)', 'Accuracy excluding perturbed edges (target)', 'Accuracy unseen (target)', 'Loss including perturbed edges (target)', 'Loss excluding perturbed edges (target)', 'Loss unseen (target)']\n",
    "perturbations_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process perturbations data\n",
    "perturbations_reset = perturbations.reset_index()\n",
    "perturbations_reset.columns = ['# Perturbations', 'Perturbed edge', 'Meta gradient', 'Accuracy including perturbed edges (surrogate)', 'Accuracy excluding perturbed edges (surrogate)', 'Accuracy unseen (surrogate)', 'Loss including perturbed edges (surrogate)', 'Loss excluding perturbed edges (surrogate)', 'Loss unseen (surrogate)', 'Accuracy including perturbed edges (target)', 'Accuracy excluding perturbed edges (target)', 'Accuracy unseen (target)', 'Loss including perturbed edges (target)', 'Loss excluding perturbed edges (target)', 'Loss unseen (target)']\n",
    "perturbations_reset\n",
    "\n",
    "# Figure specifications\n",
    "sns.set_theme()\n",
    "figsize = (7, 6)\n",
    "print('File name: ', filename)\n",
    "\n",
    "# Loss plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss excluding perturbed edges (surrogate)', color = 'blue').set_title('Comparison of loss on training data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss excluding perturbed edges (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(labels = ['Loss (surrogate)', 'Loss (target)'], loc = 'upper left')\n",
    "if save_results: \n",
    "    fig.savefig('plots/' + dataset + '/losses-' + filename)\n",
    "plt.show()\n",
    "\n",
    "# Loss on unseen data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss unseen (surrogate)', color = 'blue').set_title('Comparison of loss on unseen data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Loss unseen (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(labels = ['Loss unseen (surrogate)', 'Loss unseen (target)'], loc = 'upper left')\n",
    "if save_results: \n",
    "    fig.savefig('plots/' + dataset + '/losses-unseen-' + filename)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy excluding perturbed edges (surrogate)', color = 'blue').set_title('Comparison of accuracy on training data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy excluding perturbed edges (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(labels = ['Accuracy (surrogate)', 'Accuracy (target)'])\n",
    "if save_results:\n",
    "    fig.savefig('plots/' + dataset + '/accuracy-' + filename)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy on unseen data plot\n",
    "plt.figure(figsize = figsize)\n",
    "sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy unseen (surrogate)', color = 'blue').set_title('Comparison of accuracy on unseen data ({})'.format(algorithm))\n",
    "fig = sns.lineplot(data = perturbations_reset, x = '# Perturbations', y = 'Accuracy unseen (target)', color = 'green').get_figure()\n",
    "plt.xlabel('Number of perturbations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(labels = ['Accuracy unseen (surrogate)', 'Accuracy unseen (target)'], loc = 'upper left')\n",
    "if save_results: \n",
    "    fig.savefig('plots/' + dataset + '/accuracy-unseen-' + filename)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f38835821387ecea7238337192aa99e87ed1a9c9c1fa6562e207de7e0c31193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PyG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
